{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "crnn_final.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vinayhpandya/onefourthlabscode/blob/master/crnn_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gCrDPkEa8vY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "import random\n",
        "import time\n",
        "import copy\n",
        "import math\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import torch.optim.lr_scheduler as lrs\n",
        "\n",
        "import torchvision.utils as utils\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as T\n",
        "import torchvision.models as models"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mh0acJe5BWtL",
        "colab_type": "code",
        "outputId": "8c4f8ad4-989f-418c-9425-6f0b87bda18d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        }
      },
      "source": [
        "!git clone --recursive https://github.com/StickCui/warp-ctc-pytorch.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'warp-ctc-pytorch'...\n",
            "remote: Enumerating objects: 41, done.\u001b[K\n",
            "remote: Total 41 (delta 0), reused 0 (delta 0), pack-reused 41\n",
            "Unpacking objects: 100% (41/41), done.\n",
            "Submodule 'warpctc/core' (https://github.com/baidu-research/warp-ctc) registered for path 'warpctc/core'\n",
            "Cloning into '/content/warp-ctc-pytorch/warpctc/core'...\n",
            "remote: Enumerating objects: 13, done.        \n",
            "remote: Counting objects: 100% (13/13), done.        \n",
            "remote: Compressing objects: 100% (12/12), done.        \n",
            "remote: Total 437 (delta 1), reused 5 (delta 0), pack-reused 424        \n",
            "Receiving objects: 100% (437/437), 334.57 KiB | 4.13 MiB/s, done.\n",
            "Resolving deltas: 100% (206/206), done.\n",
            "Submodule path 'warpctc/core': checked out '6d5b8fac130638862d97dc48ef43a8d7b5a503bb'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJgyCy-NFhAb",
        "colab_type": "code",
        "outputId": "6bd38ad9-be58-41b5-a234-6079709244c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%cd warp-ctc-pytorch\n",
        "!sh make.sh install"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/warp-ctc-pytorch\n",
            "/content/warp-ctc-pytorch\n",
            "Make core shared object of libwarp_ctc.so\n",
            "-- The C compiler identification is GNU 7.4.0\n",
            "-- The CXX compiler identification is GNU 7.4.0\n",
            "-- Check for working C compiler: /usr/bin/cc\n",
            "-- Check for working C compiler: /usr/bin/cc -- works\n",
            "-- Detecting C compiler ABI info\n",
            "-- Detecting C compiler ABI info - done\n",
            "-- Detecting C compile features\n",
            "-- Detecting C compile features - done\n",
            "-- Check for working CXX compiler: /usr/bin/c++\n",
            "-- Check for working CXX compiler: /usr/bin/c++ -- works\n",
            "-- Detecting CXX compiler ABI info\n",
            "-- Detecting CXX compiler ABI info - done\n",
            "-- Detecting CXX compile features\n",
            "-- Detecting CXX compile features - done\n",
            "-- Looking for pthread.h\n",
            "-- Looking for pthread.h - found\n",
            "-- Looking for pthread_create\n",
            "-- Looking for pthread_create - not found\n",
            "-- Looking for pthread_create in pthreads\n",
            "-- Looking for pthread_create in pthreads - not found\n",
            "-- Looking for pthread_create in pthread\n",
            "-- Looking for pthread_create in pthread - found\n",
            "-- Found Threads: TRUE  \n",
            "-- Found CUDA: /usr/local/cuda (found suitable version \"10.0\", minimum required is \"6.5\") \n",
            "-- cuda found TRUE\n",
            "CMake Warning at CMakeLists.txt:48 (FIND_PACKAGE):\n",
            "  By not providing \"FindTorch.cmake\" in CMAKE_MODULE_PATH this project has\n",
            "  asked CMake to find a package configuration file provided by \"Torch\", but\n",
            "  CMake did not find one.\n",
            "\n",
            "  Could not find a package configuration file provided by \"Torch\" with any of\n",
            "  the following names:\n",
            "\n",
            "    TorchConfig.cmake\n",
            "    torch-config.cmake\n",
            "\n",
            "  Add the installation prefix of \"Torch\" to CMAKE_PREFIX_PATH or set\n",
            "  \"Torch_DIR\" to a directory containing one of the above files.  If \"Torch\"\n",
            "  provides a separate development package or SDK, be sure it has been\n",
            "  installed.\n",
            "\n",
            "\n",
            "-- Torch found Torch_DIR-NOTFOUND\n",
            "-- Building shared library with GPU support\n",
            "-- Configuring done\n",
            "-- Generating done\n",
            "-- Build files have been written to: /content/warp-ctc-pytorch/warpctc/core/build\n",
            "[ 14%] \u001b[34m\u001b[1mBuilding NVCC (Device) object CMakeFiles/warpctc.dir/src/warpctc_generated_reduce.cu.o\u001b[0m\n",
            "[ 28%] \u001b[34m\u001b[1mBuilding NVCC (Device) object CMakeFiles/warpctc.dir/src/warpctc_generated_ctc_entrypoint.cu.o\u001b[0m\n",
            "/content/warp-ctc-pytorch/warpctc/core/src/reduce.cu(44): warning: function \"__shfl_down(float, unsigned int, int)\"\n",
            "/usr/local/cuda/include/sm_30_intrinsics.hpp(275): here was declared deprecated (\"__shfl_down() is deprecated in favor of __shfl_down_sync() and may be removed in a future release (Use -Wno-deprecated-declarations to suppress this warning).\")\n",
            "          detected during:\n",
            "            instantiation of \"T CTAReduce<NT, T, Rop>::reduce(int, T, CTAReduce<NT, T, Rop>::Storage &, int, Rop) [with NT=128, T=float, Rop=ctc_helper::add<float, float>]\" \n",
            "(76): here\n",
            "            instantiation of \"void reduce_rows<NT,Iop,Rop,T>(Iop, Rop, const T *, T *, int, int) [with NT=128, Iop=ctc_helper::negate<float, float>, Rop=ctc_helper::add<float, float>, T=float]\" \n",
            "(124): here\n",
            "            instantiation of \"void ReduceHelper::impl(Iof, Rof, const T *, T *, int, int, __nv_bool, cudaStream_t) [with T=float, Iof=ctc_helper::negate<float, float>, Rof=ctc_helper::add<float, float>]\" \n",
            "(139): here\n",
            "            instantiation of \"ctcStatus_t reduce(Iof, Rof, const T *, T *, int, int, __nv_bool, cudaStream_t) [with T=float, Iof=ctc_helper::negate<float, float>, Rof=ctc_helper::add<float, float>]\" \n",
            "(149): here\n",
            "\n",
            "/content/warp-ctc-pytorch/warpctc/core/src/reduce.cu(44): warning: function \"__shfl_down(float, unsigned int, int)\"\n",
            "/usr/local/cuda/include/sm_30_intrinsics.hpp(275): here was declared deprecated (\"__shfl_down() is deprecated in favor of __shfl_down_sync() and may be removed in a future release (Use -Wno-deprecated-declarations to suppress this warning).\")\n",
            "          detected during:\n",
            "            instantiation of \"T CTAReduce<NT, T, Rop>::reduce(int, T, CTAReduce<NT, T, Rop>::Storage &, int, Rop) [with NT=128, T=float, Rop=ctc_helper::maximum<float, float>]\" \n",
            "(76): here\n",
            "            instantiation of \"void reduce_rows<NT,Iop,Rop,T>(Iop, Rop, const T *, T *, int, int) [with NT=128, Iop=ctc_helper::identity<float, float>, Rop=ctc_helper::maximum<float, float>, T=float]\" \n",
            "(124): here\n",
            "            instantiation of \"void ReduceHelper::impl(Iof, Rof, const T *, T *, int, int, __nv_bool, cudaStream_t) [with T=float, Iof=ctc_helper::identity<float, float>, Rof=ctc_helper::maximum<float, float>]\" \n",
            "(139): here\n",
            "            instantiation of \"ctcStatus_t reduce(Iof, Rof, const T *, T *, int, int, __nv_bool, cudaStream_t) [with T=float, Iof=ctc_helper::identity<float, float>, Rof=ctc_helper::maximum<float, float>]\" \n",
            "(157): here\n",
            "\n",
            "/content/warp-ctc-pytorch/warpctc/core/include/contrib/moderngpu/include/device/intrinsics.cuh(115): warning: function \"__shfl_up(float, unsigned int, int)\"\n",
            "/usr/local/cuda/include/sm_30_intrinsics.hpp(258): here was declared deprecated (\"__shfl_up() is deprecated in favor of __shfl_up_sync() and may be removed in a future release (Use -Wno-deprecated-declarations to suppress this warning).\")\n",
            "\n",
            "/content/warp-ctc-pytorch/warpctc/core/include/contrib/moderngpu/include/device/intrinsics.cuh(125): warning: function \"__shfl_up(int, unsigned int, int)\"\n",
            "/usr/local/cuda/include/sm_30_intrinsics.hpp(172): here was declared deprecated (\"__shfl_up() is deprecated in favor of __shfl_up_sync() and may be removed in a future release (Use -Wno-deprecated-declarations to suppress this warning).\")\n",
            "\n",
            "/content/warp-ctc-pytorch/warpctc/core/include/contrib/moderngpu/include/device/intrinsics.cuh(126): warning: function \"__shfl_up(int, unsigned int, int)\"\n",
            "/usr/local/cuda/include/sm_30_intrinsics.hpp(172): here was declared deprecated (\"__shfl_up() is deprecated in favor of __shfl_up_sync() and may be removed in a future release (Use -Wno-deprecated-declarations to suppress this warning).\")\n",
            "\n",
            "/content/warp-ctc-pytorch/warpctc/core/src/reduce.cu(44): warning: function \"__shfl_down(float, unsigned int, int)\"\n",
            "/usr/local/cuda/include/sm_30_intrinsics.hpp(275): here was declared deprecated (\"__shfl_down() is deprecated in favor of __shfl_down_sync() and may be removed in a future release (Use -Wno-deprecated-declarations to suppress this warning).\")\n",
            "          detected during:\n",
            "            instantiation of \"T CTAReduce<NT, T, Rop>::reduce(int, T, CTAReduce<NT, T, Rop>::Storage &, int, Rop) [with NT=128, T=float, Rop=ctc_helper::add<float, float>]\" \n",
            "(76): here\n",
            "            instantiation of \"void reduce_rows<NT,Iop,Rop,T>(Iop, Rop, const T *, T *, int, int) [with NT=128, Iop=ctc_helper::negate<float, float>, Rop=ctc_helper::add<float, float>, T=float]\" \n",
            "(124): here\n",
            "            instantiation of \"void ReduceHelper::impl(Iof, Rof, const T *, T *, int, int, __nv_bool, cudaStream_t) [with T=float, Iof=ctc_helper::negate<float, float>, Rof=ctc_helper::add<float, float>]\" \n",
            "(139): here\n",
            "            instantiation of \"ctcStatus_t reduce(Iof, Rof, const T *, T *, int, int, __nv_bool, cudaStream_t) [with T=float, Iof=ctc_helper::negate<float, float>, Rof=ctc_helper::add<float, float>]\" \n",
            "(149): here\n",
            "\n",
            "/content/warp-ctc-pytorch/warpctc/core/src/reduce.cu(44): warning: function \"__shfl_down(float, unsigned int, int)\"\n",
            "/usr/local/cuda/include/sm_30_intrinsics.hpp(275): here was declared deprecated (\"__shfl_down() is deprecated in favor of __shfl_down_sync() and may be removed in a future release (Use -Wno-deprecated-declarations to suppress this warning).\")\n",
            "          detected during:\n",
            "            instantiation of \"T CTAReduce<NT, T, Rop>::reduce(int, T, CTAReduce<NT, T, Rop>::Storage &, int, Rop) [with NT=128, T=float, Rop=ctc_helper::maximum<float, float>]\" \n",
            "(76): here\n",
            "            instantiation of \"void reduce_rows<NT,Iop,Rop,T>(Iop, Rop, const T *, T *, int, int) [with NT=128, Iop=ctc_helper::identity<float, float>, Rop=ctc_helper::maximum<float, float>, T=float]\" \n",
            "(124): here\n",
            "            instantiation of \"void ReduceHelper::impl(Iof, Rof, const T *, T *, int, int, __nv_bool, cudaStream_t) [with T=float, Iof=ctc_helper::identity<float, float>, Rof=ctc_helper::maximum<float, float>]\" \n",
            "(139): here\n",
            "            instantiation of \"ctcStatus_t reduce(Iof, Rof, const T *, T *, int, int, __nv_bool, cudaStream_t) [with T=float, Iof=ctc_helper::identity<float, float>, Rof=ctc_helper::maximum<float, float>]\" \n",
            "(157): here\n",
            "\n",
            "ptxas /tmp/tmpxft_000001fe_00000000-11_reduce.compute_30.ptx, line 158; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_000001fe_00000000-11_reduce.compute_30.ptx, line 168; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_000001fe_00000000-11_reduce.compute_30.ptx, line 178; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_000001fe_00000000-11_reduce.compute_30.ptx, line 188; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_000001fe_00000000-11_reduce.compute_30.ptx, line 198; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_000001fe_00000000-11_reduce.compute_30.ptx, line 564; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_000001fe_00000000-11_reduce.compute_30.ptx, line 574; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_000001fe_00000000-11_reduce.compute_30.ptx, line 584; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_000001fe_00000000-11_reduce.compute_30.ptx, line 594; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_000001fe_00000000-11_reduce.compute_30.ptx, line 604; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_000001fe_00000000-11_reduce.compute_30.ptx, line 904; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_000001fe_00000000-11_reduce.compute_30.ptx, line 920; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_000001fe_00000000-11_reduce.compute_30.ptx, line 936; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_000001fe_00000000-11_reduce.compute_30.ptx, line 952; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_000001fe_00000000-11_reduce.compute_30.ptx, line 968; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "/content/warp-ctc-pytorch/warpctc/core/src/reduce.cu(44): warning: function \"__shfl_down(float, unsigned int, int)\"\n",
            "/usr/local/cuda/include/sm_30_intrinsics.hpp(275): here was declared deprecated (\"__shfl_down() is deprecated in favor of __shfl_down_sync() and may be removed in a future release (Use -Wno-deprecated-declarations to suppress this warning).\")\n",
            "          detected during:\n",
            "            instantiation of \"T CTAReduce<NT, T, Rop>::reduce(int, T, CTAReduce<NT, T, Rop>::Storage &, int, Rop) [with NT=128, T=float, Rop=ctc_helper::add<float, float>]\" \n",
            "(76): here\n",
            "            instantiation of \"void reduce_rows<NT,Iop,Rop,T>(Iop, Rop, const T *, T *, int, int) [with NT=128, Iop=ctc_helper::negate<float, float>, Rop=ctc_helper::add<float, float>, T=float]\" \n",
            "(124): here\n",
            "            instantiation of \"void ReduceHelper::impl(Iof, Rof, const T *, T *, int, int, __nv_bool, cudaStream_t) [with T=float, Iof=ctc_helper::negate<float, float>, Rof=ctc_helper::add<float, float>]\" \n",
            "(139): here\n",
            "            instantiation of \"ctcStatus_t reduce(Iof, Rof, const T *, T *, int, int, __nv_bool, cudaStream_t) [with T=float, Iof=ctc_helper::negate<float, float>, Rof=ctc_helper::add<float, float>]\" \n",
            "(149): here\n",
            "\n",
            "/content/warp-ctc-pytorch/warpctc/core/src/reduce.cu(44): warning: function \"__shfl_down(float, unsigned int, int)\"\n",
            "/usr/local/cuda/include/sm_30_intrinsics.hpp(275): here was declared deprecated (\"__shfl_down() is deprecated in favor of __shfl_down_sync() and may be removed in a future release (Use -Wno-deprecated-declarations to suppress this warning).\")\n",
            "          detected during:\n",
            "            instantiation of \"T CTAReduce<NT, T, Rop>::reduce(int, T, CTAReduce<NT, T, Rop>::Storage &, int, Rop) [with NT=128, T=float, Rop=ctc_helper::maximum<float, float>]\" \n",
            "(76): here\n",
            "            instantiation of \"void reduce_rows<NT,Iop,Rop,T>(Iop, Rop, const T *, T *, int, int) [with NT=128, Iop=ctc_helper::identity<float, float>, Rop=ctc_helper::maximum<float, float>, T=float]\" \n",
            "(124): here\n",
            "            instantiation of \"void ReduceHelper::impl(Iof, Rof, const T *, T *, int, int, __nv_bool, cudaStream_t) [with T=float, Iof=ctc_helper::identity<float, float>, Rof=ctc_helper::maximum<float, float>]\" \n",
            "(139): here\n",
            "            instantiation of \"ctcStatus_t reduce(Iof, Rof, const T *, T *, int, int, __nv_bool, cudaStream_t) [with T=float, Iof=ctc_helper::identity<float, float>, Rof=ctc_helper::maximum<float, float>]\" \n",
            "(157): here\n",
            "\n",
            "ptxas /tmp/tmpxft_000001fe_00000000-10_reduce.compute_35.ptx, line 159; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_000001fe_00000000-10_reduce.compute_35.ptx, line 169; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_000001fe_00000000-10_reduce.compute_35.ptx, line 179; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_000001fe_00000000-10_reduce.compute_35.ptx, line 189; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_000001fe_00000000-10_reduce.compute_35.ptx, line 199; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_000001fe_00000000-10_reduce.compute_35.ptx, line 565; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_000001fe_00000000-10_reduce.compute_35.ptx, line 575; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_000001fe_00000000-10_reduce.compute_35.ptx, line 585; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_000001fe_00000000-10_reduce.compute_35.ptx, line 595; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_000001fe_00000000-10_reduce.compute_35.ptx, line 605; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_000001fe_00000000-10_reduce.compute_35.ptx, line 892; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_000001fe_00000000-10_reduce.compute_35.ptx, line 908; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_000001fe_00000000-10_reduce.compute_35.ptx, line 924; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_000001fe_00000000-10_reduce.compute_35.ptx, line 940; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_000001fe_00000000-10_reduce.compute_35.ptx, line 956; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "/content/warp-ctc-pytorch/warpctc/core/src/reduce.cu(44): warning: function \"__shfl_down(float, unsigned int, int)\"\n",
            "/usr/local/cuda/include/sm_30_intrinsics.hpp(275): here was declared deprecated (\"__shfl_down() is deprecated in favor of __shfl_down_sync() and may be removed in a future release (Use -Wno-deprecated-declarations to suppress this warning).\")\n",
            "          detected during:\n",
            "            instantiation of \"T CTAReduce<NT, T, Rop>::reduce(int, T, CTAReduce<NT, T, Rop>::Storage &, int, Rop) [with NT=128, T=float, Rop=ctc_helper::add<float, float>]\" \n",
            "(76): here\n",
            "            instantiation of \"void reduce_rows<NT,Iop,Rop,T>(Iop, Rop, const T *, T *, int, int) [with NT=128, Iop=ctc_helper::negate<float, float>, Rop=ctc_helper::add<float, float>, T=float]\" \n",
            "(124): here\n",
            "            instantiation of \"void ReduceHelper::impl(Iof, Rof, const T *, T *, int, int, __nv_bool, cudaStream_t) [with T=float, Iof=ctc_helper::negate<float, float>, Rof=ctc_helper::add<float, float>]\" \n",
            "(139): here\n",
            "            instantiation of \"ctcStatus_t reduce(Iof, Rof, const T *, T *, int, int, __nv_bool, cudaStream_t) [with T=float, Iof=ctc_helper::negate<float, float>, Rof=ctc_helper::add<float, float>]\" \n",
            "(149): here\n",
            "\n",
            "/content/warp-ctc-pytorch/warpctc/core/src/reduce.cu(44): warning: function \"__shfl_down(float, unsigned int, int)\"\n",
            "/usr/local/cuda/include/sm_30_intrinsics.hpp(275): here was declared deprecated (\"__shfl_down() is deprecated in favor of __shfl_down_sync() and may be removed in a future release (Use -Wno-deprecated-declarations to suppress this warning).\")\n",
            "          detected during:\n",
            "            instantiation of \"T CTAReduce<NT, T, Rop>::reduce(int, T, CTAReduce<NT, T, Rop>::Storage &, int, Rop) [with NT=128, T=float, Rop=ctc_helper::maximum<float, float>]\" \n",
            "(76): here\n",
            "            instantiation of \"void reduce_rows<NT,Iop,Rop,T>(Iop, Rop, const T *, T *, int, int) [with NT=128, Iop=ctc_helper::identity<float, float>, Rop=ctc_helper::maximum<float, float>, T=float]\" \n",
            "(124): here\n",
            "            instantiation of \"void ReduceHelper::impl(Iof, Rof, const T *, T *, int, int, __nv_bool, cudaStream_t) [with T=float, Iof=ctc_helper::identity<float, float>, Rof=ctc_helper::maximum<float, float>]\" \n",
            "(139): here\n",
            "            instantiation of \"ctcStatus_t reduce(Iof, Rof, const T *, T *, int, int, __nv_bool, cudaStream_t) [with T=float, Iof=ctc_helper::identity<float, float>, Rof=ctc_helper::maximum<float, float>]\" \n",
            "(157): here\n",
            "\n",
            "ptxas /tmp/tmpxft_000001fe_00000000-9_reduce.compute_50.ptx, line 159; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_000001fe_00000000-9_reduce.compute_50.ptx, line 169; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_000001fe_00000000-9_reduce.compute_50.ptx, line 179; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_000001fe_00000000-9_reduce.compute_50.ptx, line 189; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_000001fe_00000000-9_reduce.compute_50.ptx, line 199; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_000001fe_00000000-9_reduce.compute_50.ptx, line 565; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_000001fe_00000000-9_reduce.compute_50.ptx, line 575; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_000001fe_00000000-9_reduce.compute_50.ptx, line 585; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_000001fe_00000000-9_reduce.compute_50.ptx, line 595; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_000001fe_00000000-9_reduce.compute_50.ptx, line 605; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_000001fe_00000000-9_reduce.compute_50.ptx, line 892; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_000001fe_00000000-9_reduce.compute_50.ptx, line 908; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_000001fe_00000000-9_reduce.compute_50.ptx, line 924; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_000001fe_00000000-9_reduce.compute_50.ptx, line 940; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_000001fe_00000000-9_reduce.compute_50.ptx, line 956; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "/content/warp-ctc-pytorch/warpctc/core/src/reduce.cu(44): warning: function \"__shfl_down(float, unsigned int, int)\"\n",
            "/usr/local/cuda/include/sm_30_intrinsics.hpp(275): here was declared deprecated (\"__shfl_down() is deprecated in favor of __shfl_down_sync() and may be removed in a future release (Use -Wno-deprecated-declarations to suppress this warning).\")\n",
            "          detected during:\n",
            "            instantiation of \"T CTAReduce<NT, T, Rop>::reduce(int, T, CTAReduce<NT, T, Rop>::Storage &, int, Rop) [with NT=128, T=float, Rop=ctc_helper::add<float, float>]\" \n",
            "(76): here\n",
            "            instantiation of \"void reduce_rows<NT,Iop,Rop,T>(Iop, Rop, const T *, T *, int, int) [with NT=128, Iop=ctc_helper::negate<float, float>, Rop=ctc_helper::add<float, float>, T=float]\" \n",
            "(124): here\n",
            "            instantiation of \"void ReduceHelper::impl(Iof, Rof, const T *, T *, int, int, __nv_bool, cudaStream_t) [with T=float, Iof=ctc_helper::negate<float, float>, Rof=ctc_helper::add<float, float>]\" \n",
            "(139): here\n",
            "            instantiation of \"ctcStatus_t reduce(Iof, Rof, const T *, T *, int, int, __nv_bool, cudaStream_t) [with T=float, Iof=ctc_helper::negate<float, float>, Rof=ctc_helper::add<float, float>]\" \n",
            "(149): here\n",
            "\n",
            "/content/warp-ctc-pytorch/warpctc/core/src/reduce.cu(44): warning: function \"__shfl_down(float, unsigned int, int)\"\n",
            "/usr/local/cuda/include/sm_30_intrinsics.hpp(275): here was declared deprecated (\"__shfl_down() is deprecated in favor of __shfl_down_sync() and may be removed in a future release (Use -Wno-deprecated-declarations to suppress this warning).\")\n",
            "          detected during:\n",
            "            instantiation of \"T CTAReduce<NT, T, Rop>::reduce(int, T, CTAReduce<NT, T, Rop>::Storage &, int, Rop) [with NT=128, T=float, Rop=ctc_helper::maximum<float, float>]\" \n",
            "(76): here\n",
            "            instantiation of \"void reduce_rows<NT,Iop,Rop,T>(Iop, Rop, const T *, T *, int, int) [with NT=128, Iop=ctc_helper::identity<float, float>, Rop=ctc_helper::maximum<float, float>, T=float]\" \n",
            "(124): here\n",
            "            instantiation of \"void ReduceHelper::impl(Iof, Rof, const T *, T *, int, int, __nv_bool, cudaStream_t) [with T=float, Iof=ctc_helper::identity<float, float>, Rof=ctc_helper::maximum<float, float>]\" \n",
            "(139): here\n",
            "            instantiation of \"ctcStatus_t reduce(Iof, Rof, const T *, T *, int, int, __nv_bool, cudaStream_t) [with T=float, Iof=ctc_helper::identity<float, float>, Rof=ctc_helper::maximum<float, float>]\" \n",
            "(157): here\n",
            "\n",
            "ptxas /tmp/tmpxft_000001fe_00000000-8_reduce.compute_52.ptx, line 159; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_000001fe_00000000-8_reduce.compute_52.ptx, line 169; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_000001fe_00000000-8_reduce.compute_52.ptx, line 179; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_000001fe_00000000-8_reduce.compute_52.ptx, line 189; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_000001fe_00000000-8_reduce.compute_52.ptx, line 199; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_000001fe_00000000-8_reduce.compute_52.ptx, line 565; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_000001fe_00000000-8_reduce.compute_52.ptx, line 575; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_000001fe_00000000-8_reduce.compute_52.ptx, line 585; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_000001fe_00000000-8_reduce.compute_52.ptx, line 595; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_000001fe_00000000-8_reduce.compute_52.ptx, line 605; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_000001fe_00000000-8_reduce.compute_52.ptx, line 892; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_000001fe_00000000-8_reduce.compute_52.ptx, line 908; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_000001fe_00000000-8_reduce.compute_52.ptx, line 924; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_000001fe_00000000-8_reduce.compute_52.ptx, line 940; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_000001fe_00000000-8_reduce.compute_52.ptx, line 956; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "/content/warp-ctc-pytorch/warpctc/core/src/reduce.cu(44): warning: function \"__shfl_down(float, unsigned int, int)\"\n",
            "/usr/local/cuda/include/sm_30_intrinsics.hpp(275): here was declared deprecated (\"__shfl_down() is deprecated in favor of __shfl_down_sync() and may be removed in a future release (Use -Wno-deprecated-declarations to suppress this warning).\")\n",
            "          detected during:\n",
            "            instantiation of \"T CTAReduce<NT, T, Rop>::reduce(int, T, CTAReduce<NT, T, Rop>::Storage &, int, Rop) [with NT=128, T=float, Rop=ctc_helper::add<float, float>]\" \n",
            "(76): here\n",
            "            instantiation of \"void reduce_rows<NT,Iop,Rop,T>(Iop, Rop, const T *, T *, int, int) [with NT=128, Iop=ctc_helper::negate<float, float>, Rop=ctc_helper::add<float, float>, T=float]\" \n",
            "(124): here\n",
            "            instantiation of \"void ReduceHelper::impl(Iof, Rof, const T *, T *, int, int, __nv_bool, cudaStream_t) [with T=float, Iof=ctc_helper::negate<float, float>, Rof=ctc_helper::add<float, float>]\" \n",
            "(139): here\n",
            "            instantiation of \"ctcStatus_t reduce(Iof, Rof, const T *, T *, int, int, __nv_bool, cudaStream_t) [with T=float, Iof=ctc_helper::negate<float, float>, Rof=ctc_helper::add<float, float>]\" \n",
            "(149): here\n",
            "\n",
            "/content/warp-ctc-pytorch/warpctc/core/src/reduce.cu(44): warning: function \"__shfl_down(float, unsigned int, int)\"\n",
            "/usr/local/cuda/include/sm_30_intrinsics.hpp(275): here was declared deprecated (\"__shfl_down() is deprecated in favor of __shfl_down_sync() and may be removed in a future release (Use -Wno-deprecated-declarations to suppress this warning).\")\n",
            "          detected during:\n",
            "            instantiation of \"T CTAReduce<NT, T, Rop>::reduce(int, T, CTAReduce<NT, T, Rop>::Storage &, int, Rop) [with NT=128, T=float, Rop=ctc_helper::maximum<float, float>]\" \n",
            "(76): here\n",
            "            instantiation of \"void reduce_rows<NT,Iop,Rop,T>(Iop, Rop, const T *, T *, int, int) [with NT=128, Iop=ctc_helper::identity<float, float>, Rop=ctc_helper::maximum<float, float>, T=float]\" \n",
            "(124): here\n",
            "            instantiation of \"void ReduceHelper::impl(Iof, Rof, const T *, T *, int, int, __nv_bool, cudaStream_t) [with T=float, Iof=ctc_helper::identity<float, float>, Rof=ctc_helper::maximum<float, float>]\" \n",
            "(139): here\n",
            "            instantiation of \"ctcStatus_t reduce(Iof, Rof, const T *, T *, int, int, __nv_bool, cudaStream_t) [with T=float, Iof=ctc_helper::identity<float, float>, Rof=ctc_helper::maximum<float, float>]\" \n",
            "(157): here\n",
            "\n",
            "ptxas /tmp/tmpxft_000001fe_00000000-7_reduce.compute_60.ptx, line 159; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_000001fe_00000000-7_reduce.compute_60.ptx, line 169; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_000001fe_00000000-7_reduce.compute_60.ptx, line 179; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_000001fe_00000000-7_reduce.compute_60.ptx, line 189; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_000001fe_00000000-7_reduce.compute_60.ptx, line 199; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_000001fe_00000000-7_reduce.compute_60.ptx, line 565; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_000001fe_00000000-7_reduce.compute_60.ptx, line 575; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_000001fe_00000000-7_reduce.compute_60.ptx, line 585; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_000001fe_00000000-7_reduce.compute_60.ptx, line 595; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_000001fe_00000000-7_reduce.compute_60.ptx, line 605; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_000001fe_00000000-7_reduce.compute_60.ptx, line 892; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_000001fe_00000000-7_reduce.compute_60.ptx, line 908; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_000001fe_00000000-7_reduce.compute_60.ptx, line 924; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_000001fe_00000000-7_reduce.compute_60.ptx, line 940; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_000001fe_00000000-7_reduce.compute_60.ptx, line 956; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "/content/warp-ctc-pytorch/warpctc/core/src/reduce.cu(44): warning: function \"__shfl_down(float, unsigned int, int)\"\n",
            "/usr/local/cuda/include/sm_30_intrinsics.hpp(275): here was declared deprecated (\"__shfl_down() is deprecated in favor of __shfl_down_sync() and may be removed in a future release (Use -Wno-deprecated-declarations to suppress this warning).\")\n",
            "          detected during:\n",
            "            instantiation of \"T CTAReduce<NT, T, Rop>::reduce(int, T, CTAReduce<NT, T, Rop>::Storage &, int, Rop) [with NT=128, T=float, Rop=ctc_helper::add<float, float>]\" \n",
            "(76): here\n",
            "            instantiation of \"void reduce_rows<NT,Iop,Rop,T>(Iop, Rop, const T *, T *, int, int) [with NT=128, Iop=ctc_helper::negate<float, float>, Rop=ctc_helper::add<float, float>, T=float]\" \n",
            "(124): here\n",
            "            instantiation of \"void ReduceHelper::impl(Iof, Rof, const T *, T *, int, int, __nv_bool, cudaStream_t) [with T=float, Iof=ctc_helper::negate<float, float>, Rof=ctc_helper::add<float, float>]\" \n",
            "(139): here\n",
            "            instantiation of \"ctcStatus_t reduce(Iof, Rof, const T *, T *, int, int, __nv_bool, cudaStream_t) [with T=float, Iof=ctc_helper::negate<float, float>, Rof=ctc_helper::add<float, float>]\" \n",
            "(149): here\n",
            "\n",
            "/content/warp-ctc-pytorch/warpctc/core/src/reduce.cu(44): warning: function \"__shfl_down(float, unsigned int, int)\"\n",
            "/usr/local/cuda/include/sm_30_intrinsics.hpp(275): here was declared deprecated (\"__shfl_down() is deprecated in favor of __shfl_down_sync() and may be removed in a future release (Use -Wno-deprecated-declarations to suppress this warning).\")\n",
            "          detected during:\n",
            "            instantiation of \"T CTAReduce<NT, T, Rop>::reduce(int, T, CTAReduce<NT, T, Rop>::Storage &, int, Rop) [with NT=128, T=float, Rop=ctc_helper::maximum<float, float>]\" \n",
            "(76): here\n",
            "            instantiation of \"void reduce_rows<NT,Iop,Rop,T>(Iop, Rop, const T *, T *, int, int) [with NT=128, Iop=ctc_helper::identity<float, float>, Rop=ctc_helper::maximum<float, float>, T=float]\" \n",
            "(124): here\n",
            "            instantiation of \"void ReduceHelper::impl(Iof, Rof, const T *, T *, int, int, __nv_bool, cudaStream_t) [with T=float, Iof=ctc_helper::identity<float, float>, Rof=ctc_helper::maximum<float, float>]\" \n",
            "(139): here\n",
            "            instantiation of \"ctcStatus_t reduce(Iof, Rof, const T *, T *, int, int, __nv_bool, cudaStream_t) [with T=float, Iof=ctc_helper::identity<float, float>, Rof=ctc_helper::maximum<float, float>]\" \n",
            "(157): here\n",
            "\n",
            "ptxas /tmp/tmpxft_000001fe_00000000-6_reduce.compute_61.ptx, line 159; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_000001fe_00000000-6_reduce.compute_61.ptx, line 169; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_000001fe_00000000-6_reduce.compute_61.ptx, line 179; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_000001fe_00000000-6_reduce.compute_61.ptx, line 189; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_000001fe_00000000-6_reduce.compute_61.ptx, line 199; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_000001fe_00000000-6_reduce.compute_61.ptx, line 565; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_000001fe_00000000-6_reduce.compute_61.ptx, line 575; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_000001fe_00000000-6_reduce.compute_61.ptx, line 585; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_000001fe_00000000-6_reduce.compute_61.ptx, line 595; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_000001fe_00000000-6_reduce.compute_61.ptx, line 605; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_000001fe_00000000-6_reduce.compute_61.ptx, line 892; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_000001fe_00000000-6_reduce.compute_61.ptx, line 908; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_000001fe_00000000-6_reduce.compute_61.ptx, line 924; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_000001fe_00000000-6_reduce.compute_61.ptx, line 940; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_000001fe_00000000-6_reduce.compute_61.ptx, line 956; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_000001fe_00000000-5_reduce.compute_62.ptx, line 159; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_000001fe_00000000-5_reduce.compute_62.ptx, line 169; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_000001fe_00000000-5_reduce.compute_62.ptx, line 179; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_000001fe_00000000-5_reduce.compute_62.ptx, line 189; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_000001fe_00000000-5_reduce.compute_62.ptx, line 199; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_000001fe_00000000-5_reduce.compute_62.ptx, line 565; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_000001fe_00000000-5_reduce.compute_62.ptx, line 575; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_000001fe_00000000-5_reduce.compute_62.ptx, line 585; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_000001fe_00000000-5_reduce.compute_62.ptx, line 595; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_000001fe_00000000-5_reduce.compute_62.ptx, line 605; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_000001fe_00000000-5_reduce.compute_62.ptx, line 892; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_000001fe_00000000-5_reduce.compute_62.ptx, line 908; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_000001fe_00000000-5_reduce.compute_62.ptx, line 924; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_000001fe_00000000-5_reduce.compute_62.ptx, line 940; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_000001fe_00000000-5_reduce.compute_62.ptx, line 956; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "/content/warp-ctc-pytorch/warpctc/core/include/contrib/moderngpu/include/device/intrinsics.cuh(115): warning: function \"__shfl_up(float, unsigned int, int)\"\n",
            "/usr/local/cuda/include/sm_30_intrinsics.hpp(258): here was declared deprecated (\"__shfl_up() is deprecated in favor of __shfl_up_sync() and may be removed in a future release (Use -Wno-deprecated-declarations to suppress this warning).\")\n",
            "\n",
            "/content/warp-ctc-pytorch/warpctc/core/include/contrib/moderngpu/include/device/intrinsics.cuh(125): warning: function \"__shfl_up(int, unsigned int, int)\"\n",
            "/usr/local/cuda/include/sm_30_intrinsics.hpp(172): here was declared deprecated (\"__shfl_up() is deprecated in favor of __shfl_up_sync() and may be removed in a future release (Use -Wno-deprecated-declarations to suppress this warning).\")\n",
            "\n",
            "/content/warp-ctc-pytorch/warpctc/core/include/contrib/moderngpu/include/device/intrinsics.cuh(126): warning: function \"__shfl_up(int, unsigned int, int)\"\n",
            "/usr/local/cuda/include/sm_30_intrinsics.hpp(172): here was declared deprecated (\"__shfl_up() is deprecated in favor of __shfl_up_sync() and may be removed in a future release (Use -Wno-deprecated-declarations to suppress this warning).\")\n",
            "\n",
            "ptxas /tmp/tmpxft_00000212_00000000-11_ctc_entrypoint.compute_30.ptx, line 1903; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-11_ctc_entrypoint.compute_30.ptx, line 1907; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-11_ctc_entrypoint.compute_30.ptx, line 1911; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-11_ctc_entrypoint.compute_30.ptx, line 1915; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-11_ctc_entrypoint.compute_30.ptx, line 1919; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-11_ctc_entrypoint.compute_30.ptx, line 5697; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-11_ctc_entrypoint.compute_30.ptx, line 5721; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-11_ctc_entrypoint.compute_30.ptx, line 5725; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-11_ctc_entrypoint.compute_30.ptx, line 5729; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-11_ctc_entrypoint.compute_30.ptx, line 5733; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-11_ctc_entrypoint.compute_30.ptx, line 5737; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-11_ctc_entrypoint.compute_30.ptx, line 9580; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-11_ctc_entrypoint.compute_30.ptx, line 9584; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-11_ctc_entrypoint.compute_30.ptx, line 9606; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-11_ctc_entrypoint.compute_30.ptx, line 9609; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-11_ctc_entrypoint.compute_30.ptx, line 9613; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-11_ctc_entrypoint.compute_30.ptx, line 9617; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-11_ctc_entrypoint.compute_30.ptx, line 9621; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-11_ctc_entrypoint.compute_30.ptx, line 13856; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-11_ctc_entrypoint.compute_30.ptx, line 13881; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-11_ctc_entrypoint.compute_30.ptx, line 13885; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-11_ctc_entrypoint.compute_30.ptx, line 13889; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-11_ctc_entrypoint.compute_30.ptx, line 13893; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-11_ctc_entrypoint.compute_30.ptx, line 13897; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-11_ctc_entrypoint.compute_30.ptx, line 18012; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-11_ctc_entrypoint.compute_30.ptx, line 18016; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-11_ctc_entrypoint.compute_30.ptx, line 18040; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-11_ctc_entrypoint.compute_30.ptx, line 18043; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-11_ctc_entrypoint.compute_30.ptx, line 18047; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-11_ctc_entrypoint.compute_30.ptx, line 18051; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-11_ctc_entrypoint.compute_30.ptx, line 18055; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-11_ctc_entrypoint.compute_30.ptx, line 23584; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-11_ctc_entrypoint.compute_30.ptx, line 23588; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-11_ctc_entrypoint.compute_30.ptx, line 23592; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-11_ctc_entrypoint.compute_30.ptx, line 23596; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-11_ctc_entrypoint.compute_30.ptx, line 23600; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-11_ctc_entrypoint.compute_30.ptx, line 28681; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-11_ctc_entrypoint.compute_30.ptx, line 28706; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-11_ctc_entrypoint.compute_30.ptx, line 28710; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-11_ctc_entrypoint.compute_30.ptx, line 28714; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-11_ctc_entrypoint.compute_30.ptx, line 28718; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-11_ctc_entrypoint.compute_30.ptx, line 28722; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-11_ctc_entrypoint.compute_30.ptx, line 33418; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-11_ctc_entrypoint.compute_30.ptx, line 33422; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-11_ctc_entrypoint.compute_30.ptx, line 33445; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-11_ctc_entrypoint.compute_30.ptx, line 33448; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-11_ctc_entrypoint.compute_30.ptx, line 33452; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-11_ctc_entrypoint.compute_30.ptx, line 33456; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-11_ctc_entrypoint.compute_30.ptx, line 33460; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-11_ctc_entrypoint.compute_30.ptx, line 39361; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-11_ctc_entrypoint.compute_30.ptx, line 39386; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-11_ctc_entrypoint.compute_30.ptx, line 39390; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-11_ctc_entrypoint.compute_30.ptx, line 39394; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-11_ctc_entrypoint.compute_30.ptx, line 39398; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-11_ctc_entrypoint.compute_30.ptx, line 39402; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-11_ctc_entrypoint.compute_30.ptx, line 44712; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-11_ctc_entrypoint.compute_30.ptx, line 44716; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-11_ctc_entrypoint.compute_30.ptx, line 44739; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-11_ctc_entrypoint.compute_30.ptx, line 44742; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-11_ctc_entrypoint.compute_30.ptx, line 44746; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-11_ctc_entrypoint.compute_30.ptx, line 44750; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-11_ctc_entrypoint.compute_30.ptx, line 44754; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-11_ctc_entrypoint.compute_30.ptx, line 51025; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-11_ctc_entrypoint.compute_30.ptx, line 51029; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-11_ctc_entrypoint.compute_30.ptx, line 51052; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-11_ctc_entrypoint.compute_30.ptx, line 51055; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-11_ctc_entrypoint.compute_30.ptx, line 51059; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-11_ctc_entrypoint.compute_30.ptx, line 51063; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-11_ctc_entrypoint.compute_30.ptx, line 51067; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-11_ctc_entrypoint.compute_30.ptx, line 57735; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-11_ctc_entrypoint.compute_30.ptx, line 57739; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-11_ctc_entrypoint.compute_30.ptx, line 57762; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-11_ctc_entrypoint.compute_30.ptx, line 57765; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-11_ctc_entrypoint.compute_30.ptx, line 57769; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-11_ctc_entrypoint.compute_30.ptx, line 57773; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-11_ctc_entrypoint.compute_30.ptx, line 57777; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "/content/warp-ctc-pytorch/warpctc/core/include/contrib/moderngpu/include/device/intrinsics.cuh(115): warning: function \"__shfl_up(float, unsigned int, int)\"\n",
            "/usr/local/cuda/include/sm_30_intrinsics.hpp(258): here was declared deprecated (\"__shfl_up() is deprecated in favor of __shfl_up_sync() and may be removed in a future release (Use -Wno-deprecated-declarations to suppress this warning).\")\n",
            "\n",
            "/content/warp-ctc-pytorch/warpctc/core/include/contrib/moderngpu/include/device/intrinsics.cuh(125): warning: function \"__shfl_up(int, unsigned int, int)\"\n",
            "/usr/local/cuda/include/sm_30_intrinsics.hpp(172): here was declared deprecated (\"__shfl_up() is deprecated in favor of __shfl_up_sync() and may be removed in a future release (Use -Wno-deprecated-declarations to suppress this warning).\")\n",
            "\n",
            "/content/warp-ctc-pytorch/warpctc/core/include/contrib/moderngpu/include/device/intrinsics.cuh(126): warning: function \"__shfl_up(int, unsigned int, int)\"\n",
            "/usr/local/cuda/include/sm_30_intrinsics.hpp(172): here was declared deprecated (\"__shfl_up() is deprecated in favor of __shfl_up_sync() and may be removed in a future release (Use -Wno-deprecated-declarations to suppress this warning).\")\n",
            "\n",
            "ptxas /tmp/tmpxft_00000212_00000000-10_ctc_entrypoint.compute_35.ptx, line 1880; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-10_ctc_entrypoint.compute_35.ptx, line 1884; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-10_ctc_entrypoint.compute_35.ptx, line 1888; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-10_ctc_entrypoint.compute_35.ptx, line 1892; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-10_ctc_entrypoint.compute_35.ptx, line 1896; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-10_ctc_entrypoint.compute_35.ptx, line 5613; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-10_ctc_entrypoint.compute_35.ptx, line 5635; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-10_ctc_entrypoint.compute_35.ptx, line 5639; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-10_ctc_entrypoint.compute_35.ptx, line 5643; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-10_ctc_entrypoint.compute_35.ptx, line 5647; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-10_ctc_entrypoint.compute_35.ptx, line 5651; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-10_ctc_entrypoint.compute_35.ptx, line 9433; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-10_ctc_entrypoint.compute_35.ptx, line 9437; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-10_ctc_entrypoint.compute_35.ptx, line 9459; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-10_ctc_entrypoint.compute_35.ptx, line 9462; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-10_ctc_entrypoint.compute_35.ptx, line 9466; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-10_ctc_entrypoint.compute_35.ptx, line 9470; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-10_ctc_entrypoint.compute_35.ptx, line 9474; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-10_ctc_entrypoint.compute_35.ptx, line 13643; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-10_ctc_entrypoint.compute_35.ptx, line 13666; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-10_ctc_entrypoint.compute_35.ptx, line 13670; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-10_ctc_entrypoint.compute_35.ptx, line 13674; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-10_ctc_entrypoint.compute_35.ptx, line 13678; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-10_ctc_entrypoint.compute_35.ptx, line 13682; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-10_ctc_entrypoint.compute_35.ptx, line 17736; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-10_ctc_entrypoint.compute_35.ptx, line 17740; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-10_ctc_entrypoint.compute_35.ptx, line 17763; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-10_ctc_entrypoint.compute_35.ptx, line 17766; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-10_ctc_entrypoint.compute_35.ptx, line 17770; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-10_ctc_entrypoint.compute_35.ptx, line 17774; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-10_ctc_entrypoint.compute_35.ptx, line 17778; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-10_ctc_entrypoint.compute_35.ptx, line 23224; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-10_ctc_entrypoint.compute_35.ptx, line 23228; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-10_ctc_entrypoint.compute_35.ptx, line 23232; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-10_ctc_entrypoint.compute_35.ptx, line 23236; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-10_ctc_entrypoint.compute_35.ptx, line 23240; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-10_ctc_entrypoint.compute_35.ptx, line 28288; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-10_ctc_entrypoint.compute_35.ptx, line 28311; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-10_ctc_entrypoint.compute_35.ptx, line 28315; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-10_ctc_entrypoint.compute_35.ptx, line 28319; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-10_ctc_entrypoint.compute_35.ptx, line 28323; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-10_ctc_entrypoint.compute_35.ptx, line 28327; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-10_ctc_entrypoint.compute_35.ptx, line 32977; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-10_ctc_entrypoint.compute_35.ptx, line 32981; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-10_ctc_entrypoint.compute_35.ptx, line 33003; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-10_ctc_entrypoint.compute_35.ptx, line 33006; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-10_ctc_entrypoint.compute_35.ptx, line 33010; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-10_ctc_entrypoint.compute_35.ptx, line 33014; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-10_ctc_entrypoint.compute_35.ptx, line 33018; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-10_ctc_entrypoint.compute_35.ptx, line 38835; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-10_ctc_entrypoint.compute_35.ptx, line 38858; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-10_ctc_entrypoint.compute_35.ptx, line 38862; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-10_ctc_entrypoint.compute_35.ptx, line 38866; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-10_ctc_entrypoint.compute_35.ptx, line 38870; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-10_ctc_entrypoint.compute_35.ptx, line 38874; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-10_ctc_entrypoint.compute_35.ptx, line 44150; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-10_ctc_entrypoint.compute_35.ptx, line 44154; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-10_ctc_entrypoint.compute_35.ptx, line 44177; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-10_ctc_entrypoint.compute_35.ptx, line 44180; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-10_ctc_entrypoint.compute_35.ptx, line 44184; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-10_ctc_entrypoint.compute_35.ptx, line 44188; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-10_ctc_entrypoint.compute_35.ptx, line 44192; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-10_ctc_entrypoint.compute_35.ptx, line 50393; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-10_ctc_entrypoint.compute_35.ptx, line 50397; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-10_ctc_entrypoint.compute_35.ptx, line 50420; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-10_ctc_entrypoint.compute_35.ptx, line 50423; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-10_ctc_entrypoint.compute_35.ptx, line 50427; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-10_ctc_entrypoint.compute_35.ptx, line 50431; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-10_ctc_entrypoint.compute_35.ptx, line 50435; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-10_ctc_entrypoint.compute_35.ptx, line 57006; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-10_ctc_entrypoint.compute_35.ptx, line 57010; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-10_ctc_entrypoint.compute_35.ptx, line 57033; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-10_ctc_entrypoint.compute_35.ptx, line 57036; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-10_ctc_entrypoint.compute_35.ptx, line 57040; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-10_ctc_entrypoint.compute_35.ptx, line 57044; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-10_ctc_entrypoint.compute_35.ptx, line 57048; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "/content/warp-ctc-pytorch/warpctc/core/include/contrib/moderngpu/include/device/intrinsics.cuh(115): warning: function \"__shfl_up(float, unsigned int, int)\"\n",
            "/usr/local/cuda/include/sm_30_intrinsics.hpp(258): here was declared deprecated (\"__shfl_up() is deprecated in favor of __shfl_up_sync() and may be removed in a future release (Use -Wno-deprecated-declarations to suppress this warning).\")\n",
            "\n",
            "/content/warp-ctc-pytorch/warpctc/core/include/contrib/moderngpu/include/device/intrinsics.cuh(125): warning: function \"__shfl_up(int, unsigned int, int)\"\n",
            "/usr/local/cuda/include/sm_30_intrinsics.hpp(172): here was declared deprecated (\"__shfl_up() is deprecated in favor of __shfl_up_sync() and may be removed in a future release (Use -Wno-deprecated-declarations to suppress this warning).\")\n",
            "\n",
            "/content/warp-ctc-pytorch/warpctc/core/include/contrib/moderngpu/include/device/intrinsics.cuh(126): warning: function \"__shfl_up(int, unsigned int, int)\"\n",
            "/usr/local/cuda/include/sm_30_intrinsics.hpp(172): here was declared deprecated (\"__shfl_up() is deprecated in favor of __shfl_up_sync() and may be removed in a future release (Use -Wno-deprecated-declarations to suppress this warning).\")\n",
            "\n",
            "ptxas /tmp/tmpxft_00000212_00000000-9_ctc_entrypoint.compute_50.ptx, line 1880; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-9_ctc_entrypoint.compute_50.ptx, line 1884; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-9_ctc_entrypoint.compute_50.ptx, line 1888; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-9_ctc_entrypoint.compute_50.ptx, line 1892; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-9_ctc_entrypoint.compute_50.ptx, line 1896; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-9_ctc_entrypoint.compute_50.ptx, line 5613; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-9_ctc_entrypoint.compute_50.ptx, line 5635; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-9_ctc_entrypoint.compute_50.ptx, line 5639; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-9_ctc_entrypoint.compute_50.ptx, line 5643; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-9_ctc_entrypoint.compute_50.ptx, line 5647; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-9_ctc_entrypoint.compute_50.ptx, line 5651; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-9_ctc_entrypoint.compute_50.ptx, line 9433; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-9_ctc_entrypoint.compute_50.ptx, line 9437; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-9_ctc_entrypoint.compute_50.ptx, line 9459; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-9_ctc_entrypoint.compute_50.ptx, line 9462; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-9_ctc_entrypoint.compute_50.ptx, line 9466; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-9_ctc_entrypoint.compute_50.ptx, line 9470; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-9_ctc_entrypoint.compute_50.ptx, line 9474; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-9_ctc_entrypoint.compute_50.ptx, line 13643; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-9_ctc_entrypoint.compute_50.ptx, line 13666; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-9_ctc_entrypoint.compute_50.ptx, line 13670; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-9_ctc_entrypoint.compute_50.ptx, line 13674; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-9_ctc_entrypoint.compute_50.ptx, line 13678; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-9_ctc_entrypoint.compute_50.ptx, line 13682; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-9_ctc_entrypoint.compute_50.ptx, line 17736; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-9_ctc_entrypoint.compute_50.ptx, line 17740; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-9_ctc_entrypoint.compute_50.ptx, line 17763; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-9_ctc_entrypoint.compute_50.ptx, line 17766; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-9_ctc_entrypoint.compute_50.ptx, line 17770; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-9_ctc_entrypoint.compute_50.ptx, line 17774; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-9_ctc_entrypoint.compute_50.ptx, line 17778; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-9_ctc_entrypoint.compute_50.ptx, line 23224; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-9_ctc_entrypoint.compute_50.ptx, line 23228; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-9_ctc_entrypoint.compute_50.ptx, line 23232; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-9_ctc_entrypoint.compute_50.ptx, line 23236; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-9_ctc_entrypoint.compute_50.ptx, line 23240; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-9_ctc_entrypoint.compute_50.ptx, line 28288; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-9_ctc_entrypoint.compute_50.ptx, line 28311; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-9_ctc_entrypoint.compute_50.ptx, line 28315; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-9_ctc_entrypoint.compute_50.ptx, line 28319; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-9_ctc_entrypoint.compute_50.ptx, line 28323; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-9_ctc_entrypoint.compute_50.ptx, line 28327; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-9_ctc_entrypoint.compute_50.ptx, line 32977; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-9_ctc_entrypoint.compute_50.ptx, line 32981; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-9_ctc_entrypoint.compute_50.ptx, line 33003; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-9_ctc_entrypoint.compute_50.ptx, line 33006; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-9_ctc_entrypoint.compute_50.ptx, line 33010; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-9_ctc_entrypoint.compute_50.ptx, line 33014; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-9_ctc_entrypoint.compute_50.ptx, line 33018; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-9_ctc_entrypoint.compute_50.ptx, line 38835; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-9_ctc_entrypoint.compute_50.ptx, line 38858; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-9_ctc_entrypoint.compute_50.ptx, line 38862; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-9_ctc_entrypoint.compute_50.ptx, line 38866; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-9_ctc_entrypoint.compute_50.ptx, line 38870; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-9_ctc_entrypoint.compute_50.ptx, line 38874; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-9_ctc_entrypoint.compute_50.ptx, line 44150; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-9_ctc_entrypoint.compute_50.ptx, line 44154; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-9_ctc_entrypoint.compute_50.ptx, line 44177; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-9_ctc_entrypoint.compute_50.ptx, line 44180; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-9_ctc_entrypoint.compute_50.ptx, line 44184; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-9_ctc_entrypoint.compute_50.ptx, line 44188; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-9_ctc_entrypoint.compute_50.ptx, line 44192; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-9_ctc_entrypoint.compute_50.ptx, line 50393; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-9_ctc_entrypoint.compute_50.ptx, line 50397; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-9_ctc_entrypoint.compute_50.ptx, line 50420; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-9_ctc_entrypoint.compute_50.ptx, line 50423; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-9_ctc_entrypoint.compute_50.ptx, line 50427; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-9_ctc_entrypoint.compute_50.ptx, line 50431; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-9_ctc_entrypoint.compute_50.ptx, line 50435; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-9_ctc_entrypoint.compute_50.ptx, line 57006; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-9_ctc_entrypoint.compute_50.ptx, line 57010; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-9_ctc_entrypoint.compute_50.ptx, line 57033; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-9_ctc_entrypoint.compute_50.ptx, line 57036; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-9_ctc_entrypoint.compute_50.ptx, line 57040; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-9_ctc_entrypoint.compute_50.ptx, line 57044; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-9_ctc_entrypoint.compute_50.ptx, line 57048; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "/content/warp-ctc-pytorch/warpctc/core/include/contrib/moderngpu/include/device/intrinsics.cuh(115): warning: function \"__shfl_up(float, unsigned int, int)\"\n",
            "/usr/local/cuda/include/sm_30_intrinsics.hpp(258): here was declared deprecated (\"__shfl_up() is deprecated in favor of __shfl_up_sync() and may be removed in a future release (Use -Wno-deprecated-declarations to suppress this warning).\")\n",
            "\n",
            "/content/warp-ctc-pytorch/warpctc/core/include/contrib/moderngpu/include/device/intrinsics.cuh(125): warning: function \"__shfl_up(int, unsigned int, int)\"\n",
            "/usr/local/cuda/include/sm_30_intrinsics.hpp(172): here was declared deprecated (\"__shfl_up() is deprecated in favor of __shfl_up_sync() and may be removed in a future release (Use -Wno-deprecated-declarations to suppress this warning).\")\n",
            "\n",
            "/content/warp-ctc-pytorch/warpctc/core/include/contrib/moderngpu/include/device/intrinsics.cuh(126): warning: function \"__shfl_up(int, unsigned int, int)\"\n",
            "/usr/local/cuda/include/sm_30_intrinsics.hpp(172): here was declared deprecated (\"__shfl_up() is deprecated in favor of __shfl_up_sync() and may be removed in a future release (Use -Wno-deprecated-declarations to suppress this warning).\")\n",
            "\n",
            "ptxas /tmp/tmpxft_00000212_00000000-8_ctc_entrypoint.compute_52.ptx, line 1880; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-8_ctc_entrypoint.compute_52.ptx, line 1884; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-8_ctc_entrypoint.compute_52.ptx, line 1888; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-8_ctc_entrypoint.compute_52.ptx, line 1892; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-8_ctc_entrypoint.compute_52.ptx, line 1896; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-8_ctc_entrypoint.compute_52.ptx, line 5613; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-8_ctc_entrypoint.compute_52.ptx, line 5635; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-8_ctc_entrypoint.compute_52.ptx, line 5639; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-8_ctc_entrypoint.compute_52.ptx, line 5643; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-8_ctc_entrypoint.compute_52.ptx, line 5647; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-8_ctc_entrypoint.compute_52.ptx, line 5651; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-8_ctc_entrypoint.compute_52.ptx, line 9433; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-8_ctc_entrypoint.compute_52.ptx, line 9437; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-8_ctc_entrypoint.compute_52.ptx, line 9459; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-8_ctc_entrypoint.compute_52.ptx, line 9462; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-8_ctc_entrypoint.compute_52.ptx, line 9466; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-8_ctc_entrypoint.compute_52.ptx, line 9470; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-8_ctc_entrypoint.compute_52.ptx, line 9474; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-8_ctc_entrypoint.compute_52.ptx, line 13643; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-8_ctc_entrypoint.compute_52.ptx, line 13666; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-8_ctc_entrypoint.compute_52.ptx, line 13670; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-8_ctc_entrypoint.compute_52.ptx, line 13674; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-8_ctc_entrypoint.compute_52.ptx, line 13678; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-8_ctc_entrypoint.compute_52.ptx, line 13682; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-8_ctc_entrypoint.compute_52.ptx, line 17736; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-8_ctc_entrypoint.compute_52.ptx, line 17740; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-8_ctc_entrypoint.compute_52.ptx, line 17763; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-8_ctc_entrypoint.compute_52.ptx, line 17766; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-8_ctc_entrypoint.compute_52.ptx, line 17770; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-8_ctc_entrypoint.compute_52.ptx, line 17774; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-8_ctc_entrypoint.compute_52.ptx, line 17778; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-8_ctc_entrypoint.compute_52.ptx, line 23224; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-8_ctc_entrypoint.compute_52.ptx, line 23228; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-8_ctc_entrypoint.compute_52.ptx, line 23232; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-8_ctc_entrypoint.compute_52.ptx, line 23236; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-8_ctc_entrypoint.compute_52.ptx, line 23240; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-8_ctc_entrypoint.compute_52.ptx, line 28288; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-8_ctc_entrypoint.compute_52.ptx, line 28311; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-8_ctc_entrypoint.compute_52.ptx, line 28315; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-8_ctc_entrypoint.compute_52.ptx, line 28319; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-8_ctc_entrypoint.compute_52.ptx, line 28323; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-8_ctc_entrypoint.compute_52.ptx, line 28327; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-8_ctc_entrypoint.compute_52.ptx, line 32977; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-8_ctc_entrypoint.compute_52.ptx, line 32981; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-8_ctc_entrypoint.compute_52.ptx, line 33003; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-8_ctc_entrypoint.compute_52.ptx, line 33006; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-8_ctc_entrypoint.compute_52.ptx, line 33010; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-8_ctc_entrypoint.compute_52.ptx, line 33014; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-8_ctc_entrypoint.compute_52.ptx, line 33018; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-8_ctc_entrypoint.compute_52.ptx, line 38835; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-8_ctc_entrypoint.compute_52.ptx, line 38858; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-8_ctc_entrypoint.compute_52.ptx, line 38862; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-8_ctc_entrypoint.compute_52.ptx, line 38866; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-8_ctc_entrypoint.compute_52.ptx, line 38870; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-8_ctc_entrypoint.compute_52.ptx, line 38874; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-8_ctc_entrypoint.compute_52.ptx, line 44150; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-8_ctc_entrypoint.compute_52.ptx, line 44154; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-8_ctc_entrypoint.compute_52.ptx, line 44177; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-8_ctc_entrypoint.compute_52.ptx, line 44180; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-8_ctc_entrypoint.compute_52.ptx, line 44184; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-8_ctc_entrypoint.compute_52.ptx, line 44188; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-8_ctc_entrypoint.compute_52.ptx, line 44192; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-8_ctc_entrypoint.compute_52.ptx, line 50393; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-8_ctc_entrypoint.compute_52.ptx, line 50397; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-8_ctc_entrypoint.compute_52.ptx, line 50420; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-8_ctc_entrypoint.compute_52.ptx, line 50423; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-8_ctc_entrypoint.compute_52.ptx, line 50427; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-8_ctc_entrypoint.compute_52.ptx, line 50431; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-8_ctc_entrypoint.compute_52.ptx, line 50435; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-8_ctc_entrypoint.compute_52.ptx, line 57006; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-8_ctc_entrypoint.compute_52.ptx, line 57010; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-8_ctc_entrypoint.compute_52.ptx, line 57033; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-8_ctc_entrypoint.compute_52.ptx, line 57036; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-8_ctc_entrypoint.compute_52.ptx, line 57040; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-8_ctc_entrypoint.compute_52.ptx, line 57044; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-8_ctc_entrypoint.compute_52.ptx, line 57048; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "/content/warp-ctc-pytorch/warpctc/core/include/contrib/moderngpu/include/device/intrinsics.cuh(115): warning: function \"__shfl_up(float, unsigned int, int)\"\n",
            "/usr/local/cuda/include/sm_30_intrinsics.hpp(258): here was declared deprecated (\"__shfl_up() is deprecated in favor of __shfl_up_sync() and may be removed in a future release (Use -Wno-deprecated-declarations to suppress this warning).\")\n",
            "\n",
            "/content/warp-ctc-pytorch/warpctc/core/include/contrib/moderngpu/include/device/intrinsics.cuh(125): warning: function \"__shfl_up(int, unsigned int, int)\"\n",
            "/usr/local/cuda/include/sm_30_intrinsics.hpp(172): here was declared deprecated (\"__shfl_up() is deprecated in favor of __shfl_up_sync() and may be removed in a future release (Use -Wno-deprecated-declarations to suppress this warning).\")\n",
            "\n",
            "/content/warp-ctc-pytorch/warpctc/core/include/contrib/moderngpu/include/device/intrinsics.cuh(126): warning: function \"__shfl_up(int, unsigned int, int)\"\n",
            "/usr/local/cuda/include/sm_30_intrinsics.hpp(172): here was declared deprecated (\"__shfl_up() is deprecated in favor of __shfl_up_sync() and may be removed in a future release (Use -Wno-deprecated-declarations to suppress this warning).\")\n",
            "\n",
            "ptxas /tmp/tmpxft_00000212_00000000-7_ctc_entrypoint.compute_60.ptx, line 1880; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-7_ctc_entrypoint.compute_60.ptx, line 1884; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-7_ctc_entrypoint.compute_60.ptx, line 1888; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-7_ctc_entrypoint.compute_60.ptx, line 1892; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-7_ctc_entrypoint.compute_60.ptx, line 1896; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-7_ctc_entrypoint.compute_60.ptx, line 5613; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-7_ctc_entrypoint.compute_60.ptx, line 5635; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-7_ctc_entrypoint.compute_60.ptx, line 5639; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-7_ctc_entrypoint.compute_60.ptx, line 5643; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-7_ctc_entrypoint.compute_60.ptx, line 5647; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-7_ctc_entrypoint.compute_60.ptx, line 5651; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-7_ctc_entrypoint.compute_60.ptx, line 9433; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-7_ctc_entrypoint.compute_60.ptx, line 9437; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-7_ctc_entrypoint.compute_60.ptx, line 9459; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-7_ctc_entrypoint.compute_60.ptx, line 9462; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-7_ctc_entrypoint.compute_60.ptx, line 9466; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-7_ctc_entrypoint.compute_60.ptx, line 9470; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-7_ctc_entrypoint.compute_60.ptx, line 9474; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-7_ctc_entrypoint.compute_60.ptx, line 13643; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-7_ctc_entrypoint.compute_60.ptx, line 13666; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-7_ctc_entrypoint.compute_60.ptx, line 13670; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-7_ctc_entrypoint.compute_60.ptx, line 13674; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-7_ctc_entrypoint.compute_60.ptx, line 13678; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-7_ctc_entrypoint.compute_60.ptx, line 13682; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-7_ctc_entrypoint.compute_60.ptx, line 17736; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-7_ctc_entrypoint.compute_60.ptx, line 17740; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-7_ctc_entrypoint.compute_60.ptx, line 17763; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-7_ctc_entrypoint.compute_60.ptx, line 17766; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-7_ctc_entrypoint.compute_60.ptx, line 17770; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-7_ctc_entrypoint.compute_60.ptx, line 17774; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-7_ctc_entrypoint.compute_60.ptx, line 17778; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-7_ctc_entrypoint.compute_60.ptx, line 23224; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-7_ctc_entrypoint.compute_60.ptx, line 23228; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-7_ctc_entrypoint.compute_60.ptx, line 23232; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-7_ctc_entrypoint.compute_60.ptx, line 23236; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-7_ctc_entrypoint.compute_60.ptx, line 23240; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-7_ctc_entrypoint.compute_60.ptx, line 28288; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-7_ctc_entrypoint.compute_60.ptx, line 28311; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-7_ctc_entrypoint.compute_60.ptx, line 28315; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-7_ctc_entrypoint.compute_60.ptx, line 28319; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-7_ctc_entrypoint.compute_60.ptx, line 28323; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-7_ctc_entrypoint.compute_60.ptx, line 28327; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-7_ctc_entrypoint.compute_60.ptx, line 32977; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-7_ctc_entrypoint.compute_60.ptx, line 32981; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-7_ctc_entrypoint.compute_60.ptx, line 33003; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-7_ctc_entrypoint.compute_60.ptx, line 33006; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-7_ctc_entrypoint.compute_60.ptx, line 33010; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-7_ctc_entrypoint.compute_60.ptx, line 33014; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-7_ctc_entrypoint.compute_60.ptx, line 33018; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-7_ctc_entrypoint.compute_60.ptx, line 38835; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-7_ctc_entrypoint.compute_60.ptx, line 38858; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-7_ctc_entrypoint.compute_60.ptx, line 38862; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-7_ctc_entrypoint.compute_60.ptx, line 38866; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-7_ctc_entrypoint.compute_60.ptx, line 38870; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-7_ctc_entrypoint.compute_60.ptx, line 38874; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-7_ctc_entrypoint.compute_60.ptx, line 44150; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-7_ctc_entrypoint.compute_60.ptx, line 44154; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-7_ctc_entrypoint.compute_60.ptx, line 44177; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-7_ctc_entrypoint.compute_60.ptx, line 44180; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-7_ctc_entrypoint.compute_60.ptx, line 44184; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-7_ctc_entrypoint.compute_60.ptx, line 44188; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-7_ctc_entrypoint.compute_60.ptx, line 44192; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-7_ctc_entrypoint.compute_60.ptx, line 50393; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-7_ctc_entrypoint.compute_60.ptx, line 50397; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-7_ctc_entrypoint.compute_60.ptx, line 50420; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-7_ctc_entrypoint.compute_60.ptx, line 50423; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-7_ctc_entrypoint.compute_60.ptx, line 50427; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-7_ctc_entrypoint.compute_60.ptx, line 50431; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-7_ctc_entrypoint.compute_60.ptx, line 50435; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-7_ctc_entrypoint.compute_60.ptx, line 57006; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-7_ctc_entrypoint.compute_60.ptx, line 57010; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-7_ctc_entrypoint.compute_60.ptx, line 57033; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-7_ctc_entrypoint.compute_60.ptx, line 57036; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-7_ctc_entrypoint.compute_60.ptx, line 57040; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-7_ctc_entrypoint.compute_60.ptx, line 57044; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-7_ctc_entrypoint.compute_60.ptx, line 57048; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "/content/warp-ctc-pytorch/warpctc/core/include/contrib/moderngpu/include/device/intrinsics.cuh(115): warning: function \"__shfl_up(float, unsigned int, int)\"\n",
            "/usr/local/cuda/include/sm_30_intrinsics.hpp(258): here was declared deprecated (\"__shfl_up() is deprecated in favor of __shfl_up_sync() and may be removed in a future release (Use -Wno-deprecated-declarations to suppress this warning).\")\n",
            "\n",
            "/content/warp-ctc-pytorch/warpctc/core/include/contrib/moderngpu/include/device/intrinsics.cuh(125): warning: function \"__shfl_up(int, unsigned int, int)\"\n",
            "/usr/local/cuda/include/sm_30_intrinsics.hpp(172): here was declared deprecated (\"__shfl_up() is deprecated in favor of __shfl_up_sync() and may be removed in a future release (Use -Wno-deprecated-declarations to suppress this warning).\")\n",
            "\n",
            "/content/warp-ctc-pytorch/warpctc/core/include/contrib/moderngpu/include/device/intrinsics.cuh(126): warning: function \"__shfl_up(int, unsigned int, int)\"\n",
            "/usr/local/cuda/include/sm_30_intrinsics.hpp(172): here was declared deprecated (\"__shfl_up() is deprecated in favor of __shfl_up_sync() and may be removed in a future release (Use -Wno-deprecated-declarations to suppress this warning).\")\n",
            "\n",
            "ptxas /tmp/tmpxft_00000212_00000000-6_ctc_entrypoint.compute_61.ptx, line 1880; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-6_ctc_entrypoint.compute_61.ptx, line 1884; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-6_ctc_entrypoint.compute_61.ptx, line 1888; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-6_ctc_entrypoint.compute_61.ptx, line 1892; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-6_ctc_entrypoint.compute_61.ptx, line 1896; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-6_ctc_entrypoint.compute_61.ptx, line 5613; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-6_ctc_entrypoint.compute_61.ptx, line 5635; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-6_ctc_entrypoint.compute_61.ptx, line 5639; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-6_ctc_entrypoint.compute_61.ptx, line 5643; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-6_ctc_entrypoint.compute_61.ptx, line 5647; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-6_ctc_entrypoint.compute_61.ptx, line 5651; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-6_ctc_entrypoint.compute_61.ptx, line 9433; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-6_ctc_entrypoint.compute_61.ptx, line 9437; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-6_ctc_entrypoint.compute_61.ptx, line 9459; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-6_ctc_entrypoint.compute_61.ptx, line 9462; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-6_ctc_entrypoint.compute_61.ptx, line 9466; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-6_ctc_entrypoint.compute_61.ptx, line 9470; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-6_ctc_entrypoint.compute_61.ptx, line 9474; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-6_ctc_entrypoint.compute_61.ptx, line 13643; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-6_ctc_entrypoint.compute_61.ptx, line 13666; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-6_ctc_entrypoint.compute_61.ptx, line 13670; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-6_ctc_entrypoint.compute_61.ptx, line 13674; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-6_ctc_entrypoint.compute_61.ptx, line 13678; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-6_ctc_entrypoint.compute_61.ptx, line 13682; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-6_ctc_entrypoint.compute_61.ptx, line 17736; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-6_ctc_entrypoint.compute_61.ptx, line 17740; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-6_ctc_entrypoint.compute_61.ptx, line 17763; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-6_ctc_entrypoint.compute_61.ptx, line 17766; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-6_ctc_entrypoint.compute_61.ptx, line 17770; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-6_ctc_entrypoint.compute_61.ptx, line 17774; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-6_ctc_entrypoint.compute_61.ptx, line 17778; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-6_ctc_entrypoint.compute_61.ptx, line 23224; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-6_ctc_entrypoint.compute_61.ptx, line 23228; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-6_ctc_entrypoint.compute_61.ptx, line 23232; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-6_ctc_entrypoint.compute_61.ptx, line 23236; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-6_ctc_entrypoint.compute_61.ptx, line 23240; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-6_ctc_entrypoint.compute_61.ptx, line 28288; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-6_ctc_entrypoint.compute_61.ptx, line 28311; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-6_ctc_entrypoint.compute_61.ptx, line 28315; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-6_ctc_entrypoint.compute_61.ptx, line 28319; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-6_ctc_entrypoint.compute_61.ptx, line 28323; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-6_ctc_entrypoint.compute_61.ptx, line 28327; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-6_ctc_entrypoint.compute_61.ptx, line 32977; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-6_ctc_entrypoint.compute_61.ptx, line 32981; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-6_ctc_entrypoint.compute_61.ptx, line 33003; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-6_ctc_entrypoint.compute_61.ptx, line 33006; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-6_ctc_entrypoint.compute_61.ptx, line 33010; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-6_ctc_entrypoint.compute_61.ptx, line 33014; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-6_ctc_entrypoint.compute_61.ptx, line 33018; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-6_ctc_entrypoint.compute_61.ptx, line 38835; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-6_ctc_entrypoint.compute_61.ptx, line 38858; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-6_ctc_entrypoint.compute_61.ptx, line 38862; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-6_ctc_entrypoint.compute_61.ptx, line 38866; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-6_ctc_entrypoint.compute_61.ptx, line 38870; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-6_ctc_entrypoint.compute_61.ptx, line 38874; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-6_ctc_entrypoint.compute_61.ptx, line 44150; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-6_ctc_entrypoint.compute_61.ptx, line 44154; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-6_ctc_entrypoint.compute_61.ptx, line 44177; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-6_ctc_entrypoint.compute_61.ptx, line 44180; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-6_ctc_entrypoint.compute_61.ptx, line 44184; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-6_ctc_entrypoint.compute_61.ptx, line 44188; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-6_ctc_entrypoint.compute_61.ptx, line 44192; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-6_ctc_entrypoint.compute_61.ptx, line 50393; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-6_ctc_entrypoint.compute_61.ptx, line 50397; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-6_ctc_entrypoint.compute_61.ptx, line 50420; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-6_ctc_entrypoint.compute_61.ptx, line 50423; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-6_ctc_entrypoint.compute_61.ptx, line 50427; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-6_ctc_entrypoint.compute_61.ptx, line 50431; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-6_ctc_entrypoint.compute_61.ptx, line 50435; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-6_ctc_entrypoint.compute_61.ptx, line 57006; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-6_ctc_entrypoint.compute_61.ptx, line 57010; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-6_ctc_entrypoint.compute_61.ptx, line 57033; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-6_ctc_entrypoint.compute_61.ptx, line 57036; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-6_ctc_entrypoint.compute_61.ptx, line 57040; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-6_ctc_entrypoint.compute_61.ptx, line 57044; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-6_ctc_entrypoint.compute_61.ptx, line 57048; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-5_ctc_entrypoint.compute_62.ptx, line 1880; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-5_ctc_entrypoint.compute_62.ptx, line 1884; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-5_ctc_entrypoint.compute_62.ptx, line 1888; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-5_ctc_entrypoint.compute_62.ptx, line 1892; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-5_ctc_entrypoint.compute_62.ptx, line 1896; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-5_ctc_entrypoint.compute_62.ptx, line 5613; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-5_ctc_entrypoint.compute_62.ptx, line 5635; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-5_ctc_entrypoint.compute_62.ptx, line 5639; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-5_ctc_entrypoint.compute_62.ptx, line 5643; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-5_ctc_entrypoint.compute_62.ptx, line 5647; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-5_ctc_entrypoint.compute_62.ptx, line 5651; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-5_ctc_entrypoint.compute_62.ptx, line 9433; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-5_ctc_entrypoint.compute_62.ptx, line 9437; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-5_ctc_entrypoint.compute_62.ptx, line 9459; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-5_ctc_entrypoint.compute_62.ptx, line 9462; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-5_ctc_entrypoint.compute_62.ptx, line 9466; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-5_ctc_entrypoint.compute_62.ptx, line 9470; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-5_ctc_entrypoint.compute_62.ptx, line 9474; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-5_ctc_entrypoint.compute_62.ptx, line 13643; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-5_ctc_entrypoint.compute_62.ptx, line 13666; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-5_ctc_entrypoint.compute_62.ptx, line 13670; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-5_ctc_entrypoint.compute_62.ptx, line 13674; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-5_ctc_entrypoint.compute_62.ptx, line 13678; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-5_ctc_entrypoint.compute_62.ptx, line 13682; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-5_ctc_entrypoint.compute_62.ptx, line 17736; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-5_ctc_entrypoint.compute_62.ptx, line 17740; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-5_ctc_entrypoint.compute_62.ptx, line 17763; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-5_ctc_entrypoint.compute_62.ptx, line 17766; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-5_ctc_entrypoint.compute_62.ptx, line 17770; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-5_ctc_entrypoint.compute_62.ptx, line 17774; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-5_ctc_entrypoint.compute_62.ptx, line 17778; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-5_ctc_entrypoint.compute_62.ptx, line 23224; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-5_ctc_entrypoint.compute_62.ptx, line 23228; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-5_ctc_entrypoint.compute_62.ptx, line 23232; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-5_ctc_entrypoint.compute_62.ptx, line 23236; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-5_ctc_entrypoint.compute_62.ptx, line 23240; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-5_ctc_entrypoint.compute_62.ptx, line 28288; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-5_ctc_entrypoint.compute_62.ptx, line 28311; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-5_ctc_entrypoint.compute_62.ptx, line 28315; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-5_ctc_entrypoint.compute_62.ptx, line 28319; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-5_ctc_entrypoint.compute_62.ptx, line 28323; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-5_ctc_entrypoint.compute_62.ptx, line 28327; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-5_ctc_entrypoint.compute_62.ptx, line 32977; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-5_ctc_entrypoint.compute_62.ptx, line 32981; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-5_ctc_entrypoint.compute_62.ptx, line 33003; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-5_ctc_entrypoint.compute_62.ptx, line 33006; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-5_ctc_entrypoint.compute_62.ptx, line 33010; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-5_ctc_entrypoint.compute_62.ptx, line 33014; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-5_ctc_entrypoint.compute_62.ptx, line 33018; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-5_ctc_entrypoint.compute_62.ptx, line 38835; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-5_ctc_entrypoint.compute_62.ptx, line 38858; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-5_ctc_entrypoint.compute_62.ptx, line 38862; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-5_ctc_entrypoint.compute_62.ptx, line 38866; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-5_ctc_entrypoint.compute_62.ptx, line 38870; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-5_ctc_entrypoint.compute_62.ptx, line 38874; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-5_ctc_entrypoint.compute_62.ptx, line 44150; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-5_ctc_entrypoint.compute_62.ptx, line 44154; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-5_ctc_entrypoint.compute_62.ptx, line 44177; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-5_ctc_entrypoint.compute_62.ptx, line 44180; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-5_ctc_entrypoint.compute_62.ptx, line 44184; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-5_ctc_entrypoint.compute_62.ptx, line 44188; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-5_ctc_entrypoint.compute_62.ptx, line 44192; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-5_ctc_entrypoint.compute_62.ptx, line 50393; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-5_ctc_entrypoint.compute_62.ptx, line 50397; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-5_ctc_entrypoint.compute_62.ptx, line 50420; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-5_ctc_entrypoint.compute_62.ptx, line 50423; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-5_ctc_entrypoint.compute_62.ptx, line 50427; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-5_ctc_entrypoint.compute_62.ptx, line 50431; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-5_ctc_entrypoint.compute_62.ptx, line 50435; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-5_ctc_entrypoint.compute_62.ptx, line 57006; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-5_ctc_entrypoint.compute_62.ptx, line 57010; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-5_ctc_entrypoint.compute_62.ptx, line 57033; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-5_ctc_entrypoint.compute_62.ptx, line 57036; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-5_ctc_entrypoint.compute_62.ptx, line 57040; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-5_ctc_entrypoint.compute_62.ptx, line 57044; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_00000212_00000000-5_ctc_entrypoint.compute_62.ptx, line 57048; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "\u001b[35m\u001b[1mScanning dependencies of target warpctc\u001b[0m\n",
            "[ 42%] \u001b[32m\u001b[1mLinking CXX shared library libwarpctc.so\u001b[0m\n",
            "[ 42%] Built target warpctc\n",
            "[ 57%] \u001b[34m\u001b[1mBuilding NVCC (Device) object CMakeFiles/test_gpu.dir/tests/test_gpu_generated_test_gpu.cu.o\u001b[0m\n",
            "\u001b[35m\u001b[1mScanning dependencies of target test_cpu\u001b[0m\n",
            "[ 71%] \u001b[32mBuilding CXX object CMakeFiles/test_cpu.dir/tests/test_cpu.cpp.o\u001b[0m\n",
            "[ 85%] \u001b[32m\u001b[1mLinking CXX executable test_cpu\u001b[0m\n",
            "[ 85%] Built target test_cpu\n",
            "\u001b[35m\u001b[1mScanning dependencies of target test_gpu\u001b[0m\n",
            "[100%] \u001b[32m\u001b[1mLinking CXX executable test_gpu\u001b[0m\n",
            "[100%] Built target test_gpu\n",
            "Install extension of warp_ctc\n",
            "running install\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "creating warpctc.egg-info\n",
            "writing warpctc.egg-info/PKG-INFO\n",
            "writing dependency_links to warpctc.egg-info/dependency_links.txt\n",
            "writing requirements to warpctc.egg-info/requires.txt\n",
            "writing top-level names to warpctc.egg-info/top_level.txt\n",
            "writing manifest file 'warpctc.egg-info/SOURCES.txt'\n",
            "writing manifest file 'warpctc.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_py\n",
            "creating build\n",
            "creating build/lib.linux-x86_64-3.6\n",
            "creating build/lib.linux-x86_64-3.6/warpctc\n",
            "copying warpctc/warp_ctc.py -> build/lib.linux-x86_64-3.6/warpctc\n",
            "copying warpctc/__init__.py -> build/lib.linux-x86_64-3.6/warpctc\n",
            "running build_ext\n",
            "building 'warpctc._warp_ctc' extension\n",
            "creating build/temp.linux-x86_64-3.6\n",
            "creating build/temp.linux-x86_64-3.6/warpctc\n",
            "creating build/temp.linux-x86_64-3.6/warpctc/src\n",
            "creating build/temp.linux-x86_64-3.6/warpctc/src/cpu\n",
            "creating build/temp.linux-x86_64-3.6/warpctc/src/cuda\n",
            "x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_CUDA -Iwarpctc/core/include -Iwarpctc/src -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c warpctc/src/version.cpp -o build/temp.linux-x86_64-3.6/warpctc/src/version.o -std=c++11 -fPIC -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=_warp_ctc -D_GLIBCXX_USE_CXX11_ABI=0\n",
            "x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_CUDA -Iwarpctc/core/include -Iwarpctc/src -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c warpctc/src/cpu/cpu_ctc.cpp -o build/temp.linux-x86_64-3.6/warpctc/src/cpu/cpu_ctc.o -std=c++11 -fPIC -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=_warp_ctc -D_GLIBCXX_USE_CXX11_ABI=0\n",
            "\u001b[01m\u001b[Kwarpctc/src/cpu/cpu_ctc.cpp:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kint cpu_ctc(const at::Tensor&, at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, int, at::Tensor&)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Kwarpctc/src/cpu/cpu_ctc.cpp:14:55:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     float *probs_ptr = probs.contiguous().data<float>(\u001b[01;35m\u001b[K)\u001b[m\u001b[K;\n",
            "                                                       \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kwarpctc/src/cpu/version.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kwarpctc/src/cpu/cpu_ctc.cpp:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:303:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "   T * \u001b[01;36m\u001b[Kdata\u001b[m\u001b[K() const {\n",
            "       \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kwarpctc/src/cpu/cpu_ctc.cpp:15:55:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     float *grads_ptr = grads.contiguous().data<float>(\u001b[01;35m\u001b[K)\u001b[m\u001b[K;\n",
            "                                                       \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kwarpctc/src/cpu/version.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kwarpctc/src/cpu/cpu_ctc.cpp:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:303:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "   T * \u001b[01;36m\u001b[Kdata\u001b[m\u001b[K() const {\n",
            "       \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kwarpctc/src/cpu/cpu_ctc.cpp:21:51:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = int]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     int *sizes_ptr = sizes.contiguous().data<int>(\u001b[01;35m\u001b[K)\u001b[m\u001b[K;\n",
            "                                                   \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kwarpctc/src/cpu/version.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kwarpctc/src/cpu/cpu_ctc.cpp:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:303:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "   T * \u001b[01;36m\u001b[Kdata\u001b[m\u001b[K() const {\n",
            "       \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kwarpctc/src/cpu/cpu_ctc.cpp:22:53:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = int]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     int *labels_ptr = labels.contiguous().data<int>(\u001b[01;35m\u001b[K)\u001b[m\u001b[K;\n",
            "                                                     \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kwarpctc/src/cpu/version.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kwarpctc/src/cpu/cpu_ctc.cpp:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:303:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "   T * \u001b[01;36m\u001b[Kdata\u001b[m\u001b[K() const {\n",
            "       \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kwarpctc/src/cpu/cpu_ctc.cpp:23:63:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = int]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     int *label_sizes_ptr = label_sizes.contiguous().data<int>(\u001b[01;35m\u001b[K)\u001b[m\u001b[K;\n",
            "                                                               \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kwarpctc/src/cpu/version.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kwarpctc/src/cpu/cpu_ctc.cpp:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:303:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "   T * \u001b[01;36m\u001b[Kdata\u001b[m\u001b[K() const {\n",
            "       \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kwarpctc/src/cpu/cpu_ctc.cpp:32:55:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     float *costs_ptr = costs.contiguous().data<float>(\u001b[01;35m\u001b[K)\u001b[m\u001b[K;\n",
            "                                                       \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kwarpctc/src/cpu/version.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kwarpctc/src/cpu/cpu_ctc.cpp:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:303:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "   T * \u001b[01;36m\u001b[Kdata\u001b[m\u001b[K() const {\n",
            "       \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "/usr/local/cuda/bin/nvcc -DWITH_CUDA -Iwarpctc/core/include -Iwarpctc/src -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c warpctc/src/cuda/gpu_ctc.cu -o build/temp.linux-x86_64-3.6/warpctc/src/cuda/gpu_ctc.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -DCUDA_HAS_FP16=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -Wno-deprecated-gpu-targets -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=_warp_ctc -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=sm_75 -std=c++11\n",
            "/usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "\u001b[01m\u001b[Kwarpctc/src/cuda/gpu_ctc.cu:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kint gpu_ctc(const at::Tensor&, at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, int, at::Tensor&)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Kwarpctc/src/cuda/gpu_ctc.cu:26:40:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     float *probs_ptr = probs.data<float\u001b[01;35m\u001b[K>\u001b[m\u001b[K();\n",
            "                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:303:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kwarpctc/src/cuda/gpu_ctc.cu:27:40:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     float *grads_ptr = grads.data<float\u001b[01;35m\u001b[K>\u001b[m\u001b[K();\n",
            "                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:303:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kwarpctc/src/cuda/gpu_ctc.cu:33:36:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = int]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     int *sizes_ptr = sizes.data<int\u001b[01;35m\u001b[K>\u001b[m\u001b[K();\n",
            "                                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:303:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kwarpctc/src/cuda/gpu_ctc.cu:34:38:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = int]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     int *labels_ptr = labels.data<int\u001b[01;35m\u001b[K>\u001b[m\u001b[K();\n",
            "                                      \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:303:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kwarpctc/src/cuda/gpu_ctc.cu:35:48:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = int]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     int *label_sizes_ptr = label_sizes.data<int\u001b[01;35m\u001b[K>\u001b[m\u001b[K();\n",
            "                                                \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:303:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kwarpctc/src/cuda/gpu_ctc.cu:44:40:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     float *costs_ptr = costs.data<float\u001b[01;35m\u001b[K>\u001b[m\u001b[K();\n",
            "                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:303:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/warpctc/src/version.o build/temp.linux-x86_64-3.6/warpctc/src/cpu/cpu_ctc.o build/temp.linux-x86_64-3.6/warpctc/src/cuda/gpu_ctc.o -L/content/warp-ctc-pytorch/warpctc/core/build -L/usr/local/cuda/lib64 -Wl,--enable-new-dtags,-R/content/warp-ctc-pytorch/warpctc/core/build -lwarpctc -lcudart -o build/lib.linux-x86_64-3.6/warpctc/_warp_ctc.cpython-36m-x86_64-linux-gnu.so\n",
            "creating build/bdist.linux-x86_64\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/warpctc\n",
            "copying build/lib.linux-x86_64-3.6/warpctc/warp_ctc.py -> build/bdist.linux-x86_64/egg/warpctc\n",
            "copying build/lib.linux-x86_64-3.6/warpctc/__init__.py -> build/bdist.linux-x86_64/egg/warpctc\n",
            "copying build/lib.linux-x86_64-3.6/warpctc/_warp_ctc.cpython-36m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg/warpctc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/warpctc/warp_ctc.py to warp_ctc.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/warpctc/__init__.py to __init__.cpython-36.pyc\n",
            "creating stub loader for warpctc/_warp_ctc.cpython-36m-x86_64-linux-gnu.so\n",
            "byte-compiling build/bdist.linux-x86_64/egg/warpctc/_warp_ctc.py to _warp_ctc.cpython-36.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying warpctc.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying warpctc.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying warpctc.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying warpctc.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying warpctc.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "writing build/bdist.linux-x86_64/egg/EGG-INFO/native_libs.txt\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "warpctc.__pycache__._warp_ctc.cpython-36: module references __file__\n",
            "creating dist\n",
            "creating 'dist/warpctc-0.1-py3.6-linux-x86_64.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing warpctc-0.1-py3.6-linux-x86_64.egg\n",
            "creating /root/.local/lib/python3.6/site-packages/warpctc-0.1-py3.6-linux-x86_64.egg\n",
            "Extracting warpctc-0.1-py3.6-linux-x86_64.egg to /root/.local/lib/python3.6/site-packages\n",
            "Adding warpctc 0.1 to easy-install.pth file\n",
            "\n",
            "Installed /root/.local/lib/python3.6/site-packages/warpctc-0.1-py3.6-linux-x86_64.egg\n",
            "Processing dependencies for warpctc==0.1\n",
            "Searching for torch==1.3.1\n",
            "Best match: torch 1.3.1\n",
            "Adding torch 1.3.1 to easy-install.pth file\n",
            "Installing convert-caffe2-to-onnx script to /root/.local/bin\n",
            "Installing convert-onnx-to-caffe2 script to /root/.local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for numpy==1.17.5\n",
            "Best match: numpy 1.17.5\n",
            "Adding numpy 1.17.5 to easy-install.pth file\n",
            "Installing f2py script to /root/.local/bin\n",
            "Installing f2py3 script to /root/.local/bin\n",
            "Installing f2py3.6 script to /root/.local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Finished processing dependencies for warpctc==0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTZX1d20a-qU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vgg16 = models.vgg16(pretrained=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BU3gUvy9dTr6",
        "colab_type": "code",
        "outputId": "d110d209-eaca-4052-8536-0688575d5a08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from setuptools import find_packages\n",
        "find_packages()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['warpctc']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIsgAfgnbNoM",
        "colab_type": "code",
        "outputId": "46a0d2c9-b886-4d18-c087-e9a9daf7babf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "hindi_alphabets = ['-']+[chr(alpha) for alpha in range(2304, 2432)]\n",
        "hindi_alphabet_size = len(hindi_alphabets)\n",
        "indexTochr={}\n",
        "hindi_alpha2index={}\n",
        "cnt=0\n",
        "for alpha in hindi_alphabets:\n",
        "    hindi_alpha2index[alpha] = cnt\n",
        "    indexTochr[cnt]=alpha\n",
        "    cnt+=1\n",
        "print(hindi_alpha2index)\n",
        "vocab_size=cnt\n",
        "batch_size=16\n",
        "sequence_len=28\n",
        "RNN_input_dim=7168\n",
        "RNN_hidden_dim=256\n",
        "RNN_layer=2\n",
        "RNN_type='LSTM'\n",
        "RNN_dropout=0\n",
        "use_VGG_extractor=False\n",
        "learning_rate=(4e-3)*(0.8**0)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'-': 0, 'ऀ': 1, 'ँ': 2, 'ं': 3, 'ः': 4, 'ऄ': 5, 'अ': 6, 'आ': 7, 'इ': 8, 'ई': 9, 'उ': 10, 'ऊ': 11, 'ऋ': 12, 'ऌ': 13, 'ऍ': 14, 'ऎ': 15, 'ए': 16, 'ऐ': 17, 'ऑ': 18, 'ऒ': 19, 'ओ': 20, 'औ': 21, 'क': 22, 'ख': 23, 'ग': 24, 'घ': 25, 'ङ': 26, 'च': 27, 'छ': 28, 'ज': 29, 'झ': 30, 'ञ': 31, 'ट': 32, 'ठ': 33, 'ड': 34, 'ढ': 35, 'ण': 36, 'त': 37, 'थ': 38, 'द': 39, 'ध': 40, 'न': 41, 'ऩ': 42, 'प': 43, 'फ': 44, 'ब': 45, 'भ': 46, 'म': 47, 'य': 48, 'र': 49, 'ऱ': 50, 'ल': 51, 'ळ': 52, 'ऴ': 53, 'व': 54, 'श': 55, 'ष': 56, 'स': 57, 'ह': 58, 'ऺ': 59, 'ऻ': 60, '़': 61, 'ऽ': 62, 'ा': 63, 'ि': 64, 'ी': 65, 'ु': 66, 'ू': 67, 'ृ': 68, 'ॄ': 69, 'ॅ': 70, 'ॆ': 71, 'े': 72, 'ै': 73, 'ॉ': 74, 'ॊ': 75, 'ो': 76, 'ौ': 77, '्': 78, 'ॎ': 79, 'ॏ': 80, 'ॐ': 81, '॑': 82, '॒': 83, '॓': 84, '॔': 85, 'ॕ': 86, 'ॖ': 87, 'ॗ': 88, 'क़': 89, 'ख़': 90, 'ग़': 91, 'ज़': 92, 'ड़': 93, 'ढ़': 94, 'फ़': 95, 'य़': 96, 'ॠ': 97, 'ॡ': 98, 'ॢ': 99, 'ॣ': 100, '।': 101, '॥': 102, '०': 103, '१': 104, '२': 105, '३': 106, '४': 107, '५': 108, '६': 109, '७': 110, '८': 111, '९': 112, '॰': 113, 'ॱ': 114, 'ॲ': 115, 'ॳ': 116, 'ॴ': 117, 'ॵ': 118, 'ॶ': 119, 'ॷ': 120, 'ॸ': 121, 'ॹ': 122, 'ॺ': 123, 'ॻ': 124, 'ॼ': 125, 'ॽ': 126, 'ॾ': 127, 'ॿ': 128}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4FoiUwBb9uq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_train=1600\n",
        "train_indices=range(num_train)\n",
        "num_test=3000\n",
        "\n",
        "mytransform = T.Compose(\n",
        "    [\n",
        "        T.Resize((224,224)),\n",
        "        T.ToTensor(),\n",
        "        T.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ]\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5OYYk-gc9bd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import DataLoader, Dataset, random_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1HovXzCE4lcZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from PIL import Image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QgApuFy0cOix",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CroppedDataset(Dataset):\n",
        "  def __init__(self,transform,image_dir,annotate_dir):\n",
        "    self.transform=transform\n",
        "    self.img_path=[]\n",
        "    self.img=[]\n",
        "    self.word=[]\n",
        "    for file in os.listdir(image_dir):\n",
        "      self.img.append(file)\n",
        "    with open(annotate_dir) as f:\n",
        "      data=f.readlines()\n",
        "    for k in data:\n",
        "      #print(k.split(\"\\t\"))\n",
        "      self.img_path.append(k.split(\"\\t\")[0])\n",
        "      self.word.append(k.split(\"\\t\")[1])\n",
        "  def __len__(self):\n",
        "    return len(self.img)\n",
        "  def __getitem__(self,indx):\n",
        "    #print(self.word[indx])\n",
        "    #print(self.img[indx])\n",
        "    image=Image.open(\"cropped_data/\"+''.join(self.img_path[indx])).convert(\"RGB\")\n",
        "    word=self.word[indx]\n",
        "    return (self.transform(image),word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3OQ3Ug-4c3rs",
        "colab_type": "code",
        "outputId": "d0cd020b-4a82-4853-ef7f-4a290de688bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#%cd ./warp-ctc-pytorch\n",
        "!sh make.sh core\n",
        "!python3 setup.py build_ext --inplace"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/warp-ctc-pytorch\n",
            "Make core shared object of libwarp_ctc.so\n",
            "-- cuda found TRUE\n",
            "CMake Warning at CMakeLists.txt:48 (FIND_PACKAGE):\n",
            "  By not providing \"FindTorch.cmake\" in CMAKE_MODULE_PATH this project has\n",
            "  asked CMake to find a package configuration file provided by \"Torch\", but\n",
            "  CMake did not find one.\n",
            "\n",
            "  Could not find a package configuration file provided by \"Torch\" with any of\n",
            "  the following names:\n",
            "\n",
            "    TorchConfig.cmake\n",
            "    torch-config.cmake\n",
            "\n",
            "  Add the installation prefix of \"Torch\" to CMAKE_PREFIX_PATH or set\n",
            "  \"Torch_DIR\" to a directory containing one of the above files.  If \"Torch\"\n",
            "  provides a separate development package or SDK, be sure it has been\n",
            "  installed.\n",
            "\n",
            "\n",
            "-- Torch found Torch_DIR-NOTFOUND\n",
            "-- Building shared library with GPU support\n",
            "-- Configuring done\n",
            "-- Generating done\n",
            "-- Build files have been written to: /content/warp-ctc-pytorch/warpctc/core/build\n",
            "[ 14%] \u001b[32m\u001b[1mLinking CXX shared library libwarpctc.so\u001b[0m\n",
            "[ 42%] Built target warpctc\n",
            "[ 57%] \u001b[32m\u001b[1mLinking CXX executable test_cpu\u001b[0m\n",
            "[ 71%] \u001b[32m\u001b[1mLinking CXX executable test_gpu\u001b[0m\n",
            "[ 85%] Built target test_cpu\n",
            "[100%] Built target test_gpu\n",
            "running build_ext\n",
            "building 'warpctc._warp_ctc' extension\n",
            "creating build\n",
            "creating build/temp.linux-x86_64-3.6\n",
            "creating build/temp.linux-x86_64-3.6/warpctc\n",
            "creating build/temp.linux-x86_64-3.6/warpctc/src\n",
            "creating build/temp.linux-x86_64-3.6/warpctc/src/cpu\n",
            "creating build/temp.linux-x86_64-3.6/warpctc/src/cuda\n",
            "x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_CUDA -Iwarpctc/core/include -Iwarpctc/src -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c warpctc/src/version.cpp -o build/temp.linux-x86_64-3.6/warpctc/src/version.o -std=c++11 -fPIC -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=_warp_ctc -D_GLIBCXX_USE_CXX11_ABI=0\n",
            "x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_CUDA -Iwarpctc/core/include -Iwarpctc/src -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c warpctc/src/cpu/cpu_ctc.cpp -o build/temp.linux-x86_64-3.6/warpctc/src/cpu/cpu_ctc.o -std=c++11 -fPIC -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=_warp_ctc -D_GLIBCXX_USE_CXX11_ABI=0\n",
            "\u001b[01m\u001b[Kwarpctc/src/cpu/cpu_ctc.cpp:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kint cpu_ctc(const at::Tensor&, at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, int, at::Tensor&)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Kwarpctc/src/cpu/cpu_ctc.cpp:14:55:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     float *probs_ptr = probs.contiguous().data<float>(\u001b[01;35m\u001b[K)\u001b[m\u001b[K;\n",
            "                                                       \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kwarpctc/src/cpu/version.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kwarpctc/src/cpu/cpu_ctc.cpp:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:303:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "   T * \u001b[01;36m\u001b[Kdata\u001b[m\u001b[K() const {\n",
            "       \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kwarpctc/src/cpu/cpu_ctc.cpp:15:55:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     float *grads_ptr = grads.contiguous().data<float>(\u001b[01;35m\u001b[K)\u001b[m\u001b[K;\n",
            "                                                       \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kwarpctc/src/cpu/version.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kwarpctc/src/cpu/cpu_ctc.cpp:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:303:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "   T * \u001b[01;36m\u001b[Kdata\u001b[m\u001b[K() const {\n",
            "       \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kwarpctc/src/cpu/cpu_ctc.cpp:21:51:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = int]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     int *sizes_ptr = sizes.contiguous().data<int>(\u001b[01;35m\u001b[K)\u001b[m\u001b[K;\n",
            "                                                   \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kwarpctc/src/cpu/version.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kwarpctc/src/cpu/cpu_ctc.cpp:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:303:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "   T * \u001b[01;36m\u001b[Kdata\u001b[m\u001b[K() const {\n",
            "       \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kwarpctc/src/cpu/cpu_ctc.cpp:22:53:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = int]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     int *labels_ptr = labels.contiguous().data<int>(\u001b[01;35m\u001b[K)\u001b[m\u001b[K;\n",
            "                                                     \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kwarpctc/src/cpu/version.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kwarpctc/src/cpu/cpu_ctc.cpp:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:303:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "   T * \u001b[01;36m\u001b[Kdata\u001b[m\u001b[K() const {\n",
            "       \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kwarpctc/src/cpu/cpu_ctc.cpp:23:63:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = int]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     int *label_sizes_ptr = label_sizes.contiguous().data<int>(\u001b[01;35m\u001b[K)\u001b[m\u001b[K;\n",
            "                                                               \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kwarpctc/src/cpu/version.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kwarpctc/src/cpu/cpu_ctc.cpp:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:303:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "   T * \u001b[01;36m\u001b[Kdata\u001b[m\u001b[K() const {\n",
            "       \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kwarpctc/src/cpu/cpu_ctc.cpp:32:55:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     float *costs_ptr = costs.contiguous().data<float>(\u001b[01;35m\u001b[K)\u001b[m\u001b[K;\n",
            "                                                       \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kwarpctc/src/cpu/version.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kwarpctc/src/cpu/cpu_ctc.cpp:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:303:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "   T * \u001b[01;36m\u001b[Kdata\u001b[m\u001b[K() const {\n",
            "       \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "/usr/local/cuda/bin/nvcc -DWITH_CUDA -Iwarpctc/core/include -Iwarpctc/src -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c warpctc/src/cuda/gpu_ctc.cu -o build/temp.linux-x86_64-3.6/warpctc/src/cuda/gpu_ctc.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -DCUDA_HAS_FP16=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -Wno-deprecated-gpu-targets -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=_warp_ctc -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=sm_75 -std=c++11\n",
            "/usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "\u001b[01m\u001b[Kwarpctc/src/cuda/gpu_ctc.cu:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kint gpu_ctc(const at::Tensor&, at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, int, at::Tensor&)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Kwarpctc/src/cuda/gpu_ctc.cu:26:40:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     float *probs_ptr = probs.data<float\u001b[01;35m\u001b[K>\u001b[m\u001b[K();\n",
            "                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:303:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kwarpctc/src/cuda/gpu_ctc.cu:27:40:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     float *grads_ptr = grads.data<float\u001b[01;35m\u001b[K>\u001b[m\u001b[K();\n",
            "                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:303:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kwarpctc/src/cuda/gpu_ctc.cu:33:36:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = int]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     int *sizes_ptr = sizes.data<int\u001b[01;35m\u001b[K>\u001b[m\u001b[K();\n",
            "                                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:303:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kwarpctc/src/cuda/gpu_ctc.cu:34:38:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = int]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     int *labels_ptr = labels.data<int\u001b[01;35m\u001b[K>\u001b[m\u001b[K();\n",
            "                                      \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:303:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kwarpctc/src/cuda/gpu_ctc.cu:35:48:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = int]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     int *label_sizes_ptr = label_sizes.data<int\u001b[01;35m\u001b[K>\u001b[m\u001b[K();\n",
            "                                                \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:303:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kwarpctc/src/cuda/gpu_ctc.cu:44:40:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     float *costs_ptr = costs.data<float\u001b[01;35m\u001b[K>\u001b[m\u001b[K();\n",
            "                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:303:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "creating build/lib.linux-x86_64-3.6\n",
            "creating build/lib.linux-x86_64-3.6/warpctc\n",
            "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/warpctc/src/version.o build/temp.linux-x86_64-3.6/warpctc/src/cpu/cpu_ctc.o build/temp.linux-x86_64-3.6/warpctc/src/cuda/gpu_ctc.o -L/content/warp-ctc-pytorch/warpctc/core/build -L/usr/local/cuda/lib64 -Wl,--enable-new-dtags,-R/content/warp-ctc-pytorch/warpctc/core/build -lwarpctc -lcudart -o build/lib.linux-x86_64-3.6/warpctc/_warp_ctc.cpython-36m-x86_64-linux-gnu.so\n",
            "copying build/lib.linux-x86_64-3.6/warpctc/_warp_ctc.cpython-36m-x86_64-linux-gnu.so -> warpctc\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhycWJgpHCfW",
        "colab_type": "code",
        "outputId": "43e6a929-73c0-447b-84c5-99119b7778c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "!ls\n",
        "from setuptools import find_packages\n",
        "find_packages()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "build  check_ctc.py  LICENSE  make.sh  README.md  setup.py  warpctc\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['warpctc']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "787z08QXHuah",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from warpctc import CTCLoss\n",
        "#!unzip cropped_data.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQLYf0K2hwVY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IIIT5K_train = CroppedDataset(mytransform,\"cropped_data/cropped_dir\",\"cropped_data/annotations.txt\")\n",
        "loader_train = DataLoader(dataset = IIIT5K_train,batch_size =16,sampler=SubsetRandomSampler(range(1600)))\n",
        "loader_test = DataLoader(dataset = IIIT5K_train,batch_size = 1,shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UlLsuW-VEMkl",
        "colab_type": "code",
        "outputId": "6752b5a7-04d3-4218-f3cd-79fa87e86bc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(loader_train)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBSNB15Ok0QD",
        "colab_type": "code",
        "outputId": "4334e364-12de-4648-f9c7-02642d44c3fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "def imshow(img):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "dataiter = iter(loader_train)\n",
        "images,labels=dataiter.next()\n",
        "#print(images)\n",
        "print(labels)\n",
        "\n",
        "imshow(utils.make_grid(images))\n",
        "print(' '.join('%s' % labels[j] for j in range(batch_size)))"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('पी', 'रेल', 'विश्वकर्मा', 'परिसर', 'की', 'प्रथम', 'मल्टीकलर', 'स्वच्छ', 'रेल', 'स्टाम्प', 'सोनू', 'बालाजी', 'स्टोर्स', 'लो', 'स्टेशन', 'सी')\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAB3CAYAAAAJvFvHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "पी रेल विश्वकर्मा परिसर की प्रथम मल्टीकलर स्वच्छ रेल स्टाम्प सोनू बालाजी स्टोर्स लो स्टेशन सी\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MlOJ-9rck_18",
        "colab_type": "code",
        "outputId": "aeb6854c-0662-4569-d532-7859e2ccc76d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print('CUDA available :',torch.cuda.is_available())\n",
        "cpu_dtype = torch.FloatTensor # the CPU datatype\n",
        "gpu_dtype = torch.cuda.FloatTensor # the GPU datatype\n",
        "\n",
        "dtype=gpu_dtype\n",
        "print(dtype)\n",
        "\n",
        "# From torchvision/vgg.py\n",
        "def reset(model):\n",
        "    for m in model.modules():\n",
        "        if isinstance(m, nn.Conv2d):\n",
        "            nn.init.xavier_normal_(m.weight, gain=1)\n",
        "#             n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "#             m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "            if m.bias is not None:\n",
        "                m.bias.data.zero_()\n",
        "        elif isinstance(m, nn.BatchNorm2d):\n",
        "            m.weight.data.fill_(1)\n",
        "            m.bias.data.zero_()\n",
        "        elif isinstance(m, nn.Linear):\n",
        "            nn.init.xavier_normal_(m.weight, gain=1)\n",
        "#             m.weight.data.normal_(0, 0.01)\n",
        "            m.bias.data.zero_()\n",
        "        elif hasattr(m, 'reset_parameters'):\n",
        "            m.reset_parameters()\n",
        "            \n",
        "class Flatten(nn.Module):\n",
        "    def forward(self, x):\n",
        "        N, C, H, W = x.size() # read in N, C, H, W\n",
        "        return x.view(N, -1) "
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CUDA available : True\n",
            "<class 'torch.cuda.FloatTensor'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHgHKvEBn07F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CNN_block(nn.Module):\n",
        "    def __init__(self,in_channel,out_channel):\n",
        "        super(CNN_block, self).__init__()\n",
        "        self.conv_1=nn.Conv2d(in_channel, out_channel, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv_2=nn.Conv2d(out_channel, out_channel, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv_3=nn.Conv2d(out_channel, out_channel, kernel_size=3, stride=1, padding=1)\n",
        "        self.batchnorm1=nn.BatchNorm2d(num_features=out_channel)\n",
        "        self.batchnorm2=nn.BatchNorm2d(num_features=out_channel)\n",
        "        self.batchnorm3=nn.BatchNorm2d(num_features=out_channel)\n",
        "        self.relu=nn.ReLU(True)\n",
        "        self.maxpool=nn.MaxPool2d(kernel_size=(2,2),stride=(2,2))\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x=self.relu(self.batchnorm1(self.conv_1(x)))\n",
        "        x=self.relu(self.batchnorm2(self.conv_2(x)))\n",
        "        x=self.relu(self.batchnorm3(self.conv_3(x)))\n",
        "        x=self.maxpool(x)\n",
        "        return x\n",
        "    \n",
        "class ToRNN(nn.Module):\n",
        "    def forward(self, x):\n",
        "        x=x.permute(3,0,1,2)\n",
        "        W,N,C,H= x.size()\n",
        "        x.contiguous()\n",
        "        return x.view(W,N,-1)\n",
        "    \n",
        "class BiDireRNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BiDireRNN, self).__init__()\n",
        "        self.hidden_dim = RNN_hidden_dim\n",
        "        self.num_layers=RNN_layer\n",
        "        self.sql=sequence_len\n",
        "        self.bsize=batch_size\n",
        "        self.dropout=RNN_dropout\n",
        "        self.rnn_type=RNN_type\n",
        "        self.rnn = self.rnn_layer()\n",
        "        self.hidden=None\n",
        "        self.init_hidden(batch_size)\n",
        "        \n",
        "    def rnn_layer(self):\n",
        "        if self.rnn_type=='RNN':\n",
        "            return nn.RNN(RNN_input_dim, self.hidden_dim, self.num_layers, dropout=self.dropout, bidirectional=True)\n",
        "        elif self.rnn_type=='LSTM':\n",
        "            return nn.LSTM(RNN_input_dim, self.hidden_dim, self.num_layers, dropout=0.7, bidirectional=True)\n",
        "        elif self.rnn_type=='GRU':\n",
        "            return nn.GRU(RNN_input_dim, self.hidden_dim, self.num_layers, dropout=self.dropout, bidirectional=True)\n",
        "        else:\n",
        "            raise AssertionError('unknown RNN type:',self.rnn_type)\n",
        "    \n",
        "    def init_hidden(self,bsize):\n",
        "        if self.rnn_type=='LSTM':\n",
        "            self.hidden=(Variable(torch.zeros(self.num_layers*2, bsize, self.hidden_dim).type(dtype)),\n",
        "                    Variable(torch.zeros(self.num_layers*2, bsize, self.hidden_dim).type(dtype)))\n",
        "        else:\n",
        "            self.hidden=Variable(torch.zeros(self.num_layers*2, bsize, self.hidden_dim))\n",
        "        \n",
        "    \n",
        "    def forward(self, x):\n",
        "      rnn_out, self.hidden = self.rnn(x, self.hidden)\n",
        "      return rnn_out\n",
        "        \n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self,use_VGG_extractor=False):\n",
        "        super(Model, self).__init__()\n",
        "        if use_VGG_extractor:\n",
        "            self.feature_extractor=nn.Sequential(*([vgg16.features[i] for i in range(17)]))\n",
        "            for param in self.feature_extractor.parameters():\n",
        "                param.requires_grad=False\n",
        "                \n",
        "        else:\n",
        "            self.feature_extractor=nn.Sequential(*([CNN_block(3,64),CNN_block(64,128),CNN_block(128,256)]))\n",
        "        self.toRNN=ToRNN()\n",
        "        self.RNN=BiDireRNN()\n",
        "        self.toTraget=nn.Linear(RNN_hidden_dim*2, vocab_size)\n",
        "        self.softmax=nn.Softmax(dim=2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        feature=self.feature_extractor(x)\n",
        "        RNN_input=self.toRNN(feature)\n",
        "        RNN_out=self.RNN(RNN_input)\n",
        "        tag_scores = self.toTraget(RNN_out)\n",
        "        #tag_scores=self.softmax(tag_scores)\n",
        "        return tag_scores"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kKno6LU0oGc4",
        "colab_type": "code",
        "outputId": "de8bc7ce-bc5f-4ad4-fee1-d1f19e6a3032",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "my_model=Model(use_VGG_extractor=True).type(dtype)\n",
        "print(my_model)\n",
        "for param in my_model.named_parameters():\n",
        "    print(param[0],type(param[1].data),param[1].size(),param[1].requires_grad)"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model(\n",
            "  (feature_extractor): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): ReLU(inplace=True)\n",
            "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (13): ReLU(inplace=True)\n",
            "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): ReLU(inplace=True)\n",
            "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (toRNN): ToRNN()\n",
            "  (RNN): BiDireRNN(\n",
            "    (rnn): LSTM(7168, 256, num_layers=2, dropout=0.7, bidirectional=True)\n",
            "  )\n",
            "  (toTraget): Linear(in_features=512, out_features=129, bias=True)\n",
            "  (softmax): Softmax(dim=2)\n",
            ")\n",
            "feature_extractor.0.weight <class 'torch.Tensor'> torch.Size([64, 3, 3, 3]) False\n",
            "feature_extractor.0.bias <class 'torch.Tensor'> torch.Size([64]) False\n",
            "feature_extractor.2.weight <class 'torch.Tensor'> torch.Size([64, 64, 3, 3]) False\n",
            "feature_extractor.2.bias <class 'torch.Tensor'> torch.Size([64]) False\n",
            "feature_extractor.5.weight <class 'torch.Tensor'> torch.Size([128, 64, 3, 3]) False\n",
            "feature_extractor.5.bias <class 'torch.Tensor'> torch.Size([128]) False\n",
            "feature_extractor.7.weight <class 'torch.Tensor'> torch.Size([128, 128, 3, 3]) False\n",
            "feature_extractor.7.bias <class 'torch.Tensor'> torch.Size([128]) False\n",
            "feature_extractor.10.weight <class 'torch.Tensor'> torch.Size([256, 128, 3, 3]) False\n",
            "feature_extractor.10.bias <class 'torch.Tensor'> torch.Size([256]) False\n",
            "feature_extractor.12.weight <class 'torch.Tensor'> torch.Size([256, 256, 3, 3]) False\n",
            "feature_extractor.12.bias <class 'torch.Tensor'> torch.Size([256]) False\n",
            "feature_extractor.14.weight <class 'torch.Tensor'> torch.Size([256, 256, 3, 3]) False\n",
            "feature_extractor.14.bias <class 'torch.Tensor'> torch.Size([256]) False\n",
            "RNN.rnn.weight_ih_l0 <class 'torch.Tensor'> torch.Size([1024, 7168]) True\n",
            "RNN.rnn.weight_hh_l0 <class 'torch.Tensor'> torch.Size([1024, 256]) True\n",
            "RNN.rnn.bias_ih_l0 <class 'torch.Tensor'> torch.Size([1024]) True\n",
            "RNN.rnn.bias_hh_l0 <class 'torch.Tensor'> torch.Size([1024]) True\n",
            "RNN.rnn.weight_ih_l0_reverse <class 'torch.Tensor'> torch.Size([1024, 7168]) True\n",
            "RNN.rnn.weight_hh_l0_reverse <class 'torch.Tensor'> torch.Size([1024, 256]) True\n",
            "RNN.rnn.bias_ih_l0_reverse <class 'torch.Tensor'> torch.Size([1024]) True\n",
            "RNN.rnn.bias_hh_l0_reverse <class 'torch.Tensor'> torch.Size([1024]) True\n",
            "RNN.rnn.weight_ih_l1 <class 'torch.Tensor'> torch.Size([1024, 512]) True\n",
            "RNN.rnn.weight_hh_l1 <class 'torch.Tensor'> torch.Size([1024, 256]) True\n",
            "RNN.rnn.bias_ih_l1 <class 'torch.Tensor'> torch.Size([1024]) True\n",
            "RNN.rnn.bias_hh_l1 <class 'torch.Tensor'> torch.Size([1024]) True\n",
            "RNN.rnn.weight_ih_l1_reverse <class 'torch.Tensor'> torch.Size([1024, 512]) True\n",
            "RNN.rnn.weight_hh_l1_reverse <class 'torch.Tensor'> torch.Size([1024, 256]) True\n",
            "RNN.rnn.bias_ih_l1_reverse <class 'torch.Tensor'> torch.Size([1024]) True\n",
            "RNN.rnn.bias_hh_l1_reverse <class 'torch.Tensor'> torch.Size([1024]) True\n",
            "toTraget.weight <class 'torch.Tensor'> torch.Size([129, 512]) True\n",
            "toTraget.bias <class 'torch.Tensor'> torch.Size([129]) True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWDbUBa84Xy2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "loss_function = torch.nn.CTCLoss().type(dtype)\n",
        "# opt_parameters=my_model.parameters() if use_VGG_extractor==False else [my_model.RNN.parameters(),my_model.toTraget.parameters()]\n",
        "# print(opt_parameters)\n",
        "# optimizer = optim.Adam(opt_parameters, lr=4e-3)\n",
        "\n",
        "if use_VGG_extractor:\n",
        "    opt_parameters=list(my_model.RNN.parameters())+list(my_model.toTraget.parameters())\n",
        "    optimizer = optim.Adam(iter(opt_parameters), lr=0.004)\n",
        "else:\n",
        "    optimizer = optim.Adam(my_model.parameters(), lr=0.004)\n",
        "\n",
        "scheduler = lrs.StepLR(optimizer, step_size=30, gamma=0.8)\n",
        "softmax=torch.nn.LogSoftmax(dim=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYRSD46VEA6O",
        "colab_type": "code",
        "outputId": "7c83bf29-0d2d-4442-c2e2-4809d401f28d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(type(loss_function))"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'torch.nn.modules.loss.CTCLoss'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFKHx8fy7f_z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_train(max_epoch,print_every):\n",
        "\n",
        "    iter_each_epoch=num_train//batch_size\n",
        "    loss_his_train=[]\n",
        "\n",
        "    for epoch in range(max_epoch):\n",
        "        #scheduler.step()\n",
        "        #my_model.train()\n",
        "        print(time.strftime('%Y-%m-%d %H:%M:%S',time.localtime(time.time())),\n",
        "              'start epoch %d/%d:' % (epoch+1,max_epoch),'learning_rate =',scheduler.get_lr()[0],\n",
        "              'sequence_len =',my_model.RNN.sql)\n",
        "        tot_loss=0\n",
        "        \n",
        "        it=0\n",
        "        for images,labels in loader_train:\n",
        "\n",
        "            X_var=Variable(images.type(dtype))\n",
        "            \n",
        "            out_size=Variable(torch.IntTensor([sequence_len] * batch_size))\n",
        "            y_size=Variable(torch.IntTensor([len(l) for l in labels]))\n",
        "            conc_label=''.join(labels)\n",
        "            #print(conc_label)\n",
        "            y=[hindi_alpha2index[c] for c in conc_label]\n",
        "            #print(y)\n",
        "            #print(y_size)\n",
        "            y_var=Variable(torch.IntTensor(y))\n",
        "\n",
        "            my_model.zero_grad()\n",
        "\n",
        "            my_model.RNN.init_hidden(batch_size)\n",
        "\n",
        "            scores = my_model(X_var)\n",
        "\n",
        "            loss = loss_function(softmax(scores),y_var,out_size,y_size)/batch_size\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(my_model.parameters(), 1)\n",
        "            optimizer.step()\n",
        "            \n",
        "            tot_loss+=loss.item()\n",
        "            \n",
        "            if it==0 or (it+1)%print_every==0 or it==iter_each_epoch-1:\n",
        "                print(time.strftime('%Y-%m-%d %H:%M:%S',time.localtime(time.time())),\n",
        "                      'iter %d loss = %f' % (it+1,loss.item()))\n",
        "            it+=1\n",
        "                \n",
        "        tot_loss/=iter_each_epoch\n",
        "        print(time.strftime('%Y-%m-%d %H:%M:%S',time.localtime(time.time())),\n",
        "                'epoch %d/%d average_loss = %f\\n' % (epoch+1,max_epoch,tot_loss))\n",
        "        loss_his_train.append(tot_loss)\n",
        "    return loss_his_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4u18NNSz7sCR",
        "colab_type": "code",
        "outputId": "329e6adb-0015-4a5a-e273-16f8c85c0614",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "my_model.apply(reset)\n",
        "# my_model.load_state_dict(torch.load('parameters-5000'))\n",
        "#my_model.train()\n",
        "my_model.RNN.init_hidden(batch_size)\n",
        "loss_his_train=model_train(max_epoch=500,print_every=25)"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-01-19 17:50:22 start epoch 1/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 17:50:22 iter 1 loss = 1.935390\n",
            "2020-01-19 17:50:25 iter 25 loss = 0.654149\n",
            "2020-01-19 17:50:29 iter 50 loss = 0.908854\n",
            "2020-01-19 17:50:32 iter 75 loss = 0.596117\n",
            "2020-01-19 17:50:35 iter 100 loss = 0.514114\n",
            "2020-01-19 17:50:35 epoch 1/500 average_loss = 0.695580\n",
            "\n",
            "2020-01-19 17:50:35 start epoch 2/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 17:50:35 iter 1 loss = 0.640003\n",
            "2020-01-19 17:50:38 iter 25 loss = 0.749625\n",
            "2020-01-19 17:50:41 iter 50 loss = 0.514240\n",
            "2020-01-19 17:50:45 iter 75 loss = 0.584442\n",
            "2020-01-19 17:50:48 iter 100 loss = 0.762727\n",
            "2020-01-19 17:50:48 epoch 2/500 average_loss = 0.644802\n",
            "\n",
            "2020-01-19 17:50:48 start epoch 3/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 17:50:48 iter 1 loss = 0.596095\n",
            "2020-01-19 17:50:51 iter 25 loss = 0.593271\n",
            "2020-01-19 17:50:54 iter 50 loss = 0.501565\n",
            "2020-01-19 17:50:57 iter 75 loss = 0.850079\n",
            "2020-01-19 17:51:01 iter 100 loss = 0.598586\n",
            "2020-01-19 17:51:01 epoch 3/500 average_loss = 0.631085\n",
            "\n",
            "2020-01-19 17:51:01 start epoch 4/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 17:51:01 iter 1 loss = 0.636842\n",
            "2020-01-19 17:51:04 iter 25 loss = 0.533198\n",
            "2020-01-19 17:51:07 iter 50 loss = 0.622300\n",
            "2020-01-19 17:51:10 iter 75 loss = 0.749131\n",
            "2020-01-19 17:51:13 iter 100 loss = 0.724424\n",
            "2020-01-19 17:51:13 epoch 4/500 average_loss = 0.630069\n",
            "\n",
            "2020-01-19 17:51:13 start epoch 5/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 17:51:14 iter 1 loss = 0.736458\n",
            "2020-01-19 17:51:17 iter 25 loss = 0.809800\n",
            "2020-01-19 17:51:20 iter 50 loss = 0.532492\n",
            "2020-01-19 17:51:23 iter 75 loss = 0.568164\n",
            "2020-01-19 17:51:26 iter 100 loss = 0.639472\n",
            "2020-01-19 17:51:26 epoch 5/500 average_loss = 0.630766\n",
            "\n",
            "2020-01-19 17:51:26 start epoch 6/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 17:51:26 iter 1 loss = 0.695096\n",
            "2020-01-19 17:51:29 iter 25 loss = 0.563376\n",
            "2020-01-19 17:51:33 iter 50 loss = 0.750833\n",
            "2020-01-19 17:51:36 iter 75 loss = 0.535793\n",
            "2020-01-19 17:51:39 iter 100 loss = 0.533538\n",
            "2020-01-19 17:51:39 epoch 6/500 average_loss = 0.626536\n",
            "\n",
            "2020-01-19 17:51:39 start epoch 7/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 17:51:39 iter 1 loss = 0.752860\n",
            "2020-01-19 17:51:42 iter 25 loss = 0.603524\n",
            "2020-01-19 17:51:45 iter 50 loss = 0.613953\n",
            "2020-01-19 17:51:49 iter 75 loss = 0.647726\n",
            "2020-01-19 17:51:52 iter 100 loss = 0.517732\n",
            "2020-01-19 17:51:52 epoch 7/500 average_loss = 0.628171\n",
            "\n",
            "2020-01-19 17:51:52 start epoch 8/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 17:51:52 iter 1 loss = 0.717909\n",
            "2020-01-19 17:51:55 iter 25 loss = 0.612403\n",
            "2020-01-19 17:51:58 iter 50 loss = 0.579675\n",
            "2020-01-19 17:52:01 iter 75 loss = 0.668710\n",
            "2020-01-19 17:52:04 iter 100 loss = 0.486014\n",
            "2020-01-19 17:52:04 epoch 8/500 average_loss = 0.626315\n",
            "\n",
            "2020-01-19 17:52:04 start epoch 9/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 17:52:05 iter 1 loss = 0.617090\n",
            "2020-01-19 17:52:08 iter 25 loss = 0.627688\n",
            "2020-01-19 17:52:11 iter 50 loss = 0.590478\n",
            "2020-01-19 17:52:14 iter 75 loss = 0.521706\n",
            "2020-01-19 17:52:17 iter 100 loss = 0.560151\n",
            "2020-01-19 17:52:17 epoch 9/500 average_loss = 0.627730\n",
            "\n",
            "2020-01-19 17:52:17 start epoch 10/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 17:52:17 iter 1 loss = 0.733522\n",
            "2020-01-19 17:52:20 iter 25 loss = 0.545315\n",
            "2020-01-19 17:52:24 iter 50 loss = 0.888356\n",
            "2020-01-19 17:52:27 iter 75 loss = 0.665031\n",
            "2020-01-19 17:52:30 iter 100 loss = 0.671816\n",
            "2020-01-19 17:52:30 epoch 10/500 average_loss = 0.623064\n",
            "\n",
            "2020-01-19 17:52:30 start epoch 11/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 17:52:30 iter 1 loss = 0.532694\n",
            "2020-01-19 17:52:33 iter 25 loss = 0.615728\n",
            "2020-01-19 17:52:36 iter 50 loss = 0.539597\n",
            "2020-01-19 17:52:39 iter 75 loss = 0.642761\n",
            "2020-01-19 17:52:43 iter 100 loss = 0.778846\n",
            "2020-01-19 17:52:43 epoch 11/500 average_loss = 0.623452\n",
            "\n",
            "2020-01-19 17:52:43 start epoch 12/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 17:52:43 iter 1 loss = 0.590738\n",
            "2020-01-19 17:52:46 iter 25 loss = 0.597377\n",
            "2020-01-19 17:52:49 iter 50 loss = 0.683357\n",
            "2020-01-19 17:52:52 iter 75 loss = 0.641922\n",
            "2020-01-19 17:52:55 iter 100 loss = 0.614456\n",
            "2020-01-19 17:52:55 epoch 12/500 average_loss = 0.624640\n",
            "\n",
            "2020-01-19 17:52:55 start epoch 13/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 17:52:56 iter 1 loss = 0.715652\n",
            "2020-01-19 17:52:59 iter 25 loss = 0.780105\n",
            "2020-01-19 17:53:02 iter 50 loss = 0.532032\n",
            "2020-01-19 17:53:05 iter 75 loss = 0.513627\n",
            "2020-01-19 17:53:08 iter 100 loss = 0.668992\n",
            "2020-01-19 17:53:08 epoch 13/500 average_loss = 0.620243\n",
            "\n",
            "2020-01-19 17:53:08 start epoch 14/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 17:53:08 iter 1 loss = 0.648676\n",
            "2020-01-19 17:53:11 iter 25 loss = 0.550742\n",
            "2020-01-19 17:53:15 iter 50 loss = 0.605878\n",
            "2020-01-19 17:53:18 iter 75 loss = 0.657209\n",
            "2020-01-19 17:53:21 iter 100 loss = 0.628806\n",
            "2020-01-19 17:53:21 epoch 14/500 average_loss = 0.620012\n",
            "\n",
            "2020-01-19 17:53:21 start epoch 15/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 17:53:21 iter 1 loss = 0.627466\n",
            "2020-01-19 17:53:24 iter 25 loss = 0.558478\n",
            "2020-01-19 17:53:27 iter 50 loss = 0.607609\n",
            "2020-01-19 17:53:31 iter 75 loss = 0.579382\n",
            "2020-01-19 17:53:34 iter 100 loss = 0.523836\n",
            "2020-01-19 17:53:34 epoch 15/500 average_loss = 0.621598\n",
            "\n",
            "2020-01-19 17:53:34 start epoch 16/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 17:53:34 iter 1 loss = 0.600258\n",
            "2020-01-19 17:53:37 iter 25 loss = 0.819620\n",
            "2020-01-19 17:53:40 iter 50 loss = 0.741209\n",
            "2020-01-19 17:53:43 iter 75 loss = 0.546161\n",
            "2020-01-19 17:53:47 iter 100 loss = 0.565343\n",
            "2020-01-19 17:53:47 epoch 16/500 average_loss = 0.618358\n",
            "\n",
            "2020-01-19 17:53:47 start epoch 17/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 17:53:47 iter 1 loss = 0.573885\n",
            "2020-01-19 17:53:50 iter 25 loss = 0.499225\n",
            "2020-01-19 17:53:53 iter 50 loss = 0.557725\n",
            "2020-01-19 17:53:56 iter 75 loss = 0.548533\n",
            "2020-01-19 17:53:59 iter 100 loss = 0.621911\n",
            "2020-01-19 17:53:59 epoch 17/500 average_loss = 0.614598\n",
            "\n",
            "2020-01-19 17:53:59 start epoch 18/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 17:53:59 iter 1 loss = 0.805097\n",
            "2020-01-19 17:54:02 iter 25 loss = 0.502411\n",
            "2020-01-19 17:54:06 iter 50 loss = 0.533682\n",
            "2020-01-19 17:54:09 iter 75 loss = 0.641676\n",
            "2020-01-19 17:54:12 iter 100 loss = 0.492144\n",
            "2020-01-19 17:54:12 epoch 18/500 average_loss = 0.614251\n",
            "\n",
            "2020-01-19 17:54:12 start epoch 19/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 17:54:12 iter 1 loss = 0.558489\n",
            "2020-01-19 17:54:15 iter 25 loss = 0.507686\n",
            "2020-01-19 17:54:18 iter 50 loss = 0.545781\n",
            "2020-01-19 17:54:22 iter 75 loss = 0.438411\n",
            "2020-01-19 17:54:25 iter 100 loss = 0.656836\n",
            "2020-01-19 17:54:25 epoch 19/500 average_loss = 0.616445\n",
            "\n",
            "2020-01-19 17:54:25 start epoch 20/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 17:54:25 iter 1 loss = 0.603149\n",
            "2020-01-19 17:54:28 iter 25 loss = 0.543372\n",
            "2020-01-19 17:54:31 iter 50 loss = 0.680601\n",
            "2020-01-19 17:54:34 iter 75 loss = 0.572114\n",
            "2020-01-19 17:54:38 iter 100 loss = 0.437206\n",
            "2020-01-19 17:54:38 epoch 20/500 average_loss = 0.609137\n",
            "\n",
            "2020-01-19 17:54:38 start epoch 21/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 17:54:38 iter 1 loss = 0.692917\n",
            "2020-01-19 17:54:41 iter 25 loss = 0.840098\n",
            "2020-01-19 17:54:44 iter 50 loss = 0.692271\n",
            "2020-01-19 17:54:47 iter 75 loss = 0.630984\n",
            "2020-01-19 17:54:50 iter 100 loss = 0.646251\n",
            "2020-01-19 17:54:50 epoch 21/500 average_loss = 0.610502\n",
            "\n",
            "2020-01-19 17:54:50 start epoch 22/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 17:54:50 iter 1 loss = 0.560043\n",
            "2020-01-19 17:54:53 iter 25 loss = 0.607479\n",
            "2020-01-19 17:54:57 iter 50 loss = 0.587613\n",
            "2020-01-19 17:55:00 iter 75 loss = 0.530664\n",
            "2020-01-19 17:55:03 iter 100 loss = 0.567080\n",
            "2020-01-19 17:55:03 epoch 22/500 average_loss = 0.610796\n",
            "\n",
            "2020-01-19 17:55:03 start epoch 23/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 17:55:03 iter 1 loss = 0.580832\n",
            "2020-01-19 17:55:06 iter 25 loss = 0.544616\n",
            "2020-01-19 17:55:09 iter 50 loss = 0.606710\n",
            "2020-01-19 17:55:13 iter 75 loss = 0.543785\n",
            "2020-01-19 17:55:16 iter 100 loss = 0.630284\n",
            "2020-01-19 17:55:16 epoch 23/500 average_loss = 0.602061\n",
            "\n",
            "2020-01-19 17:55:16 start epoch 24/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 17:55:16 iter 1 loss = 0.627987\n",
            "2020-01-19 17:55:19 iter 25 loss = 0.706623\n",
            "2020-01-19 17:55:22 iter 50 loss = 0.537492\n",
            "2020-01-19 17:55:25 iter 75 loss = 0.592996\n",
            "2020-01-19 17:55:29 iter 100 loss = 0.520511\n",
            "2020-01-19 17:55:29 epoch 24/500 average_loss = 0.603969\n",
            "\n",
            "2020-01-19 17:55:29 start epoch 25/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 17:55:29 iter 1 loss = 0.538121\n",
            "2020-01-19 17:55:32 iter 25 loss = 0.558683\n",
            "2020-01-19 17:55:35 iter 50 loss = 0.606164\n",
            "2020-01-19 17:55:38 iter 75 loss = 0.660808\n",
            "2020-01-19 17:55:41 iter 100 loss = 0.534080\n",
            "2020-01-19 17:55:41 epoch 25/500 average_loss = 0.600671\n",
            "\n",
            "2020-01-19 17:55:41 start epoch 26/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 17:55:41 iter 1 loss = 0.665442\n",
            "2020-01-19 17:55:44 iter 25 loss = 0.628538\n",
            "2020-01-19 17:55:48 iter 50 loss = 0.458644\n",
            "2020-01-19 17:55:51 iter 75 loss = 0.531584\n",
            "2020-01-19 17:55:54 iter 100 loss = 0.634174\n",
            "2020-01-19 17:55:54 epoch 26/500 average_loss = 0.594613\n",
            "\n",
            "2020-01-19 17:55:54 start epoch 27/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 17:55:54 iter 1 loss = 0.590771\n",
            "2020-01-19 17:55:57 iter 25 loss = 0.557512\n",
            "2020-01-19 17:56:00 iter 50 loss = 0.591671\n",
            "2020-01-19 17:56:03 iter 75 loss = 0.648169\n",
            "2020-01-19 17:56:07 iter 100 loss = 0.576617\n",
            "2020-01-19 17:56:07 epoch 27/500 average_loss = 0.591575\n",
            "\n",
            "2020-01-19 17:56:07 start epoch 28/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 17:56:07 iter 1 loss = 0.572207\n",
            "2020-01-19 17:56:10 iter 25 loss = 0.662184\n",
            "2020-01-19 17:56:13 iter 50 loss = 0.518796\n",
            "2020-01-19 17:56:16 iter 75 loss = 0.569262\n",
            "2020-01-19 17:56:20 iter 100 loss = 0.559752\n",
            "2020-01-19 17:56:20 epoch 28/500 average_loss = 0.586793\n",
            "\n",
            "2020-01-19 17:56:20 start epoch 29/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 17:56:20 iter 1 loss = 0.622344\n",
            "2020-01-19 17:56:23 iter 25 loss = 0.547445\n",
            "2020-01-19 17:56:26 iter 50 loss = 0.698168\n",
            "2020-01-19 17:56:29 iter 75 loss = 0.745777\n",
            "2020-01-19 17:56:32 iter 100 loss = 0.567132\n",
            "2020-01-19 17:56:32 epoch 29/500 average_loss = 0.582476\n",
            "\n",
            "2020-01-19 17:56:32 start epoch 30/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 17:56:32 iter 1 loss = 0.507393\n",
            "2020-01-19 17:56:36 iter 25 loss = 0.778259\n",
            "2020-01-19 17:56:39 iter 50 loss = 0.559562\n",
            "2020-01-19 17:56:42 iter 75 loss = 0.560810\n",
            "2020-01-19 17:56:45 iter 100 loss = 0.591603\n",
            "2020-01-19 17:56:45 epoch 30/500 average_loss = 0.581160\n",
            "\n",
            "2020-01-19 17:56:45 start epoch 31/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 17:56:45 iter 1 loss = 0.456580\n",
            "2020-01-19 17:56:48 iter 25 loss = 0.611941\n",
            "2020-01-19 17:56:51 iter 50 loss = 0.669610\n",
            "2020-01-19 17:56:55 iter 75 loss = 0.599627\n",
            "2020-01-19 17:56:58 iter 100 loss = 0.482671\n",
            "2020-01-19 17:56:58 epoch 31/500 average_loss = 0.577012\n",
            "\n",
            "2020-01-19 17:56:58 start epoch 32/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 17:56:58 iter 1 loss = 0.629138\n",
            "2020-01-19 17:57:01 iter 25 loss = 0.501046\n",
            "2020-01-19 17:57:04 iter 50 loss = 0.513771\n",
            "2020-01-19 17:57:07 iter 75 loss = 0.675766\n",
            "2020-01-19 17:57:10 iter 100 loss = 0.491661\n",
            "2020-01-19 17:57:10 epoch 32/500 average_loss = 0.570466\n",
            "\n",
            "2020-01-19 17:57:10 start epoch 33/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 17:57:11 iter 1 loss = 0.788638\n",
            "2020-01-19 17:57:14 iter 25 loss = 0.462646\n",
            "2020-01-19 17:57:17 iter 50 loss = 0.542748\n",
            "2020-01-19 17:57:20 iter 75 loss = 0.632227\n",
            "2020-01-19 17:57:23 iter 100 loss = 0.563842\n",
            "2020-01-19 17:57:23 epoch 33/500 average_loss = 0.566737\n",
            "\n",
            "2020-01-19 17:57:23 start epoch 34/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 17:57:23 iter 1 loss = 0.561500\n",
            "2020-01-19 17:57:26 iter 25 loss = 0.657279\n",
            "2020-01-19 17:57:30 iter 50 loss = 0.531725\n",
            "2020-01-19 17:57:33 iter 75 loss = 0.506027\n",
            "2020-01-19 17:57:36 iter 100 loss = 0.492512\n",
            "2020-01-19 17:57:36 epoch 34/500 average_loss = 0.562810\n",
            "\n",
            "2020-01-19 17:57:36 start epoch 35/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 17:57:36 iter 1 loss = 0.568138\n",
            "2020-01-19 17:57:39 iter 25 loss = 0.578421\n",
            "2020-01-19 17:57:42 iter 50 loss = 0.441722\n",
            "2020-01-19 17:57:46 iter 75 loss = 0.617368\n",
            "2020-01-19 17:57:49 iter 100 loss = 0.786415\n",
            "2020-01-19 17:57:49 epoch 35/500 average_loss = 0.555254\n",
            "\n",
            "2020-01-19 17:57:49 start epoch 36/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 17:57:49 iter 1 loss = 0.586475\n",
            "2020-01-19 17:57:52 iter 25 loss = 0.513636\n",
            "2020-01-19 17:57:55 iter 50 loss = 0.466468\n",
            "2020-01-19 17:57:58 iter 75 loss = 0.648555\n",
            "2020-01-19 17:58:01 iter 100 loss = 0.443173\n",
            "2020-01-19 17:58:01 epoch 36/500 average_loss = 0.547107\n",
            "\n",
            "2020-01-19 17:58:01 start epoch 37/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 17:58:02 iter 1 loss = 0.684760\n",
            "2020-01-19 17:58:05 iter 25 loss = 0.538975\n",
            "2020-01-19 17:58:08 iter 50 loss = 0.632402\n",
            "2020-01-19 17:58:11 iter 75 loss = 0.479195\n",
            "2020-01-19 17:58:14 iter 100 loss = 0.515862\n",
            "2020-01-19 17:58:14 epoch 37/500 average_loss = 0.540909\n",
            "\n",
            "2020-01-19 17:58:14 start epoch 38/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 17:58:14 iter 1 loss = 0.487773\n",
            "2020-01-19 17:58:18 iter 25 loss = 0.598582\n",
            "2020-01-19 17:58:21 iter 50 loss = 0.447414\n",
            "2020-01-19 17:58:24 iter 75 loss = 0.564282\n",
            "2020-01-19 17:58:27 iter 100 loss = 0.548125\n",
            "2020-01-19 17:58:27 epoch 38/500 average_loss = 0.534415\n",
            "\n",
            "2020-01-19 17:58:27 start epoch 39/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 17:58:27 iter 1 loss = 0.546017\n",
            "2020-01-19 17:58:30 iter 25 loss = 0.421817\n",
            "2020-01-19 17:58:33 iter 50 loss = 0.489485\n",
            "2020-01-19 17:58:37 iter 75 loss = 0.733208\n",
            "2020-01-19 17:58:40 iter 100 loss = 0.412354\n",
            "2020-01-19 17:58:40 epoch 39/500 average_loss = 0.529586\n",
            "\n",
            "2020-01-19 17:58:40 start epoch 40/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 17:58:40 iter 1 loss = 0.539046\n",
            "2020-01-19 17:58:43 iter 25 loss = 0.496487\n",
            "2020-01-19 17:58:46 iter 50 loss = 0.502384\n",
            "2020-01-19 17:58:49 iter 75 loss = 0.495537\n",
            "2020-01-19 17:58:53 iter 100 loss = 0.511475\n",
            "2020-01-19 17:58:53 epoch 40/500 average_loss = 0.523704\n",
            "\n",
            "2020-01-19 17:58:53 start epoch 41/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 17:58:53 iter 1 loss = 0.529404\n",
            "2020-01-19 17:58:56 iter 25 loss = 0.476255\n",
            "2020-01-19 17:58:59 iter 50 loss = 0.536757\n",
            "2020-01-19 17:59:02 iter 75 loss = 0.549346\n",
            "2020-01-19 17:59:05 iter 100 loss = 0.519614\n",
            "2020-01-19 17:59:05 epoch 41/500 average_loss = 0.516256\n",
            "\n",
            "2020-01-19 17:59:05 start epoch 42/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 17:59:05 iter 1 loss = 0.511691\n",
            "2020-01-19 17:59:08 iter 25 loss = 0.538801\n",
            "2020-01-19 17:59:12 iter 50 loss = 0.490854\n",
            "2020-01-19 17:59:15 iter 75 loss = 0.487060\n",
            "2020-01-19 17:59:18 iter 100 loss = 0.454588\n",
            "2020-01-19 17:59:18 epoch 42/500 average_loss = 0.510227\n",
            "\n",
            "2020-01-19 17:59:18 start epoch 43/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 17:59:18 iter 1 loss = 0.521988\n",
            "2020-01-19 17:59:21 iter 25 loss = 0.387211\n",
            "2020-01-19 17:59:24 iter 50 loss = 0.570445\n",
            "2020-01-19 17:59:28 iter 75 loss = 0.494861\n",
            "2020-01-19 17:59:31 iter 100 loss = 0.573691\n",
            "2020-01-19 17:59:31 epoch 43/500 average_loss = 0.503519\n",
            "\n",
            "2020-01-19 17:59:31 start epoch 44/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 17:59:31 iter 1 loss = 0.569920\n",
            "2020-01-19 17:59:34 iter 25 loss = 0.561548\n",
            "2020-01-19 17:59:37 iter 50 loss = 0.441776\n",
            "2020-01-19 17:59:40 iter 75 loss = 0.472110\n",
            "2020-01-19 17:59:43 iter 100 loss = 0.540012\n",
            "2020-01-19 17:59:43 epoch 44/500 average_loss = 0.496639\n",
            "\n",
            "2020-01-19 17:59:43 start epoch 45/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 17:59:44 iter 1 loss = 0.521361\n",
            "2020-01-19 17:59:47 iter 25 loss = 0.553648\n",
            "2020-01-19 17:59:50 iter 50 loss = 0.474210\n",
            "2020-01-19 17:59:53 iter 75 loss = 0.437790\n",
            "2020-01-19 17:59:56 iter 100 loss = 0.532783\n",
            "2020-01-19 17:59:56 epoch 45/500 average_loss = 0.485678\n",
            "\n",
            "2020-01-19 17:59:56 start epoch 46/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 17:59:56 iter 1 loss = 0.425983\n",
            "2020-01-19 17:59:59 iter 25 loss = 0.477552\n",
            "2020-01-19 18:00:03 iter 50 loss = 0.538194\n",
            "2020-01-19 18:00:06 iter 75 loss = 0.444044\n",
            "2020-01-19 18:00:09 iter 100 loss = 0.419004\n",
            "2020-01-19 18:00:09 epoch 46/500 average_loss = 0.483055\n",
            "\n",
            "2020-01-19 18:00:09 start epoch 47/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:00:09 iter 1 loss = 0.516664\n",
            "2020-01-19 18:00:12 iter 25 loss = 0.448020\n",
            "2020-01-19 18:00:15 iter 50 loss = 0.458684\n",
            "2020-01-19 18:00:18 iter 75 loss = 0.542178\n",
            "2020-01-19 18:00:22 iter 100 loss = 0.454529\n",
            "2020-01-19 18:00:22 epoch 47/500 average_loss = 0.476202\n",
            "\n",
            "2020-01-19 18:00:22 start epoch 48/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:00:22 iter 1 loss = 0.448356\n",
            "2020-01-19 18:00:25 iter 25 loss = 0.558673\n",
            "2020-01-19 18:00:28 iter 50 loss = 0.473984\n",
            "2020-01-19 18:00:31 iter 75 loss = 0.498735\n",
            "2020-01-19 18:00:34 iter 100 loss = 0.502930\n",
            "2020-01-19 18:00:34 epoch 48/500 average_loss = 0.468871\n",
            "\n",
            "2020-01-19 18:00:34 start epoch 49/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:00:34 iter 1 loss = 0.425237\n",
            "2020-01-19 18:00:38 iter 25 loss = 0.426733\n",
            "2020-01-19 18:00:41 iter 50 loss = 0.366064\n",
            "2020-01-19 18:00:44 iter 75 loss = 0.543037\n",
            "2020-01-19 18:00:47 iter 100 loss = 0.442312\n",
            "2020-01-19 18:00:47 epoch 49/500 average_loss = 0.458543\n",
            "\n",
            "2020-01-19 18:00:47 start epoch 50/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:00:47 iter 1 loss = 0.420472\n",
            "2020-01-19 18:00:50 iter 25 loss = 0.360833\n",
            "2020-01-19 18:00:53 iter 50 loss = 0.448952\n",
            "2020-01-19 18:00:57 iter 75 loss = 0.433782\n",
            "2020-01-19 18:01:00 iter 100 loss = 0.396632\n",
            "2020-01-19 18:01:00 epoch 50/500 average_loss = 0.454493\n",
            "\n",
            "2020-01-19 18:01:00 start epoch 51/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:01:00 iter 1 loss = 0.521279\n",
            "2020-01-19 18:01:03 iter 25 loss = 0.420714\n",
            "2020-01-19 18:01:06 iter 50 loss = 0.428970\n",
            "2020-01-19 18:01:09 iter 75 loss = 0.445050\n",
            "2020-01-19 18:01:13 iter 100 loss = 0.451166\n",
            "2020-01-19 18:01:13 epoch 51/500 average_loss = 0.445692\n",
            "\n",
            "2020-01-19 18:01:13 start epoch 52/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:01:13 iter 1 loss = 0.358994\n",
            "2020-01-19 18:01:16 iter 25 loss = 0.446815\n",
            "2020-01-19 18:01:19 iter 50 loss = 0.446453\n",
            "2020-01-19 18:01:22 iter 75 loss = 0.402070\n",
            "2020-01-19 18:01:25 iter 100 loss = 0.414562\n",
            "2020-01-19 18:01:25 epoch 52/500 average_loss = 0.440615\n",
            "\n",
            "2020-01-19 18:01:25 start epoch 53/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:01:25 iter 1 loss = 0.441866\n",
            "2020-01-19 18:01:28 iter 25 loss = 0.454646\n",
            "2020-01-19 18:01:32 iter 50 loss = 0.415516\n",
            "2020-01-19 18:01:35 iter 75 loss = 0.412758\n",
            "2020-01-19 18:01:38 iter 100 loss = 0.505593\n",
            "2020-01-19 18:01:38 epoch 53/500 average_loss = 0.428454\n",
            "\n",
            "2020-01-19 18:01:38 start epoch 54/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:01:38 iter 1 loss = 0.433514\n",
            "2020-01-19 18:01:41 iter 25 loss = 0.405421\n",
            "2020-01-19 18:01:44 iter 50 loss = 0.443306\n",
            "2020-01-19 18:01:47 iter 75 loss = 0.336254\n",
            "2020-01-19 18:01:51 iter 100 loss = 0.365222\n",
            "2020-01-19 18:01:51 epoch 54/500 average_loss = 0.425180\n",
            "\n",
            "2020-01-19 18:01:51 start epoch 55/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:01:51 iter 1 loss = 0.469136\n",
            "2020-01-19 18:01:54 iter 25 loss = 0.464258\n",
            "2020-01-19 18:01:57 iter 50 loss = 0.402597\n",
            "2020-01-19 18:02:00 iter 75 loss = 0.368685\n",
            "2020-01-19 18:02:03 iter 100 loss = 0.397694\n",
            "2020-01-19 18:02:03 epoch 55/500 average_loss = 0.415397\n",
            "\n",
            "2020-01-19 18:02:03 start epoch 56/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:02:03 iter 1 loss = 0.323398\n",
            "2020-01-19 18:02:06 iter 25 loss = 0.463691\n",
            "2020-01-19 18:02:10 iter 50 loss = 0.412768\n",
            "2020-01-19 18:02:13 iter 75 loss = 0.394387\n",
            "2020-01-19 18:02:16 iter 100 loss = 0.433122\n",
            "2020-01-19 18:02:16 epoch 56/500 average_loss = 0.409929\n",
            "\n",
            "2020-01-19 18:02:16 start epoch 57/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:02:16 iter 1 loss = 0.448049\n",
            "2020-01-19 18:02:19 iter 25 loss = 0.461034\n",
            "2020-01-19 18:02:22 iter 50 loss = 0.379842\n",
            "2020-01-19 18:02:26 iter 75 loss = 0.438617\n",
            "2020-01-19 18:02:29 iter 100 loss = 0.449050\n",
            "2020-01-19 18:02:29 epoch 57/500 average_loss = 0.399344\n",
            "\n",
            "2020-01-19 18:02:29 start epoch 58/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:02:29 iter 1 loss = 0.383678\n",
            "2020-01-19 18:02:32 iter 25 loss = 0.455676\n",
            "2020-01-19 18:02:35 iter 50 loss = 0.405808\n",
            "2020-01-19 18:02:38 iter 75 loss = 0.391409\n",
            "2020-01-19 18:02:41 iter 100 loss = 0.376583\n",
            "2020-01-19 18:02:41 epoch 58/500 average_loss = 0.394240\n",
            "\n",
            "2020-01-19 18:02:41 start epoch 59/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:02:42 iter 1 loss = 0.388245\n",
            "2020-01-19 18:02:45 iter 25 loss = 0.510543\n",
            "2020-01-19 18:02:48 iter 50 loss = 0.458173\n",
            "2020-01-19 18:02:51 iter 75 loss = 0.480299\n",
            "2020-01-19 18:02:54 iter 100 loss = 0.384196\n",
            "2020-01-19 18:02:54 epoch 59/500 average_loss = 0.387730\n",
            "\n",
            "2020-01-19 18:02:54 start epoch 60/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:02:54 iter 1 loss = 0.343428\n",
            "2020-01-19 18:02:57 iter 25 loss = 0.398826\n",
            "2020-01-19 18:03:00 iter 50 loss = 0.353519\n",
            "2020-01-19 18:03:04 iter 75 loss = 0.338965\n",
            "2020-01-19 18:03:07 iter 100 loss = 0.470513\n",
            "2020-01-19 18:03:07 epoch 60/500 average_loss = 0.376732\n",
            "\n",
            "2020-01-19 18:03:07 start epoch 61/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:03:07 iter 1 loss = 0.352618\n",
            "2020-01-19 18:03:10 iter 25 loss = 0.418614\n",
            "2020-01-19 18:03:13 iter 50 loss = 0.373241\n",
            "2020-01-19 18:03:16 iter 75 loss = 0.473700\n",
            "2020-01-19 18:03:20 iter 100 loss = 0.398162\n",
            "2020-01-19 18:03:20 epoch 61/500 average_loss = 0.374484\n",
            "\n",
            "2020-01-19 18:03:20 start epoch 62/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:03:20 iter 1 loss = 0.299946\n",
            "2020-01-19 18:03:23 iter 25 loss = 0.371143\n",
            "2020-01-19 18:03:26 iter 50 loss = 0.324258\n",
            "2020-01-19 18:03:29 iter 75 loss = 0.287145\n",
            "2020-01-19 18:03:32 iter 100 loss = 0.329432\n",
            "2020-01-19 18:03:32 epoch 62/500 average_loss = 0.364034\n",
            "\n",
            "2020-01-19 18:03:32 start epoch 63/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:03:32 iter 1 loss = 0.391871\n",
            "2020-01-19 18:03:35 iter 25 loss = 0.384209\n",
            "2020-01-19 18:03:39 iter 50 loss = 0.275022\n",
            "2020-01-19 18:03:42 iter 75 loss = 0.356991\n",
            "2020-01-19 18:03:45 iter 100 loss = 0.389392\n",
            "2020-01-19 18:03:45 epoch 63/500 average_loss = 0.354298\n",
            "\n",
            "2020-01-19 18:03:45 start epoch 64/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:03:45 iter 1 loss = 0.306449\n",
            "2020-01-19 18:03:48 iter 25 loss = 0.329261\n",
            "2020-01-19 18:03:51 iter 50 loss = 0.332031\n",
            "2020-01-19 18:03:54 iter 75 loss = 0.259227\n",
            "2020-01-19 18:03:58 iter 100 loss = 0.400468\n",
            "2020-01-19 18:03:58 epoch 64/500 average_loss = 0.354296\n",
            "\n",
            "2020-01-19 18:03:58 start epoch 65/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:03:58 iter 1 loss = 0.328296\n",
            "2020-01-19 18:04:01 iter 25 loss = 0.307070\n",
            "2020-01-19 18:04:04 iter 50 loss = 0.340369\n",
            "2020-01-19 18:04:07 iter 75 loss = 0.304388\n",
            "2020-01-19 18:04:10 iter 100 loss = 0.338159\n",
            "2020-01-19 18:04:10 epoch 65/500 average_loss = 0.341484\n",
            "\n",
            "2020-01-19 18:04:10 start epoch 66/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:04:10 iter 1 loss = 0.396197\n",
            "2020-01-19 18:04:13 iter 25 loss = 0.274457\n",
            "2020-01-19 18:04:17 iter 50 loss = 0.342158\n",
            "2020-01-19 18:04:20 iter 75 loss = 0.290495\n",
            "2020-01-19 18:04:23 iter 100 loss = 0.346029\n",
            "2020-01-19 18:04:23 epoch 66/500 average_loss = 0.334370\n",
            "\n",
            "2020-01-19 18:04:23 start epoch 67/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:04:23 iter 1 loss = 0.352370\n",
            "2020-01-19 18:04:26 iter 25 loss = 0.295199\n",
            "2020-01-19 18:04:29 iter 50 loss = 0.288606\n",
            "2020-01-19 18:04:33 iter 75 loss = 0.296324\n",
            "2020-01-19 18:04:36 iter 100 loss = 0.272120\n",
            "2020-01-19 18:04:36 epoch 67/500 average_loss = 0.328921\n",
            "\n",
            "2020-01-19 18:04:36 start epoch 68/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:04:36 iter 1 loss = 0.279818\n",
            "2020-01-19 18:04:39 iter 25 loss = 0.376978\n",
            "2020-01-19 18:04:42 iter 50 loss = 0.340983\n",
            "2020-01-19 18:04:45 iter 75 loss = 0.411199\n",
            "2020-01-19 18:04:48 iter 100 loss = 0.361133\n",
            "2020-01-19 18:04:48 epoch 68/500 average_loss = 0.320402\n",
            "\n",
            "2020-01-19 18:04:48 start epoch 69/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:04:49 iter 1 loss = 0.304466\n",
            "2020-01-19 18:04:52 iter 25 loss = 0.282115\n",
            "2020-01-19 18:04:55 iter 50 loss = 0.343630\n",
            "2020-01-19 18:04:58 iter 75 loss = 0.315619\n",
            "2020-01-19 18:05:01 iter 100 loss = 0.335404\n",
            "2020-01-19 18:05:01 epoch 69/500 average_loss = 0.317276\n",
            "\n",
            "2020-01-19 18:05:01 start epoch 70/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:05:01 iter 1 loss = 0.315616\n",
            "2020-01-19 18:05:04 iter 25 loss = 0.304175\n",
            "2020-01-19 18:05:08 iter 50 loss = 0.322130\n",
            "2020-01-19 18:05:11 iter 75 loss = 0.320248\n",
            "2020-01-19 18:05:14 iter 100 loss = 0.401837\n",
            "2020-01-19 18:05:14 epoch 70/500 average_loss = 0.317363\n",
            "\n",
            "2020-01-19 18:05:14 start epoch 71/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:05:14 iter 1 loss = 0.337647\n",
            "2020-01-19 18:05:17 iter 25 loss = 0.281663\n",
            "2020-01-19 18:05:20 iter 50 loss = 0.266656\n",
            "2020-01-19 18:05:23 iter 75 loss = 0.286766\n",
            "2020-01-19 18:05:27 iter 100 loss = 0.405776\n",
            "2020-01-19 18:05:27 epoch 71/500 average_loss = 0.303550\n",
            "\n",
            "2020-01-19 18:05:27 start epoch 72/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:05:27 iter 1 loss = 0.321820\n",
            "2020-01-19 18:05:30 iter 25 loss = 0.247435\n",
            "2020-01-19 18:05:33 iter 50 loss = 0.330518\n",
            "2020-01-19 18:05:36 iter 75 loss = 0.375812\n",
            "2020-01-19 18:05:39 iter 100 loss = 0.334610\n",
            "2020-01-19 18:05:39 epoch 72/500 average_loss = 0.298816\n",
            "\n",
            "2020-01-19 18:05:39 start epoch 73/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:05:39 iter 1 loss = 0.307043\n",
            "2020-01-19 18:05:42 iter 25 loss = 0.237473\n",
            "2020-01-19 18:05:46 iter 50 loss = 0.276760\n",
            "2020-01-19 18:05:49 iter 75 loss = 0.368103\n",
            "2020-01-19 18:05:52 iter 100 loss = 0.338769\n",
            "2020-01-19 18:05:52 epoch 73/500 average_loss = 0.293220\n",
            "\n",
            "2020-01-19 18:05:52 start epoch 74/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:05:52 iter 1 loss = 0.251612\n",
            "2020-01-19 18:05:55 iter 25 loss = 0.329710\n",
            "2020-01-19 18:05:58 iter 50 loss = 0.283043\n",
            "2020-01-19 18:06:01 iter 75 loss = 0.301154\n",
            "2020-01-19 18:06:05 iter 100 loss = 0.280303\n",
            "2020-01-19 18:06:05 epoch 74/500 average_loss = 0.288184\n",
            "\n",
            "2020-01-19 18:06:05 start epoch 75/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:06:05 iter 1 loss = 0.317312\n",
            "2020-01-19 18:06:08 iter 25 loss = 0.257211\n",
            "2020-01-19 18:06:11 iter 50 loss = 0.258832\n",
            "2020-01-19 18:06:14 iter 75 loss = 0.295460\n",
            "2020-01-19 18:06:17 iter 100 loss = 0.230362\n",
            "2020-01-19 18:06:17 epoch 75/500 average_loss = 0.277963\n",
            "\n",
            "2020-01-19 18:06:17 start epoch 76/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:06:17 iter 1 loss = 0.308852\n",
            "2020-01-19 18:06:20 iter 25 loss = 0.341831\n",
            "2020-01-19 18:06:24 iter 50 loss = 0.236811\n",
            "2020-01-19 18:06:27 iter 75 loss = 0.286380\n",
            "2020-01-19 18:06:30 iter 100 loss = 0.299839\n",
            "2020-01-19 18:06:30 epoch 76/500 average_loss = 0.279706\n",
            "\n",
            "2020-01-19 18:06:30 start epoch 77/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:06:30 iter 1 loss = 0.307748\n",
            "2020-01-19 18:06:33 iter 25 loss = 0.246068\n",
            "2020-01-19 18:06:36 iter 50 loss = 0.279070\n",
            "2020-01-19 18:06:39 iter 75 loss = 0.322861\n",
            "2020-01-19 18:06:43 iter 100 loss = 0.310796\n",
            "2020-01-19 18:06:43 epoch 77/500 average_loss = 0.270700\n",
            "\n",
            "2020-01-19 18:06:43 start epoch 78/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:06:43 iter 1 loss = 0.348069\n",
            "2020-01-19 18:06:46 iter 25 loss = 0.288362\n",
            "2020-01-19 18:06:49 iter 50 loss = 0.205657\n",
            "2020-01-19 18:06:52 iter 75 loss = 0.285263\n",
            "2020-01-19 18:06:55 iter 100 loss = 0.308964\n",
            "2020-01-19 18:06:55 epoch 78/500 average_loss = 0.267574\n",
            "\n",
            "2020-01-19 18:06:55 start epoch 79/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:06:55 iter 1 loss = 0.347004\n",
            "2020-01-19 18:06:59 iter 25 loss = 0.221151\n",
            "2020-01-19 18:07:02 iter 50 loss = 0.210273\n",
            "2020-01-19 18:07:05 iter 75 loss = 0.255056\n",
            "2020-01-19 18:07:08 iter 100 loss = 0.288197\n",
            "2020-01-19 18:07:08 epoch 79/500 average_loss = 0.260985\n",
            "\n",
            "2020-01-19 18:07:08 start epoch 80/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:07:08 iter 1 loss = 0.254564\n",
            "2020-01-19 18:07:11 iter 25 loss = 0.311799\n",
            "2020-01-19 18:07:14 iter 50 loss = 0.234558\n",
            "2020-01-19 18:07:18 iter 75 loss = 0.241688\n",
            "2020-01-19 18:07:21 iter 100 loss = 0.292978\n",
            "2020-01-19 18:07:21 epoch 80/500 average_loss = 0.259520\n",
            "\n",
            "2020-01-19 18:07:21 start epoch 81/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:07:21 iter 1 loss = 0.253184\n",
            "2020-01-19 18:07:24 iter 25 loss = 0.275505\n",
            "2020-01-19 18:07:27 iter 50 loss = 0.245340\n",
            "2020-01-19 18:07:30 iter 75 loss = 0.297270\n",
            "2020-01-19 18:07:34 iter 100 loss = 0.267956\n",
            "2020-01-19 18:07:34 epoch 81/500 average_loss = 0.253398\n",
            "\n",
            "2020-01-19 18:07:34 start epoch 82/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:07:34 iter 1 loss = 0.275603\n",
            "2020-01-19 18:07:37 iter 25 loss = 0.251094\n",
            "2020-01-19 18:07:40 iter 50 loss = 0.288774\n",
            "2020-01-19 18:07:43 iter 75 loss = 0.230152\n",
            "2020-01-19 18:07:46 iter 100 loss = 0.198319\n",
            "2020-01-19 18:07:46 epoch 82/500 average_loss = 0.243111\n",
            "\n",
            "2020-01-19 18:07:46 start epoch 83/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:07:46 iter 1 loss = 0.230943\n",
            "2020-01-19 18:07:50 iter 25 loss = 0.258210\n",
            "2020-01-19 18:07:53 iter 50 loss = 0.228229\n",
            "2020-01-19 18:07:56 iter 75 loss = 0.246441\n",
            "2020-01-19 18:07:59 iter 100 loss = 0.230543\n",
            "2020-01-19 18:07:59 epoch 83/500 average_loss = 0.241867\n",
            "\n",
            "2020-01-19 18:07:59 start epoch 84/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:07:59 iter 1 loss = 0.258681\n",
            "2020-01-19 18:08:02 iter 25 loss = 0.219123\n",
            "2020-01-19 18:08:05 iter 50 loss = 0.223800\n",
            "2020-01-19 18:08:08 iter 75 loss = 0.260919\n",
            "2020-01-19 18:08:12 iter 100 loss = 0.229626\n",
            "2020-01-19 18:08:12 epoch 84/500 average_loss = 0.245641\n",
            "\n",
            "2020-01-19 18:08:12 start epoch 85/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:08:12 iter 1 loss = 0.215199\n",
            "2020-01-19 18:08:15 iter 25 loss = 0.276950\n",
            "2020-01-19 18:08:18 iter 50 loss = 0.194654\n",
            "2020-01-19 18:08:21 iter 75 loss = 0.244177\n",
            "2020-01-19 18:08:24 iter 100 loss = 0.214571\n",
            "2020-01-19 18:08:24 epoch 85/500 average_loss = 0.236744\n",
            "\n",
            "2020-01-19 18:08:24 start epoch 86/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:08:25 iter 1 loss = 0.231242\n",
            "2020-01-19 18:08:28 iter 25 loss = 0.202177\n",
            "2020-01-19 18:08:31 iter 50 loss = 0.215841\n",
            "2020-01-19 18:08:34 iter 75 loss = 0.230162\n",
            "2020-01-19 18:08:37 iter 100 loss = 0.216091\n",
            "2020-01-19 18:08:37 epoch 86/500 average_loss = 0.231725\n",
            "\n",
            "2020-01-19 18:08:37 start epoch 87/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:08:37 iter 1 loss = 0.234916\n",
            "2020-01-19 18:08:40 iter 25 loss = 0.221295\n",
            "2020-01-19 18:08:43 iter 50 loss = 0.247603\n",
            "2020-01-19 18:08:47 iter 75 loss = 0.209846\n",
            "2020-01-19 18:08:50 iter 100 loss = 0.204053\n",
            "2020-01-19 18:08:50 epoch 87/500 average_loss = 0.227418\n",
            "\n",
            "2020-01-19 18:08:50 start epoch 88/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:08:50 iter 1 loss = 0.205462\n",
            "2020-01-19 18:08:53 iter 25 loss = 0.193496\n",
            "2020-01-19 18:08:56 iter 50 loss = 0.213881\n",
            "2020-01-19 18:08:59 iter 75 loss = 0.191979\n",
            "2020-01-19 18:09:02 iter 100 loss = 0.264676\n",
            "2020-01-19 18:09:02 epoch 88/500 average_loss = 0.223216\n",
            "\n",
            "2020-01-19 18:09:02 start epoch 89/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:09:03 iter 1 loss = 0.215752\n",
            "2020-01-19 18:09:06 iter 25 loss = 0.193262\n",
            "2020-01-19 18:09:09 iter 50 loss = 0.249083\n",
            "2020-01-19 18:09:12 iter 75 loss = 0.266148\n",
            "2020-01-19 18:09:15 iter 100 loss = 0.235735\n",
            "2020-01-19 18:09:15 epoch 89/500 average_loss = 0.222091\n",
            "\n",
            "2020-01-19 18:09:15 start epoch 90/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:09:15 iter 1 loss = 0.239532\n",
            "2020-01-19 18:09:18 iter 25 loss = 0.228945\n",
            "2020-01-19 18:09:21 iter 50 loss = 0.268792\n",
            "2020-01-19 18:09:25 iter 75 loss = 0.267371\n",
            "2020-01-19 18:09:28 iter 100 loss = 0.206945\n",
            "2020-01-19 18:09:28 epoch 90/500 average_loss = 0.218742\n",
            "\n",
            "2020-01-19 18:09:28 start epoch 91/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:09:28 iter 1 loss = 0.231921\n",
            "2020-01-19 18:09:31 iter 25 loss = 0.182999\n",
            "2020-01-19 18:09:34 iter 50 loss = 0.188204\n",
            "2020-01-19 18:09:37 iter 75 loss = 0.258000\n",
            "2020-01-19 18:09:41 iter 100 loss = 0.291736\n",
            "2020-01-19 18:09:41 epoch 91/500 average_loss = 0.213506\n",
            "\n",
            "2020-01-19 18:09:41 start epoch 92/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:09:41 iter 1 loss = 0.225048\n",
            "2020-01-19 18:09:44 iter 25 loss = 0.231887\n",
            "2020-01-19 18:09:47 iter 50 loss = 0.211376\n",
            "2020-01-19 18:09:50 iter 75 loss = 0.211329\n",
            "2020-01-19 18:09:53 iter 100 loss = 0.232903\n",
            "2020-01-19 18:09:53 epoch 92/500 average_loss = 0.214164\n",
            "\n",
            "2020-01-19 18:09:53 start epoch 93/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:09:53 iter 1 loss = 0.172390\n",
            "2020-01-19 18:09:56 iter 25 loss = 0.173510\n",
            "2020-01-19 18:10:00 iter 50 loss = 0.179977\n",
            "2020-01-19 18:10:03 iter 75 loss = 0.263512\n",
            "2020-01-19 18:10:06 iter 100 loss = 0.172248\n",
            "2020-01-19 18:10:06 epoch 93/500 average_loss = 0.213036\n",
            "\n",
            "2020-01-19 18:10:06 start epoch 94/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:10:06 iter 1 loss = 0.204756\n",
            "2020-01-19 18:10:09 iter 25 loss = 0.201746\n",
            "2020-01-19 18:10:12 iter 50 loss = 0.217063\n",
            "2020-01-19 18:10:16 iter 75 loss = 0.174505\n",
            "2020-01-19 18:10:19 iter 100 loss = 0.252507\n",
            "2020-01-19 18:10:19 epoch 94/500 average_loss = 0.212333\n",
            "\n",
            "2020-01-19 18:10:19 start epoch 95/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:10:19 iter 1 loss = 0.184596\n",
            "2020-01-19 18:10:22 iter 25 loss = 0.200030\n",
            "2020-01-19 18:10:25 iter 50 loss = 0.218668\n",
            "2020-01-19 18:10:28 iter 75 loss = 0.200545\n",
            "2020-01-19 18:10:32 iter 100 loss = 0.177521\n",
            "2020-01-19 18:10:32 epoch 95/500 average_loss = 0.203357\n",
            "\n",
            "2020-01-19 18:10:32 start epoch 96/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:10:32 iter 1 loss = 0.209023\n",
            "2020-01-19 18:10:35 iter 25 loss = 0.199912\n",
            "2020-01-19 18:10:38 iter 50 loss = 0.206807\n",
            "2020-01-19 18:10:41 iter 75 loss = 0.221844\n",
            "2020-01-19 18:10:44 iter 100 loss = 0.235603\n",
            "2020-01-19 18:10:44 epoch 96/500 average_loss = 0.199686\n",
            "\n",
            "2020-01-19 18:10:44 start epoch 97/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:10:44 iter 1 loss = 0.210501\n",
            "2020-01-19 18:10:47 iter 25 loss = 0.237731\n",
            "2020-01-19 18:10:50 iter 50 loss = 0.206896\n",
            "2020-01-19 18:10:54 iter 75 loss = 0.200595\n",
            "2020-01-19 18:10:57 iter 100 loss = 0.200471\n",
            "2020-01-19 18:10:57 epoch 97/500 average_loss = 0.196846\n",
            "\n",
            "2020-01-19 18:10:57 start epoch 98/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:10:57 iter 1 loss = 0.154406\n",
            "2020-01-19 18:11:00 iter 25 loss = 0.173615\n",
            "2020-01-19 18:11:03 iter 50 loss = 0.218574\n",
            "2020-01-19 18:11:06 iter 75 loss = 0.189245\n",
            "2020-01-19 18:11:10 iter 100 loss = 0.203967\n",
            "2020-01-19 18:11:10 epoch 98/500 average_loss = 0.196668\n",
            "\n",
            "2020-01-19 18:11:10 start epoch 99/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:11:10 iter 1 loss = 0.197156\n",
            "2020-01-19 18:11:13 iter 25 loss = 0.160863\n",
            "2020-01-19 18:11:16 iter 50 loss = 0.206345\n",
            "2020-01-19 18:11:19 iter 75 loss = 0.177116\n",
            "2020-01-19 18:11:22 iter 100 loss = 0.180390\n",
            "2020-01-19 18:11:22 epoch 99/500 average_loss = 0.190900\n",
            "\n",
            "2020-01-19 18:11:22 start epoch 100/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:11:22 iter 1 loss = 0.200981\n",
            "2020-01-19 18:11:26 iter 25 loss = 0.225213\n",
            "2020-01-19 18:11:29 iter 50 loss = 0.205409\n",
            "2020-01-19 18:11:32 iter 75 loss = 0.228390\n",
            "2020-01-19 18:11:35 iter 100 loss = 0.265058\n",
            "2020-01-19 18:11:35 epoch 100/500 average_loss = 0.193965\n",
            "\n",
            "2020-01-19 18:11:35 start epoch 101/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:11:35 iter 1 loss = 0.207355\n",
            "2020-01-19 18:11:38 iter 25 loss = 0.163487\n",
            "2020-01-19 18:11:41 iter 50 loss = 0.200604\n",
            "2020-01-19 18:11:45 iter 75 loss = 0.166403\n",
            "2020-01-19 18:11:48 iter 100 loss = 0.215221\n",
            "2020-01-19 18:11:48 epoch 101/500 average_loss = 0.188902\n",
            "\n",
            "2020-01-19 18:11:48 start epoch 102/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:11:48 iter 1 loss = 0.210452\n",
            "2020-01-19 18:11:51 iter 25 loss = 0.135913\n",
            "2020-01-19 18:11:54 iter 50 loss = 0.162113\n",
            "2020-01-19 18:11:57 iter 75 loss = 0.169513\n",
            "2020-01-19 18:12:01 iter 100 loss = 0.190681\n",
            "2020-01-19 18:12:01 epoch 102/500 average_loss = 0.189510\n",
            "\n",
            "2020-01-19 18:12:01 start epoch 103/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:12:01 iter 1 loss = 0.158318\n",
            "2020-01-19 18:12:04 iter 25 loss = 0.187495\n",
            "2020-01-19 18:12:07 iter 50 loss = 0.138693\n",
            "2020-01-19 18:12:10 iter 75 loss = 0.216552\n",
            "2020-01-19 18:12:13 iter 100 loss = 0.156663\n",
            "2020-01-19 18:12:13 epoch 103/500 average_loss = 0.184397\n",
            "\n",
            "2020-01-19 18:12:13 start epoch 104/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:12:13 iter 1 loss = 0.154983\n",
            "2020-01-19 18:12:16 iter 25 loss = 0.161272\n",
            "2020-01-19 18:12:20 iter 50 loss = 0.165354\n",
            "2020-01-19 18:12:23 iter 75 loss = 0.190320\n",
            "2020-01-19 18:12:26 iter 100 loss = 0.181004\n",
            "2020-01-19 18:12:26 epoch 104/500 average_loss = 0.187409\n",
            "\n",
            "2020-01-19 18:12:26 start epoch 105/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:12:26 iter 1 loss = 0.179199\n",
            "2020-01-19 18:12:29 iter 25 loss = 0.193016\n",
            "2020-01-19 18:12:32 iter 50 loss = 0.153256\n",
            "2020-01-19 18:12:35 iter 75 loss = 0.220280\n",
            "2020-01-19 18:12:38 iter 100 loss = 0.205410\n",
            "2020-01-19 18:12:38 epoch 105/500 average_loss = 0.186151\n",
            "\n",
            "2020-01-19 18:12:38 start epoch 106/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:12:39 iter 1 loss = 0.195614\n",
            "2020-01-19 18:12:42 iter 25 loss = 0.217852\n",
            "2020-01-19 18:12:45 iter 50 loss = 0.173466\n",
            "2020-01-19 18:12:48 iter 75 loss = 0.175689\n",
            "2020-01-19 18:12:51 iter 100 loss = 0.193737\n",
            "2020-01-19 18:12:51 epoch 106/500 average_loss = 0.183075\n",
            "\n",
            "2020-01-19 18:12:51 start epoch 107/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:12:51 iter 1 loss = 0.177159\n",
            "2020-01-19 18:12:54 iter 25 loss = 0.203044\n",
            "2020-01-19 18:12:57 iter 50 loss = 0.153624\n",
            "2020-01-19 18:13:01 iter 75 loss = 0.178141\n",
            "2020-01-19 18:13:04 iter 100 loss = 0.176710\n",
            "2020-01-19 18:13:04 epoch 107/500 average_loss = 0.178934\n",
            "\n",
            "2020-01-19 18:13:04 start epoch 108/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:13:04 iter 1 loss = 0.178360\n",
            "2020-01-19 18:13:07 iter 25 loss = 0.144951\n",
            "2020-01-19 18:13:10 iter 50 loss = 0.160017\n",
            "2020-01-19 18:13:13 iter 75 loss = 0.221326\n",
            "2020-01-19 18:13:17 iter 100 loss = 0.165006\n",
            "2020-01-19 18:13:17 epoch 108/500 average_loss = 0.171386\n",
            "\n",
            "2020-01-19 18:13:17 start epoch 109/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:13:17 iter 1 loss = 0.192048\n",
            "2020-01-19 18:13:20 iter 25 loss = 0.147050\n",
            "2020-01-19 18:13:23 iter 50 loss = 0.173647\n",
            "2020-01-19 18:13:26 iter 75 loss = 0.163429\n",
            "2020-01-19 18:13:29 iter 100 loss = 0.209404\n",
            "2020-01-19 18:13:29 epoch 109/500 average_loss = 0.170241\n",
            "\n",
            "2020-01-19 18:13:29 start epoch 110/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:13:29 iter 1 loss = 0.148476\n",
            "2020-01-19 18:13:32 iter 25 loss = 0.168949\n",
            "2020-01-19 18:13:36 iter 50 loss = 0.154091\n",
            "2020-01-19 18:13:39 iter 75 loss = 0.138759\n",
            "2020-01-19 18:13:42 iter 100 loss = 0.167683\n",
            "2020-01-19 18:13:42 epoch 110/500 average_loss = 0.167951\n",
            "\n",
            "2020-01-19 18:13:42 start epoch 111/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:13:42 iter 1 loss = 0.159536\n",
            "2020-01-19 18:13:45 iter 25 loss = 0.144524\n",
            "2020-01-19 18:13:48 iter 50 loss = 0.173438\n",
            "2020-01-19 18:13:52 iter 75 loss = 0.154725\n",
            "2020-01-19 18:13:55 iter 100 loss = 0.170953\n",
            "2020-01-19 18:13:55 epoch 111/500 average_loss = 0.170461\n",
            "\n",
            "2020-01-19 18:13:55 start epoch 112/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:13:55 iter 1 loss = 0.136104\n",
            "2020-01-19 18:13:58 iter 25 loss = 0.205412\n",
            "2020-01-19 18:14:01 iter 50 loss = 0.141182\n",
            "2020-01-19 18:14:04 iter 75 loss = 0.180666\n",
            "2020-01-19 18:14:07 iter 100 loss = 0.163290\n",
            "2020-01-19 18:14:07 epoch 112/500 average_loss = 0.168408\n",
            "\n",
            "2020-01-19 18:14:07 start epoch 113/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:14:08 iter 1 loss = 0.149334\n",
            "2020-01-19 18:14:11 iter 25 loss = 0.184353\n",
            "2020-01-19 18:14:14 iter 50 loss = 0.197798\n",
            "2020-01-19 18:14:17 iter 75 loss = 0.169365\n",
            "2020-01-19 18:14:20 iter 100 loss = 0.212358\n",
            "2020-01-19 18:14:20 epoch 113/500 average_loss = 0.166690\n",
            "\n",
            "2020-01-19 18:14:20 start epoch 114/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:14:20 iter 1 loss = 0.179306\n",
            "2020-01-19 18:14:23 iter 25 loss = 0.143237\n",
            "2020-01-19 18:14:27 iter 50 loss = 0.121770\n",
            "2020-01-19 18:14:30 iter 75 loss = 0.172689\n",
            "2020-01-19 18:14:33 iter 100 loss = 0.174233\n",
            "2020-01-19 18:14:33 epoch 114/500 average_loss = 0.163527\n",
            "\n",
            "2020-01-19 18:14:33 start epoch 115/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:14:33 iter 1 loss = 0.197952\n",
            "2020-01-19 18:14:36 iter 25 loss = 0.178553\n",
            "2020-01-19 18:14:39 iter 50 loss = 0.179826\n",
            "2020-01-19 18:14:42 iter 75 loss = 0.158152\n",
            "2020-01-19 18:14:46 iter 100 loss = 0.142232\n",
            "2020-01-19 18:14:46 epoch 115/500 average_loss = 0.166086\n",
            "\n",
            "2020-01-19 18:14:46 start epoch 116/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:14:46 iter 1 loss = 0.152809\n",
            "2020-01-19 18:14:49 iter 25 loss = 0.155709\n",
            "2020-01-19 18:14:52 iter 50 loss = 0.166728\n",
            "2020-01-19 18:14:55 iter 75 loss = 0.184006\n",
            "2020-01-19 18:14:58 iter 100 loss = 0.138630\n",
            "2020-01-19 18:14:58 epoch 116/500 average_loss = 0.162940\n",
            "\n",
            "2020-01-19 18:14:58 start epoch 117/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:14:58 iter 1 loss = 0.151827\n",
            "2020-01-19 18:15:01 iter 25 loss = 0.125609\n",
            "2020-01-19 18:15:05 iter 50 loss = 0.165185\n",
            "2020-01-19 18:15:08 iter 75 loss = 0.136847\n",
            "2020-01-19 18:15:11 iter 100 loss = 0.155573\n",
            "2020-01-19 18:15:11 epoch 117/500 average_loss = 0.159839\n",
            "\n",
            "2020-01-19 18:15:11 start epoch 118/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:15:11 iter 1 loss = 0.152731\n",
            "2020-01-19 18:15:14 iter 25 loss = 0.166931\n",
            "2020-01-19 18:15:17 iter 50 loss = 0.156019\n",
            "2020-01-19 18:15:20 iter 75 loss = 0.163616\n",
            "2020-01-19 18:15:24 iter 100 loss = 0.132585\n",
            "2020-01-19 18:15:24 epoch 118/500 average_loss = 0.158243\n",
            "\n",
            "2020-01-19 18:15:24 start epoch 119/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:15:24 iter 1 loss = 0.154331\n",
            "2020-01-19 18:15:27 iter 25 loss = 0.160936\n",
            "2020-01-19 18:15:30 iter 50 loss = 0.152119\n",
            "2020-01-19 18:15:33 iter 75 loss = 0.141005\n",
            "2020-01-19 18:15:36 iter 100 loss = 0.145259\n",
            "2020-01-19 18:15:36 epoch 119/500 average_loss = 0.156506\n",
            "\n",
            "2020-01-19 18:15:36 start epoch 120/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:15:36 iter 1 loss = 0.148123\n",
            "2020-01-19 18:15:39 iter 25 loss = 0.167768\n",
            "2020-01-19 18:15:43 iter 50 loss = 0.153282\n",
            "2020-01-19 18:15:46 iter 75 loss = 0.146381\n",
            "2020-01-19 18:15:49 iter 100 loss = 0.152141\n",
            "2020-01-19 18:15:49 epoch 120/500 average_loss = 0.158330\n",
            "\n",
            "2020-01-19 18:15:49 start epoch 121/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:15:49 iter 1 loss = 0.179769\n",
            "2020-01-19 18:15:52 iter 25 loss = 0.145121\n",
            "2020-01-19 18:15:55 iter 50 loss = 0.162483\n",
            "2020-01-19 18:15:59 iter 75 loss = 0.156596\n",
            "2020-01-19 18:16:02 iter 100 loss = 0.176592\n",
            "2020-01-19 18:16:02 epoch 121/500 average_loss = 0.158006\n",
            "\n",
            "2020-01-19 18:16:02 start epoch 122/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:16:02 iter 1 loss = 0.226995\n",
            "2020-01-19 18:16:05 iter 25 loss = 0.143243\n",
            "2020-01-19 18:16:08 iter 50 loss = 0.188507\n",
            "2020-01-19 18:16:11 iter 75 loss = 0.146077\n",
            "2020-01-19 18:16:14 iter 100 loss = 0.141265\n",
            "2020-01-19 18:16:14 epoch 122/500 average_loss = 0.155980\n",
            "\n",
            "2020-01-19 18:16:14 start epoch 123/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:16:15 iter 1 loss = 0.131001\n",
            "2020-01-19 18:16:18 iter 25 loss = 0.145239\n",
            "2020-01-19 18:16:21 iter 50 loss = 0.141735\n",
            "2020-01-19 18:16:24 iter 75 loss = 0.157555\n",
            "2020-01-19 18:16:27 iter 100 loss = 0.150443\n",
            "2020-01-19 18:16:27 epoch 123/500 average_loss = 0.146520\n",
            "\n",
            "2020-01-19 18:16:27 start epoch 124/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:16:27 iter 1 loss = 0.160112\n",
            "2020-01-19 18:16:30 iter 25 loss = 0.139686\n",
            "2020-01-19 18:16:33 iter 50 loss = 0.128810\n",
            "2020-01-19 18:16:37 iter 75 loss = 0.140817\n",
            "2020-01-19 18:16:40 iter 100 loss = 0.145662\n",
            "2020-01-19 18:16:40 epoch 124/500 average_loss = 0.151903\n",
            "\n",
            "2020-01-19 18:16:40 start epoch 125/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:16:40 iter 1 loss = 0.156900\n",
            "2020-01-19 18:16:43 iter 25 loss = 0.130685\n",
            "2020-01-19 18:16:46 iter 50 loss = 0.139538\n",
            "2020-01-19 18:16:49 iter 75 loss = 0.141118\n",
            "2020-01-19 18:16:53 iter 100 loss = 0.131860\n",
            "2020-01-19 18:16:53 epoch 125/500 average_loss = 0.147824\n",
            "\n",
            "2020-01-19 18:16:53 start epoch 126/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:16:53 iter 1 loss = 0.171436\n",
            "2020-01-19 18:16:56 iter 25 loss = 0.175093\n",
            "2020-01-19 18:16:59 iter 50 loss = 0.150751\n",
            "2020-01-19 18:17:02 iter 75 loss = 0.144232\n",
            "2020-01-19 18:17:05 iter 100 loss = 0.164512\n",
            "2020-01-19 18:17:05 epoch 126/500 average_loss = 0.148989\n",
            "\n",
            "2020-01-19 18:17:05 start epoch 127/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:17:05 iter 1 loss = 0.192733\n",
            "2020-01-19 18:17:08 iter 25 loss = 0.190672\n",
            "2020-01-19 18:17:11 iter 50 loss = 0.144227\n",
            "2020-01-19 18:17:15 iter 75 loss = 0.122049\n",
            "2020-01-19 18:17:18 iter 100 loss = 0.143745\n",
            "2020-01-19 18:17:18 epoch 127/500 average_loss = 0.148974\n",
            "\n",
            "2020-01-19 18:17:18 start epoch 128/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:17:18 iter 1 loss = 0.151041\n",
            "2020-01-19 18:17:21 iter 25 loss = 0.159386\n",
            "2020-01-19 18:17:24 iter 50 loss = 0.145368\n",
            "2020-01-19 18:17:27 iter 75 loss = 0.132617\n",
            "2020-01-19 18:17:31 iter 100 loss = 0.161917\n",
            "2020-01-19 18:17:31 epoch 128/500 average_loss = 0.144130\n",
            "\n",
            "2020-01-19 18:17:31 start epoch 129/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:17:31 iter 1 loss = 0.125773\n",
            "2020-01-19 18:17:34 iter 25 loss = 0.204455\n",
            "2020-01-19 18:17:37 iter 50 loss = 0.162226\n",
            "2020-01-19 18:17:40 iter 75 loss = 0.143657\n",
            "2020-01-19 18:17:43 iter 100 loss = 0.148915\n",
            "2020-01-19 18:17:43 epoch 129/500 average_loss = 0.146520\n",
            "\n",
            "2020-01-19 18:17:43 start epoch 130/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:17:43 iter 1 loss = 0.162506\n",
            "2020-01-19 18:17:46 iter 25 loss = 0.177865\n",
            "2020-01-19 18:17:50 iter 50 loss = 0.156798\n",
            "2020-01-19 18:17:53 iter 75 loss = 0.143377\n",
            "2020-01-19 18:17:56 iter 100 loss = 0.162576\n",
            "2020-01-19 18:17:56 epoch 130/500 average_loss = 0.147884\n",
            "\n",
            "2020-01-19 18:17:56 start epoch 131/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:17:56 iter 1 loss = 0.154364\n",
            "2020-01-19 18:17:59 iter 25 loss = 0.133232\n",
            "2020-01-19 18:18:02 iter 50 loss = 0.128662\n",
            "2020-01-19 18:18:05 iter 75 loss = 0.183318\n",
            "2020-01-19 18:18:09 iter 100 loss = 0.163964\n",
            "2020-01-19 18:18:09 epoch 131/500 average_loss = 0.146822\n",
            "\n",
            "2020-01-19 18:18:09 start epoch 132/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:18:09 iter 1 loss = 0.202584\n",
            "2020-01-19 18:18:12 iter 25 loss = 0.125190\n",
            "2020-01-19 18:18:15 iter 50 loss = 0.114056\n",
            "2020-01-19 18:18:18 iter 75 loss = 0.153602\n",
            "2020-01-19 18:18:21 iter 100 loss = 0.123316\n",
            "2020-01-19 18:18:21 epoch 132/500 average_loss = 0.145058\n",
            "\n",
            "2020-01-19 18:18:21 start epoch 133/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:18:21 iter 1 loss = 0.130667\n",
            "2020-01-19 18:18:25 iter 25 loss = 0.133655\n",
            "2020-01-19 18:18:28 iter 50 loss = 0.142589\n",
            "2020-01-19 18:18:31 iter 75 loss = 0.189368\n",
            "2020-01-19 18:18:34 iter 100 loss = 0.137852\n",
            "2020-01-19 18:18:34 epoch 133/500 average_loss = 0.138550\n",
            "\n",
            "2020-01-19 18:18:34 start epoch 134/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:18:34 iter 1 loss = 0.144314\n",
            "2020-01-19 18:18:37 iter 25 loss = 0.133245\n",
            "2020-01-19 18:18:40 iter 50 loss = 0.135116\n",
            "2020-01-19 18:18:44 iter 75 loss = 0.164450\n",
            "2020-01-19 18:18:47 iter 100 loss = 0.140438\n",
            "2020-01-19 18:18:47 epoch 134/500 average_loss = 0.139479\n",
            "\n",
            "2020-01-19 18:18:47 start epoch 135/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:18:47 iter 1 loss = 0.146212\n",
            "2020-01-19 18:18:50 iter 25 loss = 0.158324\n",
            "2020-01-19 18:18:53 iter 50 loss = 0.142474\n",
            "2020-01-19 18:18:56 iter 75 loss = 0.131693\n",
            "2020-01-19 18:18:59 iter 100 loss = 0.124006\n",
            "2020-01-19 18:18:59 epoch 135/500 average_loss = 0.138870\n",
            "\n",
            "2020-01-19 18:18:59 start epoch 136/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:18:59 iter 1 loss = 0.121875\n",
            "2020-01-19 18:19:03 iter 25 loss = 0.112090\n",
            "2020-01-19 18:19:06 iter 50 loss = 0.140605\n",
            "2020-01-19 18:19:09 iter 75 loss = 0.149336\n",
            "2020-01-19 18:19:12 iter 100 loss = 0.161843\n",
            "2020-01-19 18:19:12 epoch 136/500 average_loss = 0.140126\n",
            "\n",
            "2020-01-19 18:19:12 start epoch 137/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:19:12 iter 1 loss = 0.145611\n",
            "2020-01-19 18:19:15 iter 25 loss = 0.156463\n",
            "2020-01-19 18:19:18 iter 50 loss = 0.163246\n",
            "2020-01-19 18:19:22 iter 75 loss = 0.155613\n",
            "2020-01-19 18:19:25 iter 100 loss = 0.126322\n",
            "2020-01-19 18:19:25 epoch 137/500 average_loss = 0.134975\n",
            "\n",
            "2020-01-19 18:19:25 start epoch 138/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:19:25 iter 1 loss = 0.140318\n",
            "2020-01-19 18:19:28 iter 25 loss = 0.161716\n",
            "2020-01-19 18:19:31 iter 50 loss = 0.129976\n",
            "2020-01-19 18:19:34 iter 75 loss = 0.127047\n",
            "2020-01-19 18:19:37 iter 100 loss = 0.140238\n",
            "2020-01-19 18:19:37 epoch 138/500 average_loss = 0.140809\n",
            "\n",
            "2020-01-19 18:19:37 start epoch 139/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:19:38 iter 1 loss = 0.120866\n",
            "2020-01-19 18:19:41 iter 25 loss = 0.125485\n",
            "2020-01-19 18:19:44 iter 50 loss = 0.115063\n",
            "2020-01-19 18:19:47 iter 75 loss = 0.158587\n",
            "2020-01-19 18:19:50 iter 100 loss = 0.143878\n",
            "2020-01-19 18:19:50 epoch 139/500 average_loss = 0.136747\n",
            "\n",
            "2020-01-19 18:19:50 start epoch 140/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:19:50 iter 1 loss = 0.130936\n",
            "2020-01-19 18:19:53 iter 25 loss = 0.096628\n",
            "2020-01-19 18:19:56 iter 50 loss = 0.159114\n",
            "2020-01-19 18:20:00 iter 75 loss = 0.106417\n",
            "2020-01-19 18:20:03 iter 100 loss = 0.112392\n",
            "2020-01-19 18:20:03 epoch 140/500 average_loss = 0.134611\n",
            "\n",
            "2020-01-19 18:20:03 start epoch 141/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:20:03 iter 1 loss = 0.100287\n",
            "2020-01-19 18:20:06 iter 25 loss = 0.109945\n",
            "2020-01-19 18:20:09 iter 50 loss = 0.134640\n",
            "2020-01-19 18:20:12 iter 75 loss = 0.105992\n",
            "2020-01-19 18:20:15 iter 100 loss = 0.153210\n",
            "2020-01-19 18:20:15 epoch 141/500 average_loss = 0.136612\n",
            "\n",
            "2020-01-19 18:20:15 start epoch 142/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:20:16 iter 1 loss = 0.136161\n",
            "2020-01-19 18:20:19 iter 25 loss = 0.117813\n",
            "2020-01-19 18:20:22 iter 50 loss = 0.162088\n",
            "2020-01-19 18:20:25 iter 75 loss = 0.144371\n",
            "2020-01-19 18:20:28 iter 100 loss = 0.139508\n",
            "2020-01-19 18:20:28 epoch 142/500 average_loss = 0.135828\n",
            "\n",
            "2020-01-19 18:20:28 start epoch 143/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:20:28 iter 1 loss = 0.147695\n",
            "2020-01-19 18:20:31 iter 25 loss = 0.131883\n",
            "2020-01-19 18:20:34 iter 50 loss = 0.122301\n",
            "2020-01-19 18:20:37 iter 75 loss = 0.130396\n",
            "2020-01-19 18:20:41 iter 100 loss = 0.147582\n",
            "2020-01-19 18:20:41 epoch 143/500 average_loss = 0.135427\n",
            "\n",
            "2020-01-19 18:20:41 start epoch 144/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:20:41 iter 1 loss = 0.125404\n",
            "2020-01-19 18:20:44 iter 25 loss = 0.134788\n",
            "2020-01-19 18:20:47 iter 50 loss = 0.113651\n",
            "2020-01-19 18:20:50 iter 75 loss = 0.134019\n",
            "2020-01-19 18:20:53 iter 100 loss = 0.139242\n",
            "2020-01-19 18:20:53 epoch 144/500 average_loss = 0.134318\n",
            "\n",
            "2020-01-19 18:20:53 start epoch 145/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:20:53 iter 1 loss = 0.139526\n",
            "2020-01-19 18:20:57 iter 25 loss = 0.154970\n",
            "2020-01-19 18:21:00 iter 50 loss = 0.130554\n",
            "2020-01-19 18:21:03 iter 75 loss = 0.128116\n",
            "2020-01-19 18:21:06 iter 100 loss = 0.114863\n",
            "2020-01-19 18:21:06 epoch 145/500 average_loss = 0.131365\n",
            "\n",
            "2020-01-19 18:21:06 start epoch 146/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:21:06 iter 1 loss = 0.149727\n",
            "2020-01-19 18:21:09 iter 25 loss = 0.111872\n",
            "2020-01-19 18:21:13 iter 50 loss = 0.123236\n",
            "2020-01-19 18:21:16 iter 75 loss = 0.156437\n",
            "2020-01-19 18:21:19 iter 100 loss = 0.140558\n",
            "2020-01-19 18:21:19 epoch 146/500 average_loss = 0.133127\n",
            "\n",
            "2020-01-19 18:21:19 start epoch 147/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:21:19 iter 1 loss = 0.128695\n",
            "2020-01-19 18:21:22 iter 25 loss = 0.128600\n",
            "2020-01-19 18:21:25 iter 50 loss = 0.129004\n",
            "2020-01-19 18:21:28 iter 75 loss = 0.125004\n",
            "2020-01-19 18:21:31 iter 100 loss = 0.130145\n",
            "2020-01-19 18:21:31 epoch 147/500 average_loss = 0.130894\n",
            "\n",
            "2020-01-19 18:21:31 start epoch 148/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:21:32 iter 1 loss = 0.135134\n",
            "2020-01-19 18:21:35 iter 25 loss = 0.129392\n",
            "2020-01-19 18:21:38 iter 50 loss = 0.107025\n",
            "2020-01-19 18:21:41 iter 75 loss = 0.119604\n",
            "2020-01-19 18:21:44 iter 100 loss = 0.130037\n",
            "2020-01-19 18:21:44 epoch 148/500 average_loss = 0.130707\n",
            "\n",
            "2020-01-19 18:21:44 start epoch 149/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:21:44 iter 1 loss = 0.150833\n",
            "2020-01-19 18:21:47 iter 25 loss = 0.158501\n",
            "2020-01-19 18:21:50 iter 50 loss = 0.105059\n",
            "2020-01-19 18:21:54 iter 75 loss = 0.126076\n",
            "2020-01-19 18:21:57 iter 100 loss = 0.137296\n",
            "2020-01-19 18:21:57 epoch 149/500 average_loss = 0.130119\n",
            "\n",
            "2020-01-19 18:21:57 start epoch 150/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:21:57 iter 1 loss = 0.118231\n",
            "2020-01-19 18:22:00 iter 25 loss = 0.122691\n",
            "2020-01-19 18:22:03 iter 50 loss = 0.090466\n",
            "2020-01-19 18:22:06 iter 75 loss = 0.127559\n",
            "2020-01-19 18:22:09 iter 100 loss = 0.120979\n",
            "2020-01-19 18:22:09 epoch 150/500 average_loss = 0.129370\n",
            "\n",
            "2020-01-19 18:22:09 start epoch 151/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:22:10 iter 1 loss = 0.118810\n",
            "2020-01-19 18:22:13 iter 25 loss = 0.137252\n",
            "2020-01-19 18:22:16 iter 50 loss = 0.172665\n",
            "2020-01-19 18:22:19 iter 75 loss = 0.110800\n",
            "2020-01-19 18:22:22 iter 100 loss = 0.163245\n",
            "2020-01-19 18:22:22 epoch 151/500 average_loss = 0.129754\n",
            "\n",
            "2020-01-19 18:22:22 start epoch 152/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:22:22 iter 1 loss = 0.139818\n",
            "2020-01-19 18:22:25 iter 25 loss = 0.127855\n",
            "2020-01-19 18:22:29 iter 50 loss = 0.132652\n",
            "2020-01-19 18:22:32 iter 75 loss = 0.116601\n",
            "2020-01-19 18:22:35 iter 100 loss = 0.115024\n",
            "2020-01-19 18:22:35 epoch 152/500 average_loss = 0.128246\n",
            "\n",
            "2020-01-19 18:22:35 start epoch 153/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:22:35 iter 1 loss = 0.142724\n",
            "2020-01-19 18:22:38 iter 25 loss = 0.118337\n",
            "2020-01-19 18:22:41 iter 50 loss = 0.131640\n",
            "2020-01-19 18:22:44 iter 75 loss = 0.145973\n",
            "2020-01-19 18:22:48 iter 100 loss = 0.106470\n",
            "2020-01-19 18:22:48 epoch 153/500 average_loss = 0.129374\n",
            "\n",
            "2020-01-19 18:22:48 start epoch 154/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:22:48 iter 1 loss = 0.089555\n",
            "2020-01-19 18:22:51 iter 25 loss = 0.162920\n",
            "2020-01-19 18:22:54 iter 50 loss = 0.102035\n",
            "2020-01-19 18:22:57 iter 75 loss = 0.124541\n",
            "2020-01-19 18:23:00 iter 100 loss = 0.146248\n",
            "2020-01-19 18:23:00 epoch 154/500 average_loss = 0.124856\n",
            "\n",
            "2020-01-19 18:23:00 start epoch 155/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:23:00 iter 1 loss = 0.122251\n",
            "2020-01-19 18:23:03 iter 25 loss = 0.097449\n",
            "2020-01-19 18:23:06 iter 50 loss = 0.134725\n",
            "2020-01-19 18:23:10 iter 75 loss = 0.114910\n",
            "2020-01-19 18:23:13 iter 100 loss = 0.116822\n",
            "2020-01-19 18:23:13 epoch 155/500 average_loss = 0.122196\n",
            "\n",
            "2020-01-19 18:23:13 start epoch 156/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:23:13 iter 1 loss = 0.129463\n",
            "2020-01-19 18:23:16 iter 25 loss = 0.120211\n",
            "2020-01-19 18:23:19 iter 50 loss = 0.113784\n",
            "2020-01-19 18:23:22 iter 75 loss = 0.112639\n",
            "2020-01-19 18:23:26 iter 100 loss = 0.097748\n",
            "2020-01-19 18:23:26 epoch 156/500 average_loss = 0.122667\n",
            "\n",
            "2020-01-19 18:23:26 start epoch 157/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:23:26 iter 1 loss = 0.122457\n",
            "2020-01-19 18:23:29 iter 25 loss = 0.119145\n",
            "2020-01-19 18:23:32 iter 50 loss = 0.102678\n",
            "2020-01-19 18:23:35 iter 75 loss = 0.129006\n",
            "2020-01-19 18:23:38 iter 100 loss = 0.116677\n",
            "2020-01-19 18:23:38 epoch 157/500 average_loss = 0.124471\n",
            "\n",
            "2020-01-19 18:23:38 start epoch 158/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:23:38 iter 1 loss = 0.123569\n",
            "2020-01-19 18:23:42 iter 25 loss = 0.094946\n",
            "2020-01-19 18:23:45 iter 50 loss = 0.141739\n",
            "2020-01-19 18:23:48 iter 75 loss = 0.135534\n",
            "2020-01-19 18:23:51 iter 100 loss = 0.147452\n",
            "2020-01-19 18:23:51 epoch 158/500 average_loss = 0.123952\n",
            "\n",
            "2020-01-19 18:23:51 start epoch 159/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:23:51 iter 1 loss = 0.127921\n",
            "2020-01-19 18:23:54 iter 25 loss = 0.101336\n",
            "2020-01-19 18:23:57 iter 50 loss = 0.116682\n",
            "2020-01-19 18:24:00 iter 75 loss = 0.116732\n",
            "2020-01-19 18:24:04 iter 100 loss = 0.112431\n",
            "2020-01-19 18:24:04 epoch 159/500 average_loss = 0.124889\n",
            "\n",
            "2020-01-19 18:24:04 start epoch 160/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:24:04 iter 1 loss = 0.184820\n",
            "2020-01-19 18:24:07 iter 25 loss = 0.130122\n",
            "2020-01-19 18:24:10 iter 50 loss = 0.113245\n",
            "2020-01-19 18:24:13 iter 75 loss = 0.123408\n",
            "2020-01-19 18:24:16 iter 100 loss = 0.137788\n",
            "2020-01-19 18:24:16 epoch 160/500 average_loss = 0.122982\n",
            "\n",
            "2020-01-19 18:24:16 start epoch 161/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:24:16 iter 1 loss = 0.110332\n",
            "2020-01-19 18:24:19 iter 25 loss = 0.125753\n",
            "2020-01-19 18:24:23 iter 50 loss = 0.119540\n",
            "2020-01-19 18:24:26 iter 75 loss = 0.137180\n",
            "2020-01-19 18:24:29 iter 100 loss = 0.163556\n",
            "2020-01-19 18:24:29 epoch 161/500 average_loss = 0.125162\n",
            "\n",
            "2020-01-19 18:24:29 start epoch 162/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:24:29 iter 1 loss = 0.117271\n",
            "2020-01-19 18:24:32 iter 25 loss = 0.144039\n",
            "2020-01-19 18:24:35 iter 50 loss = 0.119653\n",
            "2020-01-19 18:24:38 iter 75 loss = 0.141939\n",
            "2020-01-19 18:24:42 iter 100 loss = 0.099854\n",
            "2020-01-19 18:24:42 epoch 162/500 average_loss = 0.122267\n",
            "\n",
            "2020-01-19 18:24:42 start epoch 163/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:24:42 iter 1 loss = 0.120931\n",
            "2020-01-19 18:24:45 iter 25 loss = 0.129435\n",
            "2020-01-19 18:24:48 iter 50 loss = 0.147215\n",
            "2020-01-19 18:24:51 iter 75 loss = 0.107017\n",
            "2020-01-19 18:24:54 iter 100 loss = 0.123073\n",
            "2020-01-19 18:24:54 epoch 163/500 average_loss = 0.125829\n",
            "\n",
            "2020-01-19 18:24:54 start epoch 164/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:24:54 iter 1 loss = 0.129433\n",
            "2020-01-19 18:24:57 iter 25 loss = 0.132378\n",
            "2020-01-19 18:25:00 iter 50 loss = 0.134247\n",
            "2020-01-19 18:25:04 iter 75 loss = 0.114917\n",
            "2020-01-19 18:25:07 iter 100 loss = 0.089836\n",
            "2020-01-19 18:25:07 epoch 164/500 average_loss = 0.120652\n",
            "\n",
            "2020-01-19 18:25:07 start epoch 165/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:25:07 iter 1 loss = 0.077200\n",
            "2020-01-19 18:25:10 iter 25 loss = 0.112274\n",
            "2020-01-19 18:25:13 iter 50 loss = 0.122630\n",
            "2020-01-19 18:25:17 iter 75 loss = 0.153230\n",
            "2020-01-19 18:25:20 iter 100 loss = 0.129536\n",
            "2020-01-19 18:25:20 epoch 165/500 average_loss = 0.117444\n",
            "\n",
            "2020-01-19 18:25:20 start epoch 166/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:25:20 iter 1 loss = 0.111938\n",
            "2020-01-19 18:25:23 iter 25 loss = 0.108320\n",
            "2020-01-19 18:25:26 iter 50 loss = 0.128783\n",
            "2020-01-19 18:25:29 iter 75 loss = 0.111582\n",
            "2020-01-19 18:25:32 iter 100 loss = 0.129319\n",
            "2020-01-19 18:25:32 epoch 166/500 average_loss = 0.121192\n",
            "\n",
            "2020-01-19 18:25:32 start epoch 167/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:25:32 iter 1 loss = 0.144178\n",
            "2020-01-19 18:25:35 iter 25 loss = 0.125727\n",
            "2020-01-19 18:25:39 iter 50 loss = 0.128827\n",
            "2020-01-19 18:25:42 iter 75 loss = 0.103375\n",
            "2020-01-19 18:25:45 iter 100 loss = 0.117929\n",
            "2020-01-19 18:25:45 epoch 167/500 average_loss = 0.122431\n",
            "\n",
            "2020-01-19 18:25:45 start epoch 168/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:25:45 iter 1 loss = 0.124815\n",
            "2020-01-19 18:25:48 iter 25 loss = 0.113082\n",
            "2020-01-19 18:25:51 iter 50 loss = 0.131410\n",
            "2020-01-19 18:25:54 iter 75 loss = 0.142982\n",
            "2020-01-19 18:25:58 iter 100 loss = 0.121107\n",
            "2020-01-19 18:25:58 epoch 168/500 average_loss = 0.118771\n",
            "\n",
            "2020-01-19 18:25:58 start epoch 169/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:25:58 iter 1 loss = 0.109216\n",
            "2020-01-19 18:26:01 iter 25 loss = 0.160370\n",
            "2020-01-19 18:26:04 iter 50 loss = 0.096019\n",
            "2020-01-19 18:26:07 iter 75 loss = 0.134720\n",
            "2020-01-19 18:26:10 iter 100 loss = 0.123535\n",
            "2020-01-19 18:26:10 epoch 169/500 average_loss = 0.117877\n",
            "\n",
            "2020-01-19 18:26:10 start epoch 170/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:26:10 iter 1 loss = 0.118935\n",
            "2020-01-19 18:26:14 iter 25 loss = 0.100729\n",
            "2020-01-19 18:26:17 iter 50 loss = 0.102599\n",
            "2020-01-19 18:26:20 iter 75 loss = 0.115167\n",
            "2020-01-19 18:26:23 iter 100 loss = 0.116814\n",
            "2020-01-19 18:26:23 epoch 170/500 average_loss = 0.118473\n",
            "\n",
            "2020-01-19 18:26:23 start epoch 171/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:26:23 iter 1 loss = 0.098642\n",
            "2020-01-19 18:26:26 iter 25 loss = 0.147406\n",
            "2020-01-19 18:26:29 iter 50 loss = 0.130549\n",
            "2020-01-19 18:26:32 iter 75 loss = 0.110554\n",
            "2020-01-19 18:26:36 iter 100 loss = 0.113883\n",
            "2020-01-19 18:26:36 epoch 171/500 average_loss = 0.117922\n",
            "\n",
            "2020-01-19 18:26:36 start epoch 172/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:26:36 iter 1 loss = 0.098699\n",
            "2020-01-19 18:26:39 iter 25 loss = 0.102492\n",
            "2020-01-19 18:26:42 iter 50 loss = 0.152314\n",
            "2020-01-19 18:26:45 iter 75 loss = 0.117589\n",
            "2020-01-19 18:26:48 iter 100 loss = 0.112836\n",
            "2020-01-19 18:26:48 epoch 172/500 average_loss = 0.117241\n",
            "\n",
            "2020-01-19 18:26:48 start epoch 173/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:26:48 iter 1 loss = 0.117531\n",
            "2020-01-19 18:26:51 iter 25 loss = 0.122014\n",
            "2020-01-19 18:26:55 iter 50 loss = 0.099969\n",
            "2020-01-19 18:26:58 iter 75 loss = 0.106110\n",
            "2020-01-19 18:27:01 iter 100 loss = 0.144912\n",
            "2020-01-19 18:27:01 epoch 173/500 average_loss = 0.113765\n",
            "\n",
            "2020-01-19 18:27:01 start epoch 174/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:27:01 iter 1 loss = 0.128475\n",
            "2020-01-19 18:27:04 iter 25 loss = 0.105152\n",
            "2020-01-19 18:27:07 iter 50 loss = 0.082172\n",
            "2020-01-19 18:27:10 iter 75 loss = 0.103309\n",
            "2020-01-19 18:27:14 iter 100 loss = 0.127519\n",
            "2020-01-19 18:27:14 epoch 174/500 average_loss = 0.117107\n",
            "\n",
            "2020-01-19 18:27:14 start epoch 175/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:27:14 iter 1 loss = 0.117359\n",
            "2020-01-19 18:27:17 iter 25 loss = 0.097703\n",
            "2020-01-19 18:27:20 iter 50 loss = 0.107104\n",
            "2020-01-19 18:27:23 iter 75 loss = 0.118427\n",
            "2020-01-19 18:27:26 iter 100 loss = 0.104242\n",
            "2020-01-19 18:27:26 epoch 175/500 average_loss = 0.114234\n",
            "\n",
            "2020-01-19 18:27:26 start epoch 176/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:27:27 iter 1 loss = 0.115582\n",
            "2020-01-19 18:27:30 iter 25 loss = 0.124209\n",
            "2020-01-19 18:27:33 iter 50 loss = 0.093914\n",
            "2020-01-19 18:27:36 iter 75 loss = 0.112252\n",
            "2020-01-19 18:27:39 iter 100 loss = 0.124881\n",
            "2020-01-19 18:27:39 epoch 176/500 average_loss = 0.114383\n",
            "\n",
            "2020-01-19 18:27:39 start epoch 177/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:27:39 iter 1 loss = 0.090436\n",
            "2020-01-19 18:27:42 iter 25 loss = 0.147792\n",
            "2020-01-19 18:27:45 iter 50 loss = 0.122084\n",
            "2020-01-19 18:27:49 iter 75 loss = 0.100970\n",
            "2020-01-19 18:27:52 iter 100 loss = 0.102048\n",
            "2020-01-19 18:27:52 epoch 177/500 average_loss = 0.111270\n",
            "\n",
            "2020-01-19 18:27:52 start epoch 178/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:27:52 iter 1 loss = 0.105278\n",
            "2020-01-19 18:27:55 iter 25 loss = 0.100211\n",
            "2020-01-19 18:27:58 iter 50 loss = 0.094833\n",
            "2020-01-19 18:28:01 iter 75 loss = 0.131655\n",
            "2020-01-19 18:28:04 iter 100 loss = 0.109804\n",
            "2020-01-19 18:28:04 epoch 178/500 average_loss = 0.114067\n",
            "\n",
            "2020-01-19 18:28:04 start epoch 179/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:28:05 iter 1 loss = 0.121432\n",
            "2020-01-19 18:28:08 iter 25 loss = 0.116631\n",
            "2020-01-19 18:28:11 iter 50 loss = 0.100784\n",
            "2020-01-19 18:28:14 iter 75 loss = 0.117323\n",
            "2020-01-19 18:28:17 iter 100 loss = 0.111199\n",
            "2020-01-19 18:28:17 epoch 179/500 average_loss = 0.115973\n",
            "\n",
            "2020-01-19 18:28:17 start epoch 180/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:28:17 iter 1 loss = 0.091729\n",
            "2020-01-19 18:28:20 iter 25 loss = 0.088568\n",
            "2020-01-19 18:28:23 iter 50 loss = 0.114712\n",
            "2020-01-19 18:28:27 iter 75 loss = 0.122604\n",
            "2020-01-19 18:28:30 iter 100 loss = 0.096701\n",
            "2020-01-19 18:28:30 epoch 180/500 average_loss = 0.112220\n",
            "\n",
            "2020-01-19 18:28:30 start epoch 181/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:28:30 iter 1 loss = 0.104911\n",
            "2020-01-19 18:28:33 iter 25 loss = 0.125526\n",
            "2020-01-19 18:28:36 iter 50 loss = 0.113561\n",
            "2020-01-19 18:28:39 iter 75 loss = 0.134599\n",
            "2020-01-19 18:28:42 iter 100 loss = 0.093309\n",
            "2020-01-19 18:28:42 epoch 181/500 average_loss = 0.112300\n",
            "\n",
            "2020-01-19 18:28:42 start epoch 182/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:28:43 iter 1 loss = 0.109305\n",
            "2020-01-19 18:28:46 iter 25 loss = 0.098444\n",
            "2020-01-19 18:28:49 iter 50 loss = 0.098456\n",
            "2020-01-19 18:28:52 iter 75 loss = 0.106923\n",
            "2020-01-19 18:28:55 iter 100 loss = 0.092291\n",
            "2020-01-19 18:28:55 epoch 182/500 average_loss = 0.110358\n",
            "\n",
            "2020-01-19 18:28:55 start epoch 183/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:28:55 iter 1 loss = 0.103988\n",
            "2020-01-19 18:28:58 iter 25 loss = 0.109192\n",
            "2020-01-19 18:29:01 iter 50 loss = 0.106361\n",
            "2020-01-19 18:29:05 iter 75 loss = 0.097582\n",
            "2020-01-19 18:29:08 iter 100 loss = 0.084044\n",
            "2020-01-19 18:29:08 epoch 183/500 average_loss = 0.109759\n",
            "\n",
            "2020-01-19 18:29:08 start epoch 184/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:29:08 iter 1 loss = 0.119990\n",
            "2020-01-19 18:29:11 iter 25 loss = 0.111695\n",
            "2020-01-19 18:29:14 iter 50 loss = 0.106794\n",
            "2020-01-19 18:29:17 iter 75 loss = 0.115062\n",
            "2020-01-19 18:29:21 iter 100 loss = 0.101928\n",
            "2020-01-19 18:29:21 epoch 184/500 average_loss = 0.109807\n",
            "\n",
            "2020-01-19 18:29:21 start epoch 185/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:29:21 iter 1 loss = 0.106261\n",
            "2020-01-19 18:29:24 iter 25 loss = 0.097345\n",
            "2020-01-19 18:29:27 iter 50 loss = 0.106937\n",
            "2020-01-19 18:29:30 iter 75 loss = 0.126275\n",
            "2020-01-19 18:29:33 iter 100 loss = 0.120713\n",
            "2020-01-19 18:29:33 epoch 185/500 average_loss = 0.110830\n",
            "\n",
            "2020-01-19 18:29:33 start epoch 186/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:29:33 iter 1 loss = 0.129647\n",
            "2020-01-19 18:29:36 iter 25 loss = 0.083469\n",
            "2020-01-19 18:29:39 iter 50 loss = 0.089573\n",
            "2020-01-19 18:29:43 iter 75 loss = 0.095640\n",
            "2020-01-19 18:29:46 iter 100 loss = 0.125893\n",
            "2020-01-19 18:29:46 epoch 186/500 average_loss = 0.107147\n",
            "\n",
            "2020-01-19 18:29:46 start epoch 187/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:29:46 iter 1 loss = 0.116818\n",
            "2020-01-19 18:29:49 iter 25 loss = 0.166178\n",
            "2020-01-19 18:29:52 iter 50 loss = 0.089528\n",
            "2020-01-19 18:29:55 iter 75 loss = 0.113906\n",
            "2020-01-19 18:29:58 iter 100 loss = 0.139249\n",
            "2020-01-19 18:29:58 epoch 187/500 average_loss = 0.111066\n",
            "\n",
            "2020-01-19 18:29:58 start epoch 188/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:29:59 iter 1 loss = 0.116731\n",
            "2020-01-19 18:30:02 iter 25 loss = 0.108233\n",
            "2020-01-19 18:30:05 iter 50 loss = 0.108313\n",
            "2020-01-19 18:30:08 iter 75 loss = 0.087207\n",
            "2020-01-19 18:30:11 iter 100 loss = 0.113330\n",
            "2020-01-19 18:30:11 epoch 188/500 average_loss = 0.108406\n",
            "\n",
            "2020-01-19 18:30:11 start epoch 189/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:30:11 iter 1 loss = 0.104919\n",
            "2020-01-19 18:30:14 iter 25 loss = 0.114915\n",
            "2020-01-19 18:30:18 iter 50 loss = 0.082928\n",
            "2020-01-19 18:30:21 iter 75 loss = 0.109791\n",
            "2020-01-19 18:30:24 iter 100 loss = 0.101166\n",
            "2020-01-19 18:30:24 epoch 189/500 average_loss = 0.108721\n",
            "\n",
            "2020-01-19 18:30:24 start epoch 190/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:30:24 iter 1 loss = 0.104157\n",
            "2020-01-19 18:30:27 iter 25 loss = 0.123064\n",
            "2020-01-19 18:30:30 iter 50 loss = 0.097313\n",
            "2020-01-19 18:30:33 iter 75 loss = 0.091631\n",
            "2020-01-19 18:30:37 iter 100 loss = 0.103675\n",
            "2020-01-19 18:30:37 epoch 190/500 average_loss = 0.106365\n",
            "\n",
            "2020-01-19 18:30:37 start epoch 191/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:30:37 iter 1 loss = 0.135752\n",
            "2020-01-19 18:30:40 iter 25 loss = 0.095562\n",
            "2020-01-19 18:30:43 iter 50 loss = 0.098628\n",
            "2020-01-19 18:30:46 iter 75 loss = 0.121086\n",
            "2020-01-19 18:30:49 iter 100 loss = 0.130530\n",
            "2020-01-19 18:30:49 epoch 191/500 average_loss = 0.108059\n",
            "\n",
            "2020-01-19 18:30:49 start epoch 192/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:30:49 iter 1 loss = 0.096931\n",
            "2020-01-19 18:30:52 iter 25 loss = 0.108842\n",
            "2020-01-19 18:30:56 iter 50 loss = 0.135329\n",
            "2020-01-19 18:30:59 iter 75 loss = 0.117781\n",
            "2020-01-19 18:31:02 iter 100 loss = 0.084991\n",
            "2020-01-19 18:31:02 epoch 192/500 average_loss = 0.109868\n",
            "\n",
            "2020-01-19 18:31:02 start epoch 193/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:31:02 iter 1 loss = 0.120887\n",
            "2020-01-19 18:31:05 iter 25 loss = 0.120085\n",
            "2020-01-19 18:31:08 iter 50 loss = 0.094605\n",
            "2020-01-19 18:31:11 iter 75 loss = 0.124723\n",
            "2020-01-19 18:31:15 iter 100 loss = 0.137489\n",
            "2020-01-19 18:31:15 epoch 193/500 average_loss = 0.108971\n",
            "\n",
            "2020-01-19 18:31:15 start epoch 194/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:31:15 iter 1 loss = 0.100000\n",
            "2020-01-19 18:31:18 iter 25 loss = 0.093359\n",
            "2020-01-19 18:31:21 iter 50 loss = 0.108005\n",
            "2020-01-19 18:31:24 iter 75 loss = 0.097636\n",
            "2020-01-19 18:31:27 iter 100 loss = 0.115179\n",
            "2020-01-19 18:31:27 epoch 194/500 average_loss = 0.111344\n",
            "\n",
            "2020-01-19 18:31:27 start epoch 195/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:31:28 iter 1 loss = 0.095231\n",
            "2020-01-19 18:31:31 iter 25 loss = 0.103330\n",
            "2020-01-19 18:31:34 iter 50 loss = 0.097946\n",
            "2020-01-19 18:31:37 iter 75 loss = 0.122713\n",
            "2020-01-19 18:31:40 iter 100 loss = 0.135496\n",
            "2020-01-19 18:31:40 epoch 195/500 average_loss = 0.109341\n",
            "\n",
            "2020-01-19 18:31:40 start epoch 196/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:31:40 iter 1 loss = 0.124460\n",
            "2020-01-19 18:31:43 iter 25 loss = 0.083923\n",
            "2020-01-19 18:31:46 iter 50 loss = 0.092235\n",
            "2020-01-19 18:31:50 iter 75 loss = 0.111267\n",
            "2020-01-19 18:31:53 iter 100 loss = 0.113725\n",
            "2020-01-19 18:31:53 epoch 196/500 average_loss = 0.107648\n",
            "\n",
            "2020-01-19 18:31:53 start epoch 197/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:31:53 iter 1 loss = 0.097026\n",
            "2020-01-19 18:31:56 iter 25 loss = 0.121674\n",
            "2020-01-19 18:31:59 iter 50 loss = 0.095285\n",
            "2020-01-19 18:32:02 iter 75 loss = 0.102012\n",
            "2020-01-19 18:32:05 iter 100 loss = 0.145853\n",
            "2020-01-19 18:32:05 epoch 197/500 average_loss = 0.107971\n",
            "\n",
            "2020-01-19 18:32:05 start epoch 198/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:32:06 iter 1 loss = 0.126306\n",
            "2020-01-19 18:32:09 iter 25 loss = 0.092249\n",
            "2020-01-19 18:32:12 iter 50 loss = 0.126375\n",
            "2020-01-19 18:32:15 iter 75 loss = 0.110588\n",
            "2020-01-19 18:32:18 iter 100 loss = 0.117753\n",
            "2020-01-19 18:32:18 epoch 198/500 average_loss = 0.106884\n",
            "\n",
            "2020-01-19 18:32:18 start epoch 199/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:32:18 iter 1 loss = 0.100425\n",
            "2020-01-19 18:32:21 iter 25 loss = 0.117734\n",
            "2020-01-19 18:32:24 iter 50 loss = 0.103777\n",
            "2020-01-19 18:32:28 iter 75 loss = 0.094455\n",
            "2020-01-19 18:32:31 iter 100 loss = 0.095647\n",
            "2020-01-19 18:32:31 epoch 199/500 average_loss = 0.104274\n",
            "\n",
            "2020-01-19 18:32:31 start epoch 200/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:32:31 iter 1 loss = 0.116858\n",
            "2020-01-19 18:32:34 iter 25 loss = 0.088400\n",
            "2020-01-19 18:32:37 iter 50 loss = 0.103540\n",
            "2020-01-19 18:32:40 iter 75 loss = 0.109464\n",
            "2020-01-19 18:32:44 iter 100 loss = 0.098713\n",
            "2020-01-19 18:32:44 epoch 200/500 average_loss = 0.105414\n",
            "\n",
            "2020-01-19 18:32:44 start epoch 201/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:32:44 iter 1 loss = 0.121280\n",
            "2020-01-19 18:32:47 iter 25 loss = 0.133045\n",
            "2020-01-19 18:32:50 iter 50 loss = 0.106356\n",
            "2020-01-19 18:32:53 iter 75 loss = 0.114990\n",
            "2020-01-19 18:32:56 iter 100 loss = 0.120451\n",
            "2020-01-19 18:32:56 epoch 201/500 average_loss = 0.105890\n",
            "\n",
            "2020-01-19 18:32:56 start epoch 202/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:32:56 iter 1 loss = 0.098681\n",
            "2020-01-19 18:32:59 iter 25 loss = 0.115614\n",
            "2020-01-19 18:33:03 iter 50 loss = 0.094794\n",
            "2020-01-19 18:33:06 iter 75 loss = 0.125727\n",
            "2020-01-19 18:33:09 iter 100 loss = 0.118959\n",
            "2020-01-19 18:33:09 epoch 202/500 average_loss = 0.105054\n",
            "\n",
            "2020-01-19 18:33:09 start epoch 203/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:33:09 iter 1 loss = 0.111740\n",
            "2020-01-19 18:33:12 iter 25 loss = 0.094218\n",
            "2020-01-19 18:33:15 iter 50 loss = 0.103497\n",
            "2020-01-19 18:33:18 iter 75 loss = 0.089406\n",
            "2020-01-19 18:33:21 iter 100 loss = 0.082544\n",
            "2020-01-19 18:33:21 epoch 203/500 average_loss = 0.103778\n",
            "\n",
            "2020-01-19 18:33:21 start epoch 204/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:33:22 iter 1 loss = 0.102693\n",
            "2020-01-19 18:33:25 iter 25 loss = 0.093711\n",
            "2020-01-19 18:33:28 iter 50 loss = 0.131293\n",
            "2020-01-19 18:33:31 iter 75 loss = 0.096220\n",
            "2020-01-19 18:33:34 iter 100 loss = 0.105728\n",
            "2020-01-19 18:33:34 epoch 204/500 average_loss = 0.103818\n",
            "\n",
            "2020-01-19 18:33:34 start epoch 205/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:33:34 iter 1 loss = 0.131742\n",
            "2020-01-19 18:33:37 iter 25 loss = 0.099662\n",
            "2020-01-19 18:33:40 iter 50 loss = 0.088650\n",
            "2020-01-19 18:33:44 iter 75 loss = 0.131066\n",
            "2020-01-19 18:33:47 iter 100 loss = 0.123899\n",
            "2020-01-19 18:33:47 epoch 205/500 average_loss = 0.103288\n",
            "\n",
            "2020-01-19 18:33:47 start epoch 206/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:33:47 iter 1 loss = 0.117404\n",
            "2020-01-19 18:33:50 iter 25 loss = 0.109975\n",
            "2020-01-19 18:33:53 iter 50 loss = 0.090670\n",
            "2020-01-19 18:33:56 iter 75 loss = 0.089458\n",
            "2020-01-19 18:33:59 iter 100 loss = 0.098165\n",
            "2020-01-19 18:33:59 epoch 206/500 average_loss = 0.102945\n",
            "\n",
            "2020-01-19 18:33:59 start epoch 207/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:34:00 iter 1 loss = 0.114664\n",
            "2020-01-19 18:34:03 iter 25 loss = 0.128575\n",
            "2020-01-19 18:34:06 iter 50 loss = 0.092326\n",
            "2020-01-19 18:34:09 iter 75 loss = 0.091303\n",
            "2020-01-19 18:34:12 iter 100 loss = 0.095520\n",
            "2020-01-19 18:34:12 epoch 207/500 average_loss = 0.101779\n",
            "\n",
            "2020-01-19 18:34:12 start epoch 208/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:34:12 iter 1 loss = 0.092455\n",
            "2020-01-19 18:34:15 iter 25 loss = 0.082077\n",
            "2020-01-19 18:34:19 iter 50 loss = 0.096715\n",
            "2020-01-19 18:34:22 iter 75 loss = 0.103297\n",
            "2020-01-19 18:34:25 iter 100 loss = 0.093421\n",
            "2020-01-19 18:34:25 epoch 208/500 average_loss = 0.102052\n",
            "\n",
            "2020-01-19 18:34:25 start epoch 209/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:34:25 iter 1 loss = 0.093264\n",
            "2020-01-19 18:34:28 iter 25 loss = 0.098168\n",
            "2020-01-19 18:34:31 iter 50 loss = 0.080098\n",
            "2020-01-19 18:34:34 iter 75 loss = 0.107798\n",
            "2020-01-19 18:34:37 iter 100 loss = 0.089410\n",
            "2020-01-19 18:34:37 epoch 209/500 average_loss = 0.100984\n",
            "\n",
            "2020-01-19 18:34:37 start epoch 210/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:34:38 iter 1 loss = 0.091723\n",
            "2020-01-19 18:34:41 iter 25 loss = 0.086593\n",
            "2020-01-19 18:34:44 iter 50 loss = 0.126606\n",
            "2020-01-19 18:34:47 iter 75 loss = 0.095451\n",
            "2020-01-19 18:34:50 iter 100 loss = 0.095103\n",
            "2020-01-19 18:34:50 epoch 210/500 average_loss = 0.100852\n",
            "\n",
            "2020-01-19 18:34:50 start epoch 211/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:34:50 iter 1 loss = 0.091534\n",
            "2020-01-19 18:34:53 iter 25 loss = 0.135285\n",
            "2020-01-19 18:34:56 iter 50 loss = 0.085593\n",
            "2020-01-19 18:35:00 iter 75 loss = 0.120691\n",
            "2020-01-19 18:35:03 iter 100 loss = 0.105300\n",
            "2020-01-19 18:35:03 epoch 211/500 average_loss = 0.101384\n",
            "\n",
            "2020-01-19 18:35:03 start epoch 212/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:35:03 iter 1 loss = 0.102051\n",
            "2020-01-19 18:35:06 iter 25 loss = 0.134881\n",
            "2020-01-19 18:35:09 iter 50 loss = 0.097108\n",
            "2020-01-19 18:35:12 iter 75 loss = 0.096908\n",
            "2020-01-19 18:35:15 iter 100 loss = 0.097725\n",
            "2020-01-19 18:35:15 epoch 212/500 average_loss = 0.102841\n",
            "\n",
            "2020-01-19 18:35:15 start epoch 213/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:35:16 iter 1 loss = 0.117461\n",
            "2020-01-19 18:35:19 iter 25 loss = 0.117529\n",
            "2020-01-19 18:35:22 iter 50 loss = 0.087472\n",
            "2020-01-19 18:35:25 iter 75 loss = 0.100097\n",
            "2020-01-19 18:35:28 iter 100 loss = 0.101874\n",
            "2020-01-19 18:35:28 epoch 213/500 average_loss = 0.101558\n",
            "\n",
            "2020-01-19 18:35:28 start epoch 214/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:35:28 iter 1 loss = 0.113243\n",
            "2020-01-19 18:35:31 iter 25 loss = 0.084147\n",
            "2020-01-19 18:35:34 iter 50 loss = 0.105961\n",
            "2020-01-19 18:35:38 iter 75 loss = 0.077477\n",
            "2020-01-19 18:35:41 iter 100 loss = 0.097620\n",
            "2020-01-19 18:35:41 epoch 214/500 average_loss = 0.102692\n",
            "\n",
            "2020-01-19 18:35:41 start epoch 215/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:35:41 iter 1 loss = 0.105603\n",
            "2020-01-19 18:35:44 iter 25 loss = 0.096566\n",
            "2020-01-19 18:35:47 iter 50 loss = 0.110912\n",
            "2020-01-19 18:35:50 iter 75 loss = 0.105129\n",
            "2020-01-19 18:35:53 iter 100 loss = 0.125214\n",
            "2020-01-19 18:35:53 epoch 215/500 average_loss = 0.101636\n",
            "\n",
            "2020-01-19 18:35:53 start epoch 216/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:35:54 iter 1 loss = 0.091762\n",
            "2020-01-19 18:35:57 iter 25 loss = 0.112507\n",
            "2020-01-19 18:36:00 iter 50 loss = 0.086000\n",
            "2020-01-19 18:36:03 iter 75 loss = 0.090442\n",
            "2020-01-19 18:36:06 iter 100 loss = 0.112630\n",
            "2020-01-19 18:36:06 epoch 216/500 average_loss = 0.101649\n",
            "\n",
            "2020-01-19 18:36:06 start epoch 217/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:36:06 iter 1 loss = 0.088045\n",
            "2020-01-19 18:36:09 iter 25 loss = 0.110206\n",
            "2020-01-19 18:36:12 iter 50 loss = 0.109735\n",
            "2020-01-19 18:36:16 iter 75 loss = 0.083884\n",
            "2020-01-19 18:36:19 iter 100 loss = 0.087482\n",
            "2020-01-19 18:36:19 epoch 217/500 average_loss = 0.101283\n",
            "\n",
            "2020-01-19 18:36:19 start epoch 218/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:36:19 iter 1 loss = 0.096150\n",
            "2020-01-19 18:36:22 iter 25 loss = 0.109046\n",
            "2020-01-19 18:36:25 iter 50 loss = 0.090910\n",
            "2020-01-19 18:36:28 iter 75 loss = 0.121506\n",
            "2020-01-19 18:36:31 iter 100 loss = 0.081323\n",
            "2020-01-19 18:36:31 epoch 218/500 average_loss = 0.099886\n",
            "\n",
            "2020-01-19 18:36:31 start epoch 219/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:36:31 iter 1 loss = 0.099641\n",
            "2020-01-19 18:36:34 iter 25 loss = 0.110277\n",
            "2020-01-19 18:36:38 iter 50 loss = 0.128767\n",
            "2020-01-19 18:36:41 iter 75 loss = 0.095847\n",
            "2020-01-19 18:36:44 iter 100 loss = 0.110777\n",
            "2020-01-19 18:36:44 epoch 219/500 average_loss = 0.100018\n",
            "\n",
            "2020-01-19 18:36:44 start epoch 220/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:36:44 iter 1 loss = 0.117510\n",
            "2020-01-19 18:36:47 iter 25 loss = 0.094305\n",
            "2020-01-19 18:36:50 iter 50 loss = 0.086157\n",
            "2020-01-19 18:36:53 iter 75 loss = 0.090363\n",
            "2020-01-19 18:36:57 iter 100 loss = 0.077615\n",
            "2020-01-19 18:36:57 epoch 220/500 average_loss = 0.097156\n",
            "\n",
            "2020-01-19 18:36:57 start epoch 221/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:36:57 iter 1 loss = 0.102267\n",
            "2020-01-19 18:37:00 iter 25 loss = 0.083086\n",
            "2020-01-19 18:37:03 iter 50 loss = 0.105308\n",
            "2020-01-19 18:37:06 iter 75 loss = 0.109926\n",
            "2020-01-19 18:37:09 iter 100 loss = 0.100171\n",
            "2020-01-19 18:37:09 epoch 221/500 average_loss = 0.097392\n",
            "\n",
            "2020-01-19 18:37:09 start epoch 222/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:37:09 iter 1 loss = 0.109462\n",
            "2020-01-19 18:37:13 iter 25 loss = 0.104841\n",
            "2020-01-19 18:37:16 iter 50 loss = 0.079172\n",
            "2020-01-19 18:37:19 iter 75 loss = 0.084636\n",
            "2020-01-19 18:37:22 iter 100 loss = 0.101625\n",
            "2020-01-19 18:37:22 epoch 222/500 average_loss = 0.096603\n",
            "\n",
            "2020-01-19 18:37:22 start epoch 223/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:37:22 iter 1 loss = 0.103317\n",
            "2020-01-19 18:37:25 iter 25 loss = 0.102238\n",
            "2020-01-19 18:37:28 iter 50 loss = 0.092564\n",
            "2020-01-19 18:37:32 iter 75 loss = 0.093800\n",
            "2020-01-19 18:37:35 iter 100 loss = 0.086889\n",
            "2020-01-19 18:37:35 epoch 223/500 average_loss = 0.098780\n",
            "\n",
            "2020-01-19 18:37:35 start epoch 224/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:37:35 iter 1 loss = 0.074351\n",
            "2020-01-19 18:37:38 iter 25 loss = 0.124234\n",
            "2020-01-19 18:37:41 iter 50 loss = 0.096856\n",
            "2020-01-19 18:37:44 iter 75 loss = 0.084939\n",
            "2020-01-19 18:37:47 iter 100 loss = 0.096867\n",
            "2020-01-19 18:37:47 epoch 224/500 average_loss = 0.100009\n",
            "\n",
            "2020-01-19 18:37:47 start epoch 225/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:37:47 iter 1 loss = 0.092822\n",
            "2020-01-19 18:37:50 iter 25 loss = 0.089181\n",
            "2020-01-19 18:37:54 iter 50 loss = 0.152047\n",
            "2020-01-19 18:37:57 iter 75 loss = 0.080637\n",
            "2020-01-19 18:38:00 iter 100 loss = 0.092968\n",
            "2020-01-19 18:38:00 epoch 225/500 average_loss = 0.101780\n",
            "\n",
            "2020-01-19 18:38:00 start epoch 226/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:38:00 iter 1 loss = 0.101632\n",
            "2020-01-19 18:38:03 iter 25 loss = 0.120045\n",
            "2020-01-19 18:38:06 iter 50 loss = 0.128558\n",
            "2020-01-19 18:38:09 iter 75 loss = 0.083400\n",
            "2020-01-19 18:38:13 iter 100 loss = 0.097272\n",
            "2020-01-19 18:38:13 epoch 226/500 average_loss = 0.098147\n",
            "\n",
            "2020-01-19 18:38:13 start epoch 227/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:38:13 iter 1 loss = 0.097919\n",
            "2020-01-19 18:38:16 iter 25 loss = 0.103906\n",
            "2020-01-19 18:38:19 iter 50 loss = 0.099982\n",
            "2020-01-19 18:38:22 iter 75 loss = 0.107650\n",
            "2020-01-19 18:38:25 iter 100 loss = 0.086224\n",
            "2020-01-19 18:38:25 epoch 227/500 average_loss = 0.101040\n",
            "\n",
            "2020-01-19 18:38:25 start epoch 228/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:38:25 iter 1 loss = 0.093815\n",
            "2020-01-19 18:38:28 iter 25 loss = 0.110469\n",
            "2020-01-19 18:38:32 iter 50 loss = 0.094227\n",
            "2020-01-19 18:38:35 iter 75 loss = 0.086197\n",
            "2020-01-19 18:38:38 iter 100 loss = 0.124383\n",
            "2020-01-19 18:38:38 epoch 228/500 average_loss = 0.099142\n",
            "\n",
            "2020-01-19 18:38:38 start epoch 229/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:38:38 iter 1 loss = 0.107457\n",
            "2020-01-19 18:38:41 iter 25 loss = 0.082389\n",
            "2020-01-19 18:38:44 iter 50 loss = 0.089939\n",
            "2020-01-19 18:38:47 iter 75 loss = 0.099626\n",
            "2020-01-19 18:38:51 iter 100 loss = 0.089203\n",
            "2020-01-19 18:38:51 epoch 229/500 average_loss = 0.096094\n",
            "\n",
            "2020-01-19 18:38:51 start epoch 230/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:38:51 iter 1 loss = 0.094736\n",
            "2020-01-19 18:38:54 iter 25 loss = 0.091434\n",
            "2020-01-19 18:38:57 iter 50 loss = 0.103406\n",
            "2020-01-19 18:39:00 iter 75 loss = 0.116709\n",
            "2020-01-19 18:39:03 iter 100 loss = 0.085812\n",
            "2020-01-19 18:39:03 epoch 230/500 average_loss = 0.096335\n",
            "\n",
            "2020-01-19 18:39:03 start epoch 231/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:39:03 iter 1 loss = 0.097594\n",
            "2020-01-19 18:39:06 iter 25 loss = 0.090877\n",
            "2020-01-19 18:39:10 iter 50 loss = 0.104592\n",
            "2020-01-19 18:39:13 iter 75 loss = 0.109524\n",
            "2020-01-19 18:39:16 iter 100 loss = 0.099451\n",
            "2020-01-19 18:39:16 epoch 231/500 average_loss = 0.097095\n",
            "\n",
            "2020-01-19 18:39:16 start epoch 232/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:39:16 iter 1 loss = 0.095025\n",
            "2020-01-19 18:39:19 iter 25 loss = 0.077781\n",
            "2020-01-19 18:39:22 iter 50 loss = 0.087956\n",
            "2020-01-19 18:39:25 iter 75 loss = 0.101975\n",
            "2020-01-19 18:39:29 iter 100 loss = 0.076507\n",
            "2020-01-19 18:39:29 epoch 232/500 average_loss = 0.097720\n",
            "\n",
            "2020-01-19 18:39:29 start epoch 233/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:39:29 iter 1 loss = 0.086250\n",
            "2020-01-19 18:39:32 iter 25 loss = 0.083638\n",
            "2020-01-19 18:39:35 iter 50 loss = 0.099205\n",
            "2020-01-19 18:39:38 iter 75 loss = 0.086265\n",
            "2020-01-19 18:39:41 iter 100 loss = 0.110188\n",
            "2020-01-19 18:39:41 epoch 233/500 average_loss = 0.097442\n",
            "\n",
            "2020-01-19 18:39:41 start epoch 234/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:39:41 iter 1 loss = 0.078014\n",
            "2020-01-19 18:39:44 iter 25 loss = 0.075666\n",
            "2020-01-19 18:39:48 iter 50 loss = 0.091580\n",
            "2020-01-19 18:39:51 iter 75 loss = 0.096230\n",
            "2020-01-19 18:39:54 iter 100 loss = 0.123535\n",
            "2020-01-19 18:39:54 epoch 234/500 average_loss = 0.095606\n",
            "\n",
            "2020-01-19 18:39:54 start epoch 235/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:39:54 iter 1 loss = 0.099103\n",
            "2020-01-19 18:39:57 iter 25 loss = 0.080179\n",
            "2020-01-19 18:40:00 iter 50 loss = 0.102729\n",
            "2020-01-19 18:40:03 iter 75 loss = 0.124679\n",
            "2020-01-19 18:40:06 iter 100 loss = 0.123191\n",
            "2020-01-19 18:40:06 epoch 235/500 average_loss = 0.093134\n",
            "\n",
            "2020-01-19 18:40:06 start epoch 236/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:40:07 iter 1 loss = 0.115697\n",
            "2020-01-19 18:40:10 iter 25 loss = 0.126005\n",
            "2020-01-19 18:40:13 iter 50 loss = 0.095478\n",
            "2020-01-19 18:40:16 iter 75 loss = 0.087174\n",
            "2020-01-19 18:40:19 iter 100 loss = 0.100941\n",
            "2020-01-19 18:40:19 epoch 236/500 average_loss = 0.095690\n",
            "\n",
            "2020-01-19 18:40:19 start epoch 237/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:40:19 iter 1 loss = 0.076499\n",
            "2020-01-19 18:40:22 iter 25 loss = 0.081898\n",
            "2020-01-19 18:40:26 iter 50 loss = 0.083387\n",
            "2020-01-19 18:40:29 iter 75 loss = 0.104101\n",
            "2020-01-19 18:40:32 iter 100 loss = 0.094642\n",
            "2020-01-19 18:40:32 epoch 237/500 average_loss = 0.094240\n",
            "\n",
            "2020-01-19 18:40:32 start epoch 238/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:40:32 iter 1 loss = 0.119908\n",
            "2020-01-19 18:40:35 iter 25 loss = 0.118523\n",
            "2020-01-19 18:40:38 iter 50 loss = 0.087069\n",
            "2020-01-19 18:40:41 iter 75 loss = 0.132365\n",
            "2020-01-19 18:40:44 iter 100 loss = 0.100714\n",
            "2020-01-19 18:40:44 epoch 238/500 average_loss = 0.095996\n",
            "\n",
            "2020-01-19 18:40:44 start epoch 239/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:40:44 iter 1 loss = 0.129007\n",
            "2020-01-19 18:40:47 iter 25 loss = 0.091594\n",
            "2020-01-19 18:40:51 iter 50 loss = 0.108878\n",
            "2020-01-19 18:40:54 iter 75 loss = 0.091379\n",
            "2020-01-19 18:40:57 iter 100 loss = 0.102407\n",
            "2020-01-19 18:40:57 epoch 239/500 average_loss = 0.094107\n",
            "\n",
            "2020-01-19 18:40:57 start epoch 240/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:40:57 iter 1 loss = 0.093396\n",
            "2020-01-19 18:41:00 iter 25 loss = 0.113475\n",
            "2020-01-19 18:41:03 iter 50 loss = 0.126780\n",
            "2020-01-19 18:41:06 iter 75 loss = 0.106587\n",
            "2020-01-19 18:41:10 iter 100 loss = 0.092247\n",
            "2020-01-19 18:41:10 epoch 240/500 average_loss = 0.097263\n",
            "\n",
            "2020-01-19 18:41:10 start epoch 241/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:41:10 iter 1 loss = 0.095130\n",
            "2020-01-19 18:41:13 iter 25 loss = 0.101953\n",
            "2020-01-19 18:41:16 iter 50 loss = 0.105542\n",
            "2020-01-19 18:41:19 iter 75 loss = 0.089286\n",
            "2020-01-19 18:41:22 iter 100 loss = 0.117508\n",
            "2020-01-19 18:41:22 epoch 241/500 average_loss = 0.093835\n",
            "\n",
            "2020-01-19 18:41:22 start epoch 242/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:41:22 iter 1 loss = 0.114777\n",
            "2020-01-19 18:41:25 iter 25 loss = 0.085411\n",
            "2020-01-19 18:41:29 iter 50 loss = 0.119996\n",
            "2020-01-19 18:41:32 iter 75 loss = 0.073868\n",
            "2020-01-19 18:41:35 iter 100 loss = 0.100330\n",
            "2020-01-19 18:41:35 epoch 242/500 average_loss = 0.093050\n",
            "\n",
            "2020-01-19 18:41:35 start epoch 243/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:41:35 iter 1 loss = 0.127517\n",
            "2020-01-19 18:41:38 iter 25 loss = 0.091941\n",
            "2020-01-19 18:41:41 iter 50 loss = 0.091249\n",
            "2020-01-19 18:41:44 iter 75 loss = 0.112569\n",
            "2020-01-19 18:41:47 iter 100 loss = 0.090282\n",
            "2020-01-19 18:41:47 epoch 243/500 average_loss = 0.095285\n",
            "\n",
            "2020-01-19 18:41:47 start epoch 244/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:41:48 iter 1 loss = 0.097772\n",
            "2020-01-19 18:41:51 iter 25 loss = 0.110577\n",
            "2020-01-19 18:41:54 iter 50 loss = 0.101350\n",
            "2020-01-19 18:41:57 iter 75 loss = 0.091331\n",
            "2020-01-19 18:42:00 iter 100 loss = 0.086592\n",
            "2020-01-19 18:42:00 epoch 244/500 average_loss = 0.095258\n",
            "\n",
            "2020-01-19 18:42:00 start epoch 245/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:42:00 iter 1 loss = 0.074887\n",
            "2020-01-19 18:42:03 iter 25 loss = 0.087792\n",
            "2020-01-19 18:42:06 iter 50 loss = 0.084005\n",
            "2020-01-19 18:42:10 iter 75 loss = 0.098769\n",
            "2020-01-19 18:42:13 iter 100 loss = 0.089984\n",
            "2020-01-19 18:42:13 epoch 245/500 average_loss = 0.094543\n",
            "\n",
            "2020-01-19 18:42:13 start epoch 246/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:42:13 iter 1 loss = 0.126909\n",
            "2020-01-19 18:42:16 iter 25 loss = 0.090130\n",
            "2020-01-19 18:42:19 iter 50 loss = 0.078833\n",
            "2020-01-19 18:42:22 iter 75 loss = 0.098107\n",
            "2020-01-19 18:42:25 iter 100 loss = 0.075192\n",
            "2020-01-19 18:42:25 epoch 246/500 average_loss = 0.093881\n",
            "\n",
            "2020-01-19 18:42:25 start epoch 247/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:42:26 iter 1 loss = 0.085039\n",
            "2020-01-19 18:42:29 iter 25 loss = 0.092741\n",
            "2020-01-19 18:42:32 iter 50 loss = 0.099673\n",
            "2020-01-19 18:42:35 iter 75 loss = 0.109615\n",
            "2020-01-19 18:42:38 iter 100 loss = 0.109677\n",
            "2020-01-19 18:42:38 epoch 247/500 average_loss = 0.094760\n",
            "\n",
            "2020-01-19 18:42:38 start epoch 248/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:42:38 iter 1 loss = 0.090634\n",
            "2020-01-19 18:42:41 iter 25 loss = 0.080175\n",
            "2020-01-19 18:42:44 iter 50 loss = 0.108480\n",
            "2020-01-19 18:42:48 iter 75 loss = 0.082024\n",
            "2020-01-19 18:42:51 iter 100 loss = 0.075434\n",
            "2020-01-19 18:42:51 epoch 248/500 average_loss = 0.092565\n",
            "\n",
            "2020-01-19 18:42:51 start epoch 249/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:42:51 iter 1 loss = 0.097179\n",
            "2020-01-19 18:42:54 iter 25 loss = 0.095093\n",
            "2020-01-19 18:42:57 iter 50 loss = 0.088351\n",
            "2020-01-19 18:43:00 iter 75 loss = 0.067560\n",
            "2020-01-19 18:43:03 iter 100 loss = 0.098590\n",
            "2020-01-19 18:43:03 epoch 249/500 average_loss = 0.093642\n",
            "\n",
            "2020-01-19 18:43:03 start epoch 250/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:43:03 iter 1 loss = 0.081434\n",
            "2020-01-19 18:43:06 iter 25 loss = 0.104177\n",
            "2020-01-19 18:43:10 iter 50 loss = 0.110245\n",
            "2020-01-19 18:43:13 iter 75 loss = 0.088140\n",
            "2020-01-19 18:43:16 iter 100 loss = 0.107702\n",
            "2020-01-19 18:43:16 epoch 250/500 average_loss = 0.093848\n",
            "\n",
            "2020-01-19 18:43:16 start epoch 251/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:43:16 iter 1 loss = 0.099682\n",
            "2020-01-19 18:43:19 iter 25 loss = 0.109272\n",
            "2020-01-19 18:43:22 iter 50 loss = 0.101822\n",
            "2020-01-19 18:43:26 iter 75 loss = 0.092389\n",
            "2020-01-19 18:43:29 iter 100 loss = 0.107476\n",
            "2020-01-19 18:43:29 epoch 251/500 average_loss = 0.093094\n",
            "\n",
            "2020-01-19 18:43:29 start epoch 252/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:43:29 iter 1 loss = 0.103195\n",
            "2020-01-19 18:43:32 iter 25 loss = 0.080783\n",
            "2020-01-19 18:43:35 iter 50 loss = 0.092649\n",
            "2020-01-19 18:43:38 iter 75 loss = 0.086127\n",
            "2020-01-19 18:43:41 iter 100 loss = 0.107075\n",
            "2020-01-19 18:43:41 epoch 252/500 average_loss = 0.091705\n",
            "\n",
            "2020-01-19 18:43:41 start epoch 253/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:43:41 iter 1 loss = 0.101935\n",
            "2020-01-19 18:43:44 iter 25 loss = 0.094087\n",
            "2020-01-19 18:43:48 iter 50 loss = 0.081396\n",
            "2020-01-19 18:43:51 iter 75 loss = 0.112070\n",
            "2020-01-19 18:43:54 iter 100 loss = 0.091879\n",
            "2020-01-19 18:43:54 epoch 253/500 average_loss = 0.093317\n",
            "\n",
            "2020-01-19 18:43:54 start epoch 254/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:43:54 iter 1 loss = 0.095436\n",
            "2020-01-19 18:43:57 iter 25 loss = 0.094236\n",
            "2020-01-19 18:44:00 iter 50 loss = 0.093824\n",
            "2020-01-19 18:44:03 iter 75 loss = 0.084243\n",
            "2020-01-19 18:44:07 iter 100 loss = 0.073908\n",
            "2020-01-19 18:44:07 epoch 254/500 average_loss = 0.090074\n",
            "\n",
            "2020-01-19 18:44:07 start epoch 255/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:44:07 iter 1 loss = 0.098454\n",
            "2020-01-19 18:44:10 iter 25 loss = 0.081609\n",
            "2020-01-19 18:44:13 iter 50 loss = 0.088623\n",
            "2020-01-19 18:44:16 iter 75 loss = 0.105229\n",
            "2020-01-19 18:44:19 iter 100 loss = 0.093244\n",
            "2020-01-19 18:44:19 epoch 255/500 average_loss = 0.091821\n",
            "\n",
            "2020-01-19 18:44:19 start epoch 256/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:44:19 iter 1 loss = 0.082477\n",
            "2020-01-19 18:44:22 iter 25 loss = 0.098242\n",
            "2020-01-19 18:44:26 iter 50 loss = 0.105840\n",
            "2020-01-19 18:44:29 iter 75 loss = 0.086220\n",
            "2020-01-19 18:44:32 iter 100 loss = 0.084121\n",
            "2020-01-19 18:44:32 epoch 256/500 average_loss = 0.092267\n",
            "\n",
            "2020-01-19 18:44:32 start epoch 257/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:44:32 iter 1 loss = 0.078545\n",
            "2020-01-19 18:44:35 iter 25 loss = 0.078219\n",
            "2020-01-19 18:44:38 iter 50 loss = 0.074793\n",
            "2020-01-19 18:44:41 iter 75 loss = 0.105478\n",
            "2020-01-19 18:44:45 iter 100 loss = 0.080469\n",
            "2020-01-19 18:44:45 epoch 257/500 average_loss = 0.089752\n",
            "\n",
            "2020-01-19 18:44:45 start epoch 258/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:44:45 iter 1 loss = 0.091487\n",
            "2020-01-19 18:44:48 iter 25 loss = 0.094861\n",
            "2020-01-19 18:44:51 iter 50 loss = 0.079186\n",
            "2020-01-19 18:44:54 iter 75 loss = 0.105885\n",
            "2020-01-19 18:44:57 iter 100 loss = 0.092641\n",
            "2020-01-19 18:44:57 epoch 258/500 average_loss = 0.089902\n",
            "\n",
            "2020-01-19 18:44:57 start epoch 259/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:44:57 iter 1 loss = 0.093882\n",
            "2020-01-19 18:45:00 iter 25 loss = 0.107717\n",
            "2020-01-19 18:45:04 iter 50 loss = 0.097318\n",
            "2020-01-19 18:45:07 iter 75 loss = 0.106521\n",
            "2020-01-19 18:45:10 iter 100 loss = 0.106950\n",
            "2020-01-19 18:45:10 epoch 259/500 average_loss = 0.090642\n",
            "\n",
            "2020-01-19 18:45:10 start epoch 260/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:45:10 iter 1 loss = 0.114366\n",
            "2020-01-19 18:45:13 iter 25 loss = 0.095426\n",
            "2020-01-19 18:45:16 iter 50 loss = 0.096157\n",
            "2020-01-19 18:45:20 iter 75 loss = 0.097893\n",
            "2020-01-19 18:45:23 iter 100 loss = 0.072467\n",
            "2020-01-19 18:45:23 epoch 260/500 average_loss = 0.090919\n",
            "\n",
            "2020-01-19 18:45:23 start epoch 261/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:45:23 iter 1 loss = 0.094287\n",
            "2020-01-19 18:45:26 iter 25 loss = 0.092747\n",
            "2020-01-19 18:45:29 iter 50 loss = 0.114034\n",
            "2020-01-19 18:45:32 iter 75 loss = 0.098373\n",
            "2020-01-19 18:45:35 iter 100 loss = 0.109378\n",
            "2020-01-19 18:45:35 epoch 261/500 average_loss = 0.090590\n",
            "\n",
            "2020-01-19 18:45:35 start epoch 262/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:45:35 iter 1 loss = 0.088413\n",
            "2020-01-19 18:45:39 iter 25 loss = 0.092612\n",
            "2020-01-19 18:45:42 iter 50 loss = 0.099293\n",
            "2020-01-19 18:45:45 iter 75 loss = 0.079859\n",
            "2020-01-19 18:45:48 iter 100 loss = 0.090271\n",
            "2020-01-19 18:45:48 epoch 262/500 average_loss = 0.091356\n",
            "\n",
            "2020-01-19 18:45:48 start epoch 263/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:45:48 iter 1 loss = 0.087888\n",
            "2020-01-19 18:45:51 iter 25 loss = 0.111851\n",
            "2020-01-19 18:45:54 iter 50 loss = 0.074089\n",
            "2020-01-19 18:45:57 iter 75 loss = 0.084229\n",
            "2020-01-19 18:46:01 iter 100 loss = 0.073362\n",
            "2020-01-19 18:46:01 epoch 263/500 average_loss = 0.089998\n",
            "\n",
            "2020-01-19 18:46:01 start epoch 264/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:46:01 iter 1 loss = 0.125475\n",
            "2020-01-19 18:46:04 iter 25 loss = 0.089919\n",
            "2020-01-19 18:46:07 iter 50 loss = 0.097546\n",
            "2020-01-19 18:46:10 iter 75 loss = 0.091412\n",
            "2020-01-19 18:46:13 iter 100 loss = 0.092183\n",
            "2020-01-19 18:46:13 epoch 264/500 average_loss = 0.090386\n",
            "\n",
            "2020-01-19 18:46:13 start epoch 265/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:46:13 iter 1 loss = 0.091512\n",
            "2020-01-19 18:46:17 iter 25 loss = 0.098331\n",
            "2020-01-19 18:46:20 iter 50 loss = 0.081207\n",
            "2020-01-19 18:46:23 iter 75 loss = 0.084646\n",
            "2020-01-19 18:46:26 iter 100 loss = 0.092530\n",
            "2020-01-19 18:46:26 epoch 265/500 average_loss = 0.089520\n",
            "\n",
            "2020-01-19 18:46:26 start epoch 266/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:46:26 iter 1 loss = 0.074774\n",
            "2020-01-19 18:46:29 iter 25 loss = 0.087866\n",
            "2020-01-19 18:46:32 iter 50 loss = 0.084732\n",
            "2020-01-19 18:46:36 iter 75 loss = 0.101574\n",
            "2020-01-19 18:46:39 iter 100 loss = 0.085486\n",
            "2020-01-19 18:46:39 epoch 266/500 average_loss = 0.089701\n",
            "\n",
            "2020-01-19 18:46:39 start epoch 267/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:46:39 iter 1 loss = 0.077946\n",
            "2020-01-19 18:46:42 iter 25 loss = 0.104000\n",
            "2020-01-19 18:46:45 iter 50 loss = 0.075725\n",
            "2020-01-19 18:46:48 iter 75 loss = 0.118694\n",
            "2020-01-19 18:46:51 iter 100 loss = 0.087549\n",
            "2020-01-19 18:46:51 epoch 267/500 average_loss = 0.090198\n",
            "\n",
            "2020-01-19 18:46:51 start epoch 268/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:46:52 iter 1 loss = 0.092946\n",
            "2020-01-19 18:46:54 iter 25 loss = 0.068704\n",
            "2020-01-19 18:46:58 iter 50 loss = 0.096214\n",
            "2020-01-19 18:47:01 iter 75 loss = 0.097809\n",
            "2020-01-19 18:47:04 iter 100 loss = 0.094265\n",
            "2020-01-19 18:47:04 epoch 268/500 average_loss = 0.087772\n",
            "\n",
            "2020-01-19 18:47:04 start epoch 269/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:47:04 iter 1 loss = 0.092021\n",
            "2020-01-19 18:47:07 iter 25 loss = 0.068892\n",
            "2020-01-19 18:47:10 iter 50 loss = 0.088107\n",
            "2020-01-19 18:47:14 iter 75 loss = 0.105420\n",
            "2020-01-19 18:47:17 iter 100 loss = 0.104086\n",
            "2020-01-19 18:47:17 epoch 269/500 average_loss = 0.090898\n",
            "\n",
            "2020-01-19 18:47:17 start epoch 270/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:47:17 iter 1 loss = 0.099190\n",
            "2020-01-19 18:47:20 iter 25 loss = 0.103612\n",
            "2020-01-19 18:47:23 iter 50 loss = 0.102280\n",
            "2020-01-19 18:47:26 iter 75 loss = 0.084303\n",
            "2020-01-19 18:47:29 iter 100 loss = 0.096732\n",
            "2020-01-19 18:47:29 epoch 270/500 average_loss = 0.088798\n",
            "\n",
            "2020-01-19 18:47:29 start epoch 271/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:47:30 iter 1 loss = 0.103335\n",
            "2020-01-19 18:47:33 iter 25 loss = 0.096788\n",
            "2020-01-19 18:47:36 iter 50 loss = 0.086245\n",
            "2020-01-19 18:47:39 iter 75 loss = 0.093132\n",
            "2020-01-19 18:47:42 iter 100 loss = 0.077893\n",
            "2020-01-19 18:47:42 epoch 271/500 average_loss = 0.091902\n",
            "\n",
            "2020-01-19 18:47:42 start epoch 272/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:47:42 iter 1 loss = 0.083039\n",
            "2020-01-19 18:47:45 iter 25 loss = 0.104440\n",
            "2020-01-19 18:47:48 iter 50 loss = 0.094831\n",
            "2020-01-19 18:47:52 iter 75 loss = 0.082664\n",
            "2020-01-19 18:47:55 iter 100 loss = 0.098079\n",
            "2020-01-19 18:47:55 epoch 272/500 average_loss = 0.091679\n",
            "\n",
            "2020-01-19 18:47:55 start epoch 273/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:47:55 iter 1 loss = 0.090760\n",
            "2020-01-19 18:47:58 iter 25 loss = 0.072887\n",
            "2020-01-19 18:48:01 iter 50 loss = 0.101187\n",
            "2020-01-19 18:48:04 iter 75 loss = 0.088288\n",
            "2020-01-19 18:48:08 iter 100 loss = 0.087837\n",
            "2020-01-19 18:48:08 epoch 273/500 average_loss = 0.091931\n",
            "\n",
            "2020-01-19 18:48:08 start epoch 274/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:48:08 iter 1 loss = 0.089968\n",
            "2020-01-19 18:48:11 iter 25 loss = 0.080124\n",
            "2020-01-19 18:48:14 iter 50 loss = 0.097245\n",
            "2020-01-19 18:48:17 iter 75 loss = 0.088957\n",
            "2020-01-19 18:48:20 iter 100 loss = 0.075051\n",
            "2020-01-19 18:48:20 epoch 274/500 average_loss = 0.088657\n",
            "\n",
            "2020-01-19 18:48:20 start epoch 275/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:48:20 iter 1 loss = 0.095158\n",
            "2020-01-19 18:48:23 iter 25 loss = 0.104141\n",
            "2020-01-19 18:48:27 iter 50 loss = 0.099238\n",
            "2020-01-19 18:48:30 iter 75 loss = 0.073420\n",
            "2020-01-19 18:48:33 iter 100 loss = 0.079444\n",
            "2020-01-19 18:48:33 epoch 275/500 average_loss = 0.088776\n",
            "\n",
            "2020-01-19 18:48:33 start epoch 276/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:48:33 iter 1 loss = 0.078625\n",
            "2020-01-19 18:48:36 iter 25 loss = 0.087878\n",
            "2020-01-19 18:48:39 iter 50 loss = 0.099785\n",
            "2020-01-19 18:48:42 iter 75 loss = 0.096074\n",
            "2020-01-19 18:48:46 iter 100 loss = 0.115477\n",
            "2020-01-19 18:48:46 epoch 276/500 average_loss = 0.090937\n",
            "\n",
            "2020-01-19 18:48:46 start epoch 277/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:48:46 iter 1 loss = 0.111540\n",
            "2020-01-19 18:48:49 iter 25 loss = 0.100197\n",
            "2020-01-19 18:48:52 iter 50 loss = 0.081518\n",
            "2020-01-19 18:48:55 iter 75 loss = 0.099611\n",
            "2020-01-19 18:48:58 iter 100 loss = 0.082858\n",
            "2020-01-19 18:48:58 epoch 277/500 average_loss = 0.087662\n",
            "\n",
            "2020-01-19 18:48:58 start epoch 278/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:48:58 iter 1 loss = 0.089225\n",
            "2020-01-19 18:49:01 iter 25 loss = 0.066494\n",
            "2020-01-19 18:49:04 iter 50 loss = 0.073202\n",
            "2020-01-19 18:49:08 iter 75 loss = 0.106557\n",
            "2020-01-19 18:49:11 iter 100 loss = 0.097529\n",
            "2020-01-19 18:49:11 epoch 278/500 average_loss = 0.086909\n",
            "\n",
            "2020-01-19 18:49:11 start epoch 279/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:49:11 iter 1 loss = 0.087217\n",
            "2020-01-19 18:49:14 iter 25 loss = 0.102281\n",
            "2020-01-19 18:49:17 iter 50 loss = 0.086251\n",
            "2020-01-19 18:49:20 iter 75 loss = 0.076981\n",
            "2020-01-19 18:49:23 iter 100 loss = 0.081814\n",
            "2020-01-19 18:49:23 epoch 279/500 average_loss = 0.089535\n",
            "\n",
            "2020-01-19 18:49:23 start epoch 280/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:49:24 iter 1 loss = 0.086492\n",
            "2020-01-19 18:49:27 iter 25 loss = 0.090607\n",
            "2020-01-19 18:49:30 iter 50 loss = 0.078105\n",
            "2020-01-19 18:49:33 iter 75 loss = 0.088052\n",
            "2020-01-19 18:49:36 iter 100 loss = 0.085045\n",
            "2020-01-19 18:49:36 epoch 280/500 average_loss = 0.087576\n",
            "\n",
            "2020-01-19 18:49:36 start epoch 281/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:49:36 iter 1 loss = 0.083574\n",
            "2020-01-19 18:49:39 iter 25 loss = 0.105810\n",
            "2020-01-19 18:49:42 iter 50 loss = 0.079551\n",
            "2020-01-19 18:49:46 iter 75 loss = 0.095989\n",
            "2020-01-19 18:49:49 iter 100 loss = 0.102086\n",
            "2020-01-19 18:49:49 epoch 281/500 average_loss = 0.088073\n",
            "\n",
            "2020-01-19 18:49:49 start epoch 282/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:49:49 iter 1 loss = 0.074389\n",
            "2020-01-19 18:49:52 iter 25 loss = 0.085399\n",
            "2020-01-19 18:49:55 iter 50 loss = 0.081116\n",
            "2020-01-19 18:49:58 iter 75 loss = 0.088058\n",
            "2020-01-19 18:50:01 iter 100 loss = 0.103462\n",
            "2020-01-19 18:50:01 epoch 282/500 average_loss = 0.087849\n",
            "\n",
            "2020-01-19 18:50:01 start epoch 283/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:50:01 iter 1 loss = 0.080436\n",
            "2020-01-19 18:50:04 iter 25 loss = 0.106891\n",
            "2020-01-19 18:50:07 iter 50 loss = 0.084644\n",
            "2020-01-19 18:50:11 iter 75 loss = 0.083427\n",
            "2020-01-19 18:50:14 iter 100 loss = 0.092346\n",
            "2020-01-19 18:50:14 epoch 283/500 average_loss = 0.088055\n",
            "\n",
            "2020-01-19 18:50:14 start epoch 284/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:50:14 iter 1 loss = 0.108087\n",
            "2020-01-19 18:50:17 iter 25 loss = 0.102406\n",
            "2020-01-19 18:50:20 iter 50 loss = 0.084399\n",
            "2020-01-19 18:50:23 iter 75 loss = 0.104613\n",
            "2020-01-19 18:50:27 iter 100 loss = 0.081169\n",
            "2020-01-19 18:50:27 epoch 284/500 average_loss = 0.088343\n",
            "\n",
            "2020-01-19 18:50:27 start epoch 285/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:50:27 iter 1 loss = 0.075556\n",
            "2020-01-19 18:50:30 iter 25 loss = 0.085052\n",
            "2020-01-19 18:50:33 iter 50 loss = 0.077963\n",
            "2020-01-19 18:50:36 iter 75 loss = 0.078960\n",
            "2020-01-19 18:50:39 iter 100 loss = 0.101488\n",
            "2020-01-19 18:50:39 epoch 285/500 average_loss = 0.087273\n",
            "\n",
            "2020-01-19 18:50:39 start epoch 286/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:50:39 iter 1 loss = 0.087840\n",
            "2020-01-19 18:50:42 iter 25 loss = 0.075324\n",
            "2020-01-19 18:50:45 iter 50 loss = 0.122372\n",
            "2020-01-19 18:50:49 iter 75 loss = 0.080027\n",
            "2020-01-19 18:50:52 iter 100 loss = 0.092633\n",
            "2020-01-19 18:50:52 epoch 286/500 average_loss = 0.086847\n",
            "\n",
            "2020-01-19 18:50:52 start epoch 287/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:50:52 iter 1 loss = 0.099434\n",
            "2020-01-19 18:50:55 iter 25 loss = 0.095301\n",
            "2020-01-19 18:50:58 iter 50 loss = 0.074712\n",
            "2020-01-19 18:51:01 iter 75 loss = 0.070330\n",
            "2020-01-19 18:51:04 iter 100 loss = 0.108517\n",
            "2020-01-19 18:51:04 epoch 287/500 average_loss = 0.085570\n",
            "\n",
            "2020-01-19 18:51:04 start epoch 288/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:51:04 iter 1 loss = 0.082297\n",
            "2020-01-19 18:51:07 iter 25 loss = 0.079603\n",
            "2020-01-19 18:51:11 iter 50 loss = 0.102376\n",
            "2020-01-19 18:51:14 iter 75 loss = 0.080221\n",
            "2020-01-19 18:51:17 iter 100 loss = 0.082208\n",
            "2020-01-19 18:51:17 epoch 288/500 average_loss = 0.088808\n",
            "\n",
            "2020-01-19 18:51:17 start epoch 289/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:51:17 iter 1 loss = 0.084924\n",
            "2020-01-19 18:51:20 iter 25 loss = 0.096924\n",
            "2020-01-19 18:51:23 iter 50 loss = 0.099861\n",
            "2020-01-19 18:51:27 iter 75 loss = 0.088309\n",
            "2020-01-19 18:51:30 iter 100 loss = 0.083862\n",
            "2020-01-19 18:51:30 epoch 289/500 average_loss = 0.086316\n",
            "\n",
            "2020-01-19 18:51:30 start epoch 290/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:51:30 iter 1 loss = 0.085083\n",
            "2020-01-19 18:51:33 iter 25 loss = 0.076646\n",
            "2020-01-19 18:51:36 iter 50 loss = 0.074107\n",
            "2020-01-19 18:51:39 iter 75 loss = 0.086709\n",
            "2020-01-19 18:51:42 iter 100 loss = 0.098820\n",
            "2020-01-19 18:51:42 epoch 290/500 average_loss = 0.085447\n",
            "\n",
            "2020-01-19 18:51:42 start epoch 291/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:51:42 iter 1 loss = 0.088739\n",
            "2020-01-19 18:51:45 iter 25 loss = 0.080137\n",
            "2020-01-19 18:51:48 iter 50 loss = 0.082928\n",
            "2020-01-19 18:51:52 iter 75 loss = 0.090907\n",
            "2020-01-19 18:51:55 iter 100 loss = 0.077777\n",
            "2020-01-19 18:51:55 epoch 291/500 average_loss = 0.085907\n",
            "\n",
            "2020-01-19 18:51:55 start epoch 292/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:51:55 iter 1 loss = 0.079947\n",
            "2020-01-19 18:51:58 iter 25 loss = 0.094132\n",
            "2020-01-19 18:52:01 iter 50 loss = 0.092214\n",
            "2020-01-19 18:52:04 iter 75 loss = 0.084396\n",
            "2020-01-19 18:52:08 iter 100 loss = 0.075877\n",
            "2020-01-19 18:52:08 epoch 292/500 average_loss = 0.086380\n",
            "\n",
            "2020-01-19 18:52:08 start epoch 293/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:52:08 iter 1 loss = 0.084743\n",
            "2020-01-19 18:52:11 iter 25 loss = 0.103353\n",
            "2020-01-19 18:52:14 iter 50 loss = 0.095269\n",
            "2020-01-19 18:52:17 iter 75 loss = 0.086563\n",
            "2020-01-19 18:52:20 iter 100 loss = 0.085088\n",
            "2020-01-19 18:52:20 epoch 293/500 average_loss = 0.085624\n",
            "\n",
            "2020-01-19 18:52:20 start epoch 294/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:52:20 iter 1 loss = 0.084401\n",
            "2020-01-19 18:52:23 iter 25 loss = 0.084807\n",
            "2020-01-19 18:52:26 iter 50 loss = 0.077183\n",
            "2020-01-19 18:52:30 iter 75 loss = 0.078394\n",
            "2020-01-19 18:52:33 iter 100 loss = 0.079151\n",
            "2020-01-19 18:52:33 epoch 294/500 average_loss = 0.083800\n",
            "\n",
            "2020-01-19 18:52:33 start epoch 295/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:52:33 iter 1 loss = 0.076980\n",
            "2020-01-19 18:52:36 iter 25 loss = 0.082358\n",
            "2020-01-19 18:52:39 iter 50 loss = 0.074275\n",
            "2020-01-19 18:52:42 iter 75 loss = 0.088781\n",
            "2020-01-19 18:52:45 iter 100 loss = 0.076899\n",
            "2020-01-19 18:52:45 epoch 295/500 average_loss = 0.086643\n",
            "\n",
            "2020-01-19 18:52:45 start epoch 296/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:52:45 iter 1 loss = 0.110283\n",
            "2020-01-19 18:52:49 iter 25 loss = 0.086298\n",
            "2020-01-19 18:52:52 iter 50 loss = 0.085009\n",
            "2020-01-19 18:52:55 iter 75 loss = 0.084375\n",
            "2020-01-19 18:52:58 iter 100 loss = 0.091108\n",
            "2020-01-19 18:52:58 epoch 296/500 average_loss = 0.087082\n",
            "\n",
            "2020-01-19 18:52:58 start epoch 297/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:52:58 iter 1 loss = 0.082945\n",
            "2020-01-19 18:53:01 iter 25 loss = 0.069176\n",
            "2020-01-19 18:53:05 iter 50 loss = 0.075935\n",
            "2020-01-19 18:53:08 iter 75 loss = 0.076382\n",
            "2020-01-19 18:53:11 iter 100 loss = 0.083910\n",
            "2020-01-19 18:53:11 epoch 297/500 average_loss = 0.086680\n",
            "\n",
            "2020-01-19 18:53:11 start epoch 298/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:53:11 iter 1 loss = 0.096486\n",
            "2020-01-19 18:53:14 iter 25 loss = 0.074292\n",
            "2020-01-19 18:53:17 iter 50 loss = 0.086101\n",
            "2020-01-19 18:53:20 iter 75 loss = 0.088252\n",
            "2020-01-19 18:53:23 iter 100 loss = 0.093510\n",
            "2020-01-19 18:53:23 epoch 298/500 average_loss = 0.085501\n",
            "\n",
            "2020-01-19 18:53:23 start epoch 299/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:53:24 iter 1 loss = 0.081694\n",
            "2020-01-19 18:53:27 iter 25 loss = 0.096898\n",
            "2020-01-19 18:53:30 iter 50 loss = 0.087382\n",
            "2020-01-19 18:53:33 iter 75 loss = 0.083469\n",
            "2020-01-19 18:53:36 iter 100 loss = 0.072699\n",
            "2020-01-19 18:53:36 epoch 299/500 average_loss = 0.084251\n",
            "\n",
            "2020-01-19 18:53:36 start epoch 300/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:53:36 iter 1 loss = 0.082800\n",
            "2020-01-19 18:53:39 iter 25 loss = 0.070694\n",
            "2020-01-19 18:53:42 iter 50 loss = 0.080911\n",
            "2020-01-19 18:53:46 iter 75 loss = 0.078186\n",
            "2020-01-19 18:53:49 iter 100 loss = 0.084581\n",
            "2020-01-19 18:53:49 epoch 300/500 average_loss = 0.086082\n",
            "\n",
            "2020-01-19 18:53:49 start epoch 301/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:53:49 iter 1 loss = 0.069600\n",
            "2020-01-19 18:53:52 iter 25 loss = 0.084821\n",
            "2020-01-19 18:53:55 iter 50 loss = 0.080053\n",
            "2020-01-19 18:53:58 iter 75 loss = 0.086871\n",
            "2020-01-19 18:54:01 iter 100 loss = 0.072714\n",
            "2020-01-19 18:54:01 epoch 301/500 average_loss = 0.085847\n",
            "\n",
            "2020-01-19 18:54:01 start epoch 302/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:54:01 iter 1 loss = 0.093079\n",
            "2020-01-19 18:54:04 iter 25 loss = 0.075701\n",
            "2020-01-19 18:54:08 iter 50 loss = 0.076529\n",
            "2020-01-19 18:54:11 iter 75 loss = 0.074047\n",
            "2020-01-19 18:54:14 iter 100 loss = 0.073151\n",
            "2020-01-19 18:54:14 epoch 302/500 average_loss = 0.085455\n",
            "\n",
            "2020-01-19 18:54:14 start epoch 303/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:54:14 iter 1 loss = 0.090250\n",
            "2020-01-19 18:54:17 iter 25 loss = 0.095463\n",
            "2020-01-19 18:54:20 iter 50 loss = 0.084556\n",
            "2020-01-19 18:54:23 iter 75 loss = 0.098837\n",
            "2020-01-19 18:54:27 iter 100 loss = 0.073488\n",
            "2020-01-19 18:54:27 epoch 303/500 average_loss = 0.084369\n",
            "\n",
            "2020-01-19 18:54:27 start epoch 304/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:54:27 iter 1 loss = 0.074875\n",
            "2020-01-19 18:54:30 iter 25 loss = 0.084135\n",
            "2020-01-19 18:54:33 iter 50 loss = 0.082797\n",
            "2020-01-19 18:54:36 iter 75 loss = 0.103515\n",
            "2020-01-19 18:54:39 iter 100 loss = 0.081323\n",
            "2020-01-19 18:54:39 epoch 304/500 average_loss = 0.084757\n",
            "\n",
            "2020-01-19 18:54:39 start epoch 305/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:54:39 iter 1 loss = 0.095840\n",
            "2020-01-19 18:54:42 iter 25 loss = 0.080588\n",
            "2020-01-19 18:54:45 iter 50 loss = 0.077412\n",
            "2020-01-19 18:54:49 iter 75 loss = 0.104664\n",
            "2020-01-19 18:54:52 iter 100 loss = 0.091373\n",
            "2020-01-19 18:54:52 epoch 305/500 average_loss = 0.085518\n",
            "\n",
            "2020-01-19 18:54:52 start epoch 306/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:54:52 iter 1 loss = 0.083811\n",
            "2020-01-19 18:54:55 iter 25 loss = 0.074944\n",
            "2020-01-19 18:54:58 iter 50 loss = 0.086841\n",
            "2020-01-19 18:55:01 iter 75 loss = 0.076956\n",
            "2020-01-19 18:55:04 iter 100 loss = 0.072542\n",
            "2020-01-19 18:55:04 epoch 306/500 average_loss = 0.085079\n",
            "\n",
            "2020-01-19 18:55:04 start epoch 307/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:55:05 iter 1 loss = 0.086517\n",
            "2020-01-19 18:55:08 iter 25 loss = 0.070902\n",
            "2020-01-19 18:55:11 iter 50 loss = 0.083322\n",
            "2020-01-19 18:55:14 iter 75 loss = 0.093043\n",
            "2020-01-19 18:55:17 iter 100 loss = 0.095126\n",
            "2020-01-19 18:55:17 epoch 307/500 average_loss = 0.083898\n",
            "\n",
            "2020-01-19 18:55:17 start epoch 308/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:55:17 iter 1 loss = 0.080538\n",
            "2020-01-19 18:55:20 iter 25 loss = 0.083396\n",
            "2020-01-19 18:55:23 iter 50 loss = 0.087131\n",
            "2020-01-19 18:55:27 iter 75 loss = 0.087236\n",
            "2020-01-19 18:55:30 iter 100 loss = 0.092015\n",
            "2020-01-19 18:55:30 epoch 308/500 average_loss = 0.085292\n",
            "\n",
            "2020-01-19 18:55:30 start epoch 309/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:55:30 iter 1 loss = 0.083390\n",
            "2020-01-19 18:55:33 iter 25 loss = 0.074353\n",
            "2020-01-19 18:55:36 iter 50 loss = 0.079552\n",
            "2020-01-19 18:55:39 iter 75 loss = 0.086663\n",
            "2020-01-19 18:55:42 iter 100 loss = 0.083065\n",
            "2020-01-19 18:55:42 epoch 309/500 average_loss = 0.086144\n",
            "\n",
            "2020-01-19 18:55:42 start epoch 310/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:55:42 iter 1 loss = 0.101937\n",
            "2020-01-19 18:55:45 iter 25 loss = 0.090749\n",
            "2020-01-19 18:55:49 iter 50 loss = 0.082125\n",
            "2020-01-19 18:55:52 iter 75 loss = 0.077163\n",
            "2020-01-19 18:55:55 iter 100 loss = 0.088450\n",
            "2020-01-19 18:55:55 epoch 310/500 average_loss = 0.087793\n",
            "\n",
            "2020-01-19 18:55:55 start epoch 311/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:55:55 iter 1 loss = 0.064797\n",
            "2020-01-19 18:55:58 iter 25 loss = 0.073434\n",
            "2020-01-19 18:56:01 iter 50 loss = 0.117054\n",
            "2020-01-19 18:56:04 iter 75 loss = 0.103589\n",
            "2020-01-19 18:56:08 iter 100 loss = 0.077574\n",
            "2020-01-19 18:56:08 epoch 311/500 average_loss = 0.086796\n",
            "\n",
            "2020-01-19 18:56:08 start epoch 312/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:56:08 iter 1 loss = 0.095656\n",
            "2020-01-19 18:56:11 iter 25 loss = 0.076841\n",
            "2020-01-19 18:56:14 iter 50 loss = 0.077359\n",
            "2020-01-19 18:56:17 iter 75 loss = 0.080374\n",
            "2020-01-19 18:56:20 iter 100 loss = 0.097151\n",
            "2020-01-19 18:56:20 epoch 312/500 average_loss = 0.085273\n",
            "\n",
            "2020-01-19 18:56:20 start epoch 313/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:56:20 iter 1 loss = 0.088758\n",
            "2020-01-19 18:56:23 iter 25 loss = 0.102173\n",
            "2020-01-19 18:56:27 iter 50 loss = 0.092830\n",
            "2020-01-19 18:56:30 iter 75 loss = 0.117959\n",
            "2020-01-19 18:56:33 iter 100 loss = 0.083923\n",
            "2020-01-19 18:56:33 epoch 313/500 average_loss = 0.087466\n",
            "\n",
            "2020-01-19 18:56:33 start epoch 314/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:56:33 iter 1 loss = 0.092904\n",
            "2020-01-19 18:56:36 iter 25 loss = 0.083729\n",
            "2020-01-19 18:56:39 iter 50 loss = 0.094686\n",
            "2020-01-19 18:56:42 iter 75 loss = 0.087977\n",
            "2020-01-19 18:56:46 iter 100 loss = 0.091543\n",
            "2020-01-19 18:56:46 epoch 314/500 average_loss = 0.085991\n",
            "\n",
            "2020-01-19 18:56:46 start epoch 315/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:56:46 iter 1 loss = 0.089112\n",
            "2020-01-19 18:56:49 iter 25 loss = 0.073529\n",
            "2020-01-19 18:56:52 iter 50 loss = 0.085537\n",
            "2020-01-19 18:56:55 iter 75 loss = 0.079176\n",
            "2020-01-19 18:56:58 iter 100 loss = 0.097852\n",
            "2020-01-19 18:56:58 epoch 315/500 average_loss = 0.084895\n",
            "\n",
            "2020-01-19 18:56:58 start epoch 316/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:56:58 iter 1 loss = 0.080751\n",
            "2020-01-19 18:57:01 iter 25 loss = 0.096504\n",
            "2020-01-19 18:57:05 iter 50 loss = 0.076151\n",
            "2020-01-19 18:57:08 iter 75 loss = 0.073770\n",
            "2020-01-19 18:57:11 iter 100 loss = 0.102461\n",
            "2020-01-19 18:57:11 epoch 316/500 average_loss = 0.084655\n",
            "\n",
            "2020-01-19 18:57:11 start epoch 317/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:57:11 iter 1 loss = 0.077184\n",
            "2020-01-19 18:57:14 iter 25 loss = 0.094474\n",
            "2020-01-19 18:57:17 iter 50 loss = 0.078384\n",
            "2020-01-19 18:57:21 iter 75 loss = 0.070996\n",
            "2020-01-19 18:57:24 iter 100 loss = 0.083017\n",
            "2020-01-19 18:57:24 epoch 317/500 average_loss = 0.084584\n",
            "\n",
            "2020-01-19 18:57:24 start epoch 318/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:57:24 iter 1 loss = 0.093646\n",
            "2020-01-19 18:57:27 iter 25 loss = 0.054253\n",
            "2020-01-19 18:57:30 iter 50 loss = 0.090725\n",
            "2020-01-19 18:57:33 iter 75 loss = 0.082141\n",
            "2020-01-19 18:57:36 iter 100 loss = 0.066162\n",
            "2020-01-19 18:57:36 epoch 318/500 average_loss = 0.084915\n",
            "\n",
            "2020-01-19 18:57:36 start epoch 319/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:57:36 iter 1 loss = 0.096368\n",
            "2020-01-19 18:57:39 iter 25 loss = 0.080326\n",
            "2020-01-19 18:57:43 iter 50 loss = 0.071307\n",
            "2020-01-19 18:57:46 iter 75 loss = 0.068794\n",
            "2020-01-19 18:57:49 iter 100 loss = 0.091648\n",
            "2020-01-19 18:57:49 epoch 319/500 average_loss = 0.085765\n",
            "\n",
            "2020-01-19 18:57:49 start epoch 320/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:57:49 iter 1 loss = 0.079588\n",
            "2020-01-19 18:57:52 iter 25 loss = 0.082548\n",
            "2020-01-19 18:57:55 iter 50 loss = 0.084215\n",
            "2020-01-19 18:57:58 iter 75 loss = 0.108871\n",
            "2020-01-19 18:58:01 iter 100 loss = 0.091634\n",
            "2020-01-19 18:58:01 epoch 320/500 average_loss = 0.088005\n",
            "\n",
            "2020-01-19 18:58:01 start epoch 321/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:58:02 iter 1 loss = 0.094800\n",
            "2020-01-19 18:58:05 iter 25 loss = 0.081212\n",
            "2020-01-19 18:58:08 iter 50 loss = 0.078289\n",
            "2020-01-19 18:58:11 iter 75 loss = 0.110441\n",
            "2020-01-19 18:58:14 iter 100 loss = 0.086281\n",
            "2020-01-19 18:58:14 epoch 321/500 average_loss = 0.086404\n",
            "\n",
            "2020-01-19 18:58:14 start epoch 322/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:58:14 iter 1 loss = 0.075956\n",
            "2020-01-19 18:58:17 iter 25 loss = 0.078628\n",
            "2020-01-19 18:58:21 iter 50 loss = 0.081251\n",
            "2020-01-19 18:58:24 iter 75 loss = 0.109472\n",
            "2020-01-19 18:58:27 iter 100 loss = 0.079308\n",
            "2020-01-19 18:58:27 epoch 322/500 average_loss = 0.085889\n",
            "\n",
            "2020-01-19 18:58:27 start epoch 323/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:58:27 iter 1 loss = 0.086595\n",
            "2020-01-19 18:58:30 iter 25 loss = 0.082823\n",
            "2020-01-19 18:58:33 iter 50 loss = 0.090137\n",
            "2020-01-19 18:58:36 iter 75 loss = 0.090630\n",
            "2020-01-19 18:58:40 iter 100 loss = 0.096863\n",
            "2020-01-19 18:58:40 epoch 323/500 average_loss = 0.084147\n",
            "\n",
            "2020-01-19 18:58:40 start epoch 324/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:58:40 iter 1 loss = 0.076211\n",
            "2020-01-19 18:58:43 iter 25 loss = 0.069951\n",
            "2020-01-19 18:58:46 iter 50 loss = 0.081568\n",
            "2020-01-19 18:58:49 iter 75 loss = 0.089798\n",
            "2020-01-19 18:58:52 iter 100 loss = 0.079289\n",
            "2020-01-19 18:58:52 epoch 324/500 average_loss = 0.082724\n",
            "\n",
            "2020-01-19 18:58:52 start epoch 325/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:58:52 iter 1 loss = 0.070817\n",
            "2020-01-19 18:58:55 iter 25 loss = 0.077625\n",
            "2020-01-19 18:58:58 iter 50 loss = 0.086645\n",
            "2020-01-19 18:59:02 iter 75 loss = 0.070317\n",
            "2020-01-19 18:59:05 iter 100 loss = 0.099086\n",
            "2020-01-19 18:59:05 epoch 325/500 average_loss = 0.083133\n",
            "\n",
            "2020-01-19 18:59:05 start epoch 326/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:59:05 iter 1 loss = 0.071891\n",
            "2020-01-19 18:59:08 iter 25 loss = 0.083222\n",
            "2020-01-19 18:59:11 iter 50 loss = 0.101087\n",
            "2020-01-19 18:59:14 iter 75 loss = 0.081745\n",
            "2020-01-19 18:59:17 iter 100 loss = 0.091578\n",
            "2020-01-19 18:59:17 epoch 326/500 average_loss = 0.083763\n",
            "\n",
            "2020-01-19 18:59:17 start epoch 327/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:59:18 iter 1 loss = 0.086348\n",
            "2020-01-19 18:59:21 iter 25 loss = 0.087315\n",
            "2020-01-19 18:59:24 iter 50 loss = 0.099614\n",
            "2020-01-19 18:59:27 iter 75 loss = 0.096312\n",
            "2020-01-19 18:59:30 iter 100 loss = 0.102449\n",
            "2020-01-19 18:59:30 epoch 327/500 average_loss = 0.084469\n",
            "\n",
            "2020-01-19 18:59:30 start epoch 328/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:59:30 iter 1 loss = 0.081828\n",
            "2020-01-19 18:59:33 iter 25 loss = 0.079642\n",
            "2020-01-19 18:59:37 iter 50 loss = 0.085525\n",
            "2020-01-19 18:59:40 iter 75 loss = 0.073971\n",
            "2020-01-19 18:59:43 iter 100 loss = 0.065815\n",
            "2020-01-19 18:59:43 epoch 328/500 average_loss = 0.082772\n",
            "\n",
            "2020-01-19 18:59:43 start epoch 329/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:59:43 iter 1 loss = 0.085722\n",
            "2020-01-19 18:59:46 iter 25 loss = 0.078292\n",
            "2020-01-19 18:59:49 iter 50 loss = 0.097880\n",
            "2020-01-19 18:59:52 iter 75 loss = 0.079431\n",
            "2020-01-19 18:59:55 iter 100 loss = 0.092369\n",
            "2020-01-19 18:59:55 epoch 329/500 average_loss = 0.082249\n",
            "\n",
            "2020-01-19 18:59:55 start epoch 330/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 18:59:56 iter 1 loss = 0.084882\n",
            "2020-01-19 18:59:59 iter 25 loss = 0.080022\n",
            "2020-01-19 19:00:02 iter 50 loss = 0.075805\n",
            "2020-01-19 19:00:05 iter 75 loss = 0.088059\n",
            "2020-01-19 19:00:08 iter 100 loss = 0.077765\n",
            "2020-01-19 19:00:08 epoch 330/500 average_loss = 0.083267\n",
            "\n",
            "2020-01-19 19:00:08 start epoch 331/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:00:08 iter 1 loss = 0.070160\n",
            "2020-01-19 19:00:11 iter 25 loss = 0.089685\n",
            "2020-01-19 19:00:14 iter 50 loss = 0.070298\n",
            "2020-01-19 19:00:18 iter 75 loss = 0.089174\n",
            "2020-01-19 19:00:21 iter 100 loss = 0.091021\n",
            "2020-01-19 19:00:21 epoch 331/500 average_loss = 0.083190\n",
            "\n",
            "2020-01-19 19:00:21 start epoch 332/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:00:21 iter 1 loss = 0.077029\n",
            "2020-01-19 19:00:24 iter 25 loss = 0.089262\n",
            "2020-01-19 19:00:27 iter 50 loss = 0.074669\n",
            "2020-01-19 19:00:30 iter 75 loss = 0.073955\n",
            "2020-01-19 19:00:33 iter 100 loss = 0.074288\n",
            "2020-01-19 19:00:33 epoch 332/500 average_loss = 0.084111\n",
            "\n",
            "2020-01-19 19:00:33 start epoch 333/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:00:33 iter 1 loss = 0.099458\n",
            "2020-01-19 19:00:36 iter 25 loss = 0.075556\n",
            "2020-01-19 19:00:40 iter 50 loss = 0.075516\n",
            "2020-01-19 19:00:43 iter 75 loss = 0.079765\n",
            "2020-01-19 19:00:46 iter 100 loss = 0.096341\n",
            "2020-01-19 19:00:46 epoch 333/500 average_loss = 0.083085\n",
            "\n",
            "2020-01-19 19:00:46 start epoch 334/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:00:46 iter 1 loss = 0.092692\n",
            "2020-01-19 19:00:49 iter 25 loss = 0.116761\n",
            "2020-01-19 19:00:52 iter 50 loss = 0.089420\n",
            "2020-01-19 19:00:55 iter 75 loss = 0.115583\n",
            "2020-01-19 19:00:58 iter 100 loss = 0.087174\n",
            "2020-01-19 19:00:58 epoch 334/500 average_loss = 0.084822\n",
            "\n",
            "2020-01-19 19:00:58 start epoch 335/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:00:59 iter 1 loss = 0.074509\n",
            "2020-01-19 19:01:02 iter 25 loss = 0.089681\n",
            "2020-01-19 19:01:05 iter 50 loss = 0.086548\n",
            "2020-01-19 19:01:08 iter 75 loss = 0.082381\n",
            "2020-01-19 19:01:11 iter 100 loss = 0.094134\n",
            "2020-01-19 19:01:11 epoch 335/500 average_loss = 0.083881\n",
            "\n",
            "2020-01-19 19:01:11 start epoch 336/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:01:11 iter 1 loss = 0.084001\n",
            "2020-01-19 19:01:14 iter 25 loss = 0.094413\n",
            "2020-01-19 19:01:18 iter 50 loss = 0.068729\n",
            "2020-01-19 19:01:21 iter 75 loss = 0.078125\n",
            "2020-01-19 19:01:24 iter 100 loss = 0.078457\n",
            "2020-01-19 19:01:24 epoch 336/500 average_loss = 0.083533\n",
            "\n",
            "2020-01-19 19:01:24 start epoch 337/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:01:24 iter 1 loss = 0.080969\n",
            "2020-01-19 19:01:27 iter 25 loss = 0.080555\n",
            "2020-01-19 19:01:30 iter 50 loss = 0.086313\n",
            "2020-01-19 19:01:33 iter 75 loss = 0.072773\n",
            "2020-01-19 19:01:36 iter 100 loss = 0.112687\n",
            "2020-01-19 19:01:36 epoch 337/500 average_loss = 0.082948\n",
            "\n",
            "2020-01-19 19:01:36 start epoch 338/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:01:37 iter 1 loss = 0.066998\n",
            "2020-01-19 19:01:40 iter 25 loss = 0.088367\n",
            "2020-01-19 19:01:43 iter 50 loss = 0.069999\n",
            "2020-01-19 19:01:46 iter 75 loss = 0.084733\n",
            "2020-01-19 19:01:49 iter 100 loss = 0.075957\n",
            "2020-01-19 19:01:49 epoch 338/500 average_loss = 0.084391\n",
            "\n",
            "2020-01-19 19:01:49 start epoch 339/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:01:49 iter 1 loss = 0.074803\n",
            "2020-01-19 19:01:52 iter 25 loss = 0.085325\n",
            "2020-01-19 19:01:55 iter 50 loss = 0.069493\n",
            "2020-01-19 19:01:59 iter 75 loss = 0.079522\n",
            "2020-01-19 19:02:02 iter 100 loss = 0.087756\n",
            "2020-01-19 19:02:02 epoch 339/500 average_loss = 0.082095\n",
            "\n",
            "2020-01-19 19:02:02 start epoch 340/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:02:02 iter 1 loss = 0.077176\n",
            "2020-01-19 19:02:05 iter 25 loss = 0.078859\n",
            "2020-01-19 19:02:08 iter 50 loss = 0.072843\n",
            "2020-01-19 19:02:11 iter 75 loss = 0.083413\n",
            "2020-01-19 19:02:14 iter 100 loss = 0.096521\n",
            "2020-01-19 19:02:14 epoch 340/500 average_loss = 0.083986\n",
            "\n",
            "2020-01-19 19:02:14 start epoch 341/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:02:15 iter 1 loss = 0.072510\n",
            "2020-01-19 19:02:18 iter 25 loss = 0.084947\n",
            "2020-01-19 19:02:21 iter 50 loss = 0.085703\n",
            "2020-01-19 19:02:24 iter 75 loss = 0.071477\n",
            "2020-01-19 19:02:27 iter 100 loss = 0.075426\n",
            "2020-01-19 19:02:27 epoch 341/500 average_loss = 0.082091\n",
            "\n",
            "2020-01-19 19:02:27 start epoch 342/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:02:27 iter 1 loss = 0.075954\n",
            "2020-01-19 19:02:30 iter 25 loss = 0.068460\n",
            "2020-01-19 19:02:33 iter 50 loss = 0.081778\n",
            "2020-01-19 19:02:37 iter 75 loss = 0.110542\n",
            "2020-01-19 19:02:40 iter 100 loss = 0.082579\n",
            "2020-01-19 19:02:40 epoch 342/500 average_loss = 0.081097\n",
            "\n",
            "2020-01-19 19:02:40 start epoch 343/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:02:40 iter 1 loss = 0.110152\n",
            "2020-01-19 19:02:43 iter 25 loss = 0.073652\n",
            "2020-01-19 19:02:46 iter 50 loss = 0.088339\n",
            "2020-01-19 19:02:49 iter 75 loss = 0.073948\n",
            "2020-01-19 19:02:52 iter 100 loss = 0.089037\n",
            "2020-01-19 19:02:52 epoch 343/500 average_loss = 0.082672\n",
            "\n",
            "2020-01-19 19:02:52 start epoch 344/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:02:52 iter 1 loss = 0.090781\n",
            "2020-01-19 19:02:55 iter 25 loss = 0.102756\n",
            "2020-01-19 19:02:59 iter 50 loss = 0.075740\n",
            "2020-01-19 19:03:02 iter 75 loss = 0.070907\n",
            "2020-01-19 19:03:05 iter 100 loss = 0.090215\n",
            "2020-01-19 19:03:05 epoch 344/500 average_loss = 0.082748\n",
            "\n",
            "2020-01-19 19:03:05 start epoch 345/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:03:05 iter 1 loss = 0.072165\n",
            "2020-01-19 19:03:08 iter 25 loss = 0.091351\n",
            "2020-01-19 19:03:11 iter 50 loss = 0.084686\n",
            "2020-01-19 19:03:14 iter 75 loss = 0.080396\n",
            "2020-01-19 19:03:18 iter 100 loss = 0.075411\n",
            "2020-01-19 19:03:18 epoch 345/500 average_loss = 0.081919\n",
            "\n",
            "2020-01-19 19:03:18 start epoch 346/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:03:18 iter 1 loss = 0.069868\n",
            "2020-01-19 19:03:21 iter 25 loss = 0.079182\n",
            "2020-01-19 19:03:24 iter 50 loss = 0.105106\n",
            "2020-01-19 19:03:27 iter 75 loss = 0.104013\n",
            "2020-01-19 19:03:30 iter 100 loss = 0.103043\n",
            "2020-01-19 19:03:30 epoch 346/500 average_loss = 0.083002\n",
            "\n",
            "2020-01-19 19:03:30 start epoch 347/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:03:31 iter 1 loss = 0.073504\n",
            "2020-01-19 19:03:34 iter 25 loss = 0.068347\n",
            "2020-01-19 19:03:37 iter 50 loss = 0.087246\n",
            "2020-01-19 19:03:40 iter 75 loss = 0.087428\n",
            "2020-01-19 19:03:43 iter 100 loss = 0.077286\n",
            "2020-01-19 19:03:43 epoch 347/500 average_loss = 0.083037\n",
            "\n",
            "2020-01-19 19:03:43 start epoch 348/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:03:43 iter 1 loss = 0.079082\n",
            "2020-01-19 19:03:46 iter 25 loss = 0.080817\n",
            "2020-01-19 19:03:49 iter 50 loss = 0.107388\n",
            "2020-01-19 19:03:52 iter 75 loss = 0.068102\n",
            "2020-01-19 19:03:56 iter 100 loss = 0.073117\n",
            "2020-01-19 19:03:56 epoch 348/500 average_loss = 0.084341\n",
            "\n",
            "2020-01-19 19:03:56 start epoch 349/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:03:56 iter 1 loss = 0.092617\n",
            "2020-01-19 19:03:59 iter 25 loss = 0.071458\n",
            "2020-01-19 19:04:02 iter 50 loss = 0.083219\n",
            "2020-01-19 19:04:05 iter 75 loss = 0.071217\n",
            "2020-01-19 19:04:08 iter 100 loss = 0.080436\n",
            "2020-01-19 19:04:08 epoch 349/500 average_loss = 0.081180\n",
            "\n",
            "2020-01-19 19:04:08 start epoch 350/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:04:08 iter 1 loss = 0.076655\n",
            "2020-01-19 19:04:11 iter 25 loss = 0.087177\n",
            "2020-01-19 19:04:15 iter 50 loss = 0.087735\n",
            "2020-01-19 19:04:18 iter 75 loss = 0.080502\n",
            "2020-01-19 19:04:21 iter 100 loss = 0.078068\n",
            "2020-01-19 19:04:21 epoch 350/500 average_loss = 0.081444\n",
            "\n",
            "2020-01-19 19:04:21 start epoch 351/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:04:21 iter 1 loss = 0.085983\n",
            "2020-01-19 19:04:24 iter 25 loss = 0.088082\n",
            "2020-01-19 19:04:27 iter 50 loss = 0.072986\n",
            "2020-01-19 19:04:30 iter 75 loss = 0.068661\n",
            "2020-01-19 19:04:34 iter 100 loss = 0.080643\n",
            "2020-01-19 19:04:34 epoch 351/500 average_loss = 0.080176\n",
            "\n",
            "2020-01-19 19:04:34 start epoch 352/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:04:34 iter 1 loss = 0.076744\n",
            "2020-01-19 19:04:37 iter 25 loss = 0.093077\n",
            "2020-01-19 19:04:40 iter 50 loss = 0.087230\n",
            "2020-01-19 19:04:43 iter 75 loss = 0.073764\n",
            "2020-01-19 19:04:46 iter 100 loss = 0.076048\n",
            "2020-01-19 19:04:46 epoch 352/500 average_loss = 0.082640\n",
            "\n",
            "2020-01-19 19:04:46 start epoch 353/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:04:46 iter 1 loss = 0.083399\n",
            "2020-01-19 19:04:49 iter 25 loss = 0.080066\n",
            "2020-01-19 19:04:53 iter 50 loss = 0.081917\n",
            "2020-01-19 19:04:56 iter 75 loss = 0.092200\n",
            "2020-01-19 19:04:59 iter 100 loss = 0.082469\n",
            "2020-01-19 19:04:59 epoch 353/500 average_loss = 0.082437\n",
            "\n",
            "2020-01-19 19:04:59 start epoch 354/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:04:59 iter 1 loss = 0.071523\n",
            "2020-01-19 19:05:02 iter 25 loss = 0.089978\n",
            "2020-01-19 19:05:05 iter 50 loss = 0.082416\n",
            "2020-01-19 19:05:08 iter 75 loss = 0.071719\n",
            "2020-01-19 19:05:11 iter 100 loss = 0.084027\n",
            "2020-01-19 19:05:11 epoch 354/500 average_loss = 0.081434\n",
            "\n",
            "2020-01-19 19:05:11 start epoch 355/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:05:12 iter 1 loss = 0.070097\n",
            "2020-01-19 19:05:15 iter 25 loss = 0.076387\n",
            "2020-01-19 19:05:18 iter 50 loss = 0.081754\n",
            "2020-01-19 19:05:21 iter 75 loss = 0.092737\n",
            "2020-01-19 19:05:24 iter 100 loss = 0.069579\n",
            "2020-01-19 19:05:24 epoch 355/500 average_loss = 0.081068\n",
            "\n",
            "2020-01-19 19:05:24 start epoch 356/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:05:24 iter 1 loss = 0.077687\n",
            "2020-01-19 19:05:27 iter 25 loss = 0.098197\n",
            "2020-01-19 19:05:31 iter 50 loss = 0.076934\n",
            "2020-01-19 19:05:34 iter 75 loss = 0.103690\n",
            "2020-01-19 19:05:37 iter 100 loss = 0.088270\n",
            "2020-01-19 19:05:37 epoch 356/500 average_loss = 0.080147\n",
            "\n",
            "2020-01-19 19:05:37 start epoch 357/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:05:37 iter 1 loss = 0.074525\n",
            "2020-01-19 19:05:40 iter 25 loss = 0.078840\n",
            "2020-01-19 19:05:43 iter 50 loss = 0.075728\n",
            "2020-01-19 19:05:46 iter 75 loss = 0.077134\n",
            "2020-01-19 19:05:49 iter 100 loss = 0.090217\n",
            "2020-01-19 19:05:49 epoch 357/500 average_loss = 0.081455\n",
            "\n",
            "2020-01-19 19:05:49 start epoch 358/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:05:49 iter 1 loss = 0.088392\n",
            "2020-01-19 19:05:52 iter 25 loss = 0.089699\n",
            "2020-01-19 19:05:56 iter 50 loss = 0.096110\n",
            "2020-01-19 19:05:59 iter 75 loss = 0.080324\n",
            "2020-01-19 19:06:02 iter 100 loss = 0.078667\n",
            "2020-01-19 19:06:02 epoch 358/500 average_loss = 0.081978\n",
            "\n",
            "2020-01-19 19:06:02 start epoch 359/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:06:02 iter 1 loss = 0.069846\n",
            "2020-01-19 19:06:05 iter 25 loss = 0.095582\n",
            "2020-01-19 19:06:08 iter 50 loss = 0.080920\n",
            "2020-01-19 19:06:11 iter 75 loss = 0.081622\n",
            "2020-01-19 19:06:15 iter 100 loss = 0.071223\n",
            "2020-01-19 19:06:15 epoch 359/500 average_loss = 0.080228\n",
            "\n",
            "2020-01-19 19:06:15 start epoch 360/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:06:15 iter 1 loss = 0.074229\n",
            "2020-01-19 19:06:18 iter 25 loss = 0.085967\n",
            "2020-01-19 19:06:21 iter 50 loss = 0.073987\n",
            "2020-01-19 19:06:24 iter 75 loss = 0.071845\n",
            "2020-01-19 19:06:27 iter 100 loss = 0.085250\n",
            "2020-01-19 19:06:27 epoch 360/500 average_loss = 0.080636\n",
            "\n",
            "2020-01-19 19:06:27 start epoch 361/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:06:27 iter 1 loss = 0.097768\n",
            "2020-01-19 19:06:30 iter 25 loss = 0.082745\n",
            "2020-01-19 19:06:34 iter 50 loss = 0.092840\n",
            "2020-01-19 19:06:37 iter 75 loss = 0.083800\n",
            "2020-01-19 19:06:40 iter 100 loss = 0.078862\n",
            "2020-01-19 19:06:40 epoch 361/500 average_loss = 0.080386\n",
            "\n",
            "2020-01-19 19:06:40 start epoch 362/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:06:40 iter 1 loss = 0.080974\n",
            "2020-01-19 19:06:43 iter 25 loss = 0.098013\n",
            "2020-01-19 19:06:46 iter 50 loss = 0.066543\n",
            "2020-01-19 19:06:49 iter 75 loss = 0.080447\n",
            "2020-01-19 19:06:53 iter 100 loss = 0.071170\n",
            "2020-01-19 19:06:53 epoch 362/500 average_loss = 0.081169\n",
            "\n",
            "2020-01-19 19:06:53 start epoch 363/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:06:53 iter 1 loss = 0.082438\n",
            "2020-01-19 19:06:56 iter 25 loss = 0.091885\n",
            "2020-01-19 19:06:59 iter 50 loss = 0.077487\n",
            "2020-01-19 19:07:02 iter 75 loss = 0.084208\n",
            "2020-01-19 19:07:05 iter 100 loss = 0.079834\n",
            "2020-01-19 19:07:05 epoch 363/500 average_loss = 0.080916\n",
            "\n",
            "2020-01-19 19:07:05 start epoch 364/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:07:05 iter 1 loss = 0.078436\n",
            "2020-01-19 19:07:08 iter 25 loss = 0.073269\n",
            "2020-01-19 19:07:11 iter 50 loss = 0.088135\n",
            "2020-01-19 19:07:15 iter 75 loss = 0.071663\n",
            "2020-01-19 19:07:18 iter 100 loss = 0.070214\n",
            "2020-01-19 19:07:18 epoch 364/500 average_loss = 0.082436\n",
            "\n",
            "2020-01-19 19:07:18 start epoch 365/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:07:18 iter 1 loss = 0.073660\n",
            "2020-01-19 19:07:21 iter 25 loss = 0.079127\n",
            "2020-01-19 19:07:24 iter 50 loss = 0.084045\n",
            "2020-01-19 19:07:27 iter 75 loss = 0.082641\n",
            "2020-01-19 19:07:30 iter 100 loss = 0.085679\n",
            "2020-01-19 19:07:30 epoch 365/500 average_loss = 0.081042\n",
            "\n",
            "2020-01-19 19:07:30 start epoch 366/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:07:31 iter 1 loss = 0.075703\n",
            "2020-01-19 19:07:34 iter 25 loss = 0.088860\n",
            "2020-01-19 19:07:37 iter 50 loss = 0.087671\n",
            "2020-01-19 19:07:40 iter 75 loss = 0.081301\n",
            "2020-01-19 19:07:43 iter 100 loss = 0.069463\n",
            "2020-01-19 19:07:43 epoch 366/500 average_loss = 0.081533\n",
            "\n",
            "2020-01-19 19:07:43 start epoch 367/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:07:43 iter 1 loss = 0.075184\n",
            "2020-01-19 19:07:46 iter 25 loss = 0.073919\n",
            "2020-01-19 19:07:49 iter 50 loss = 0.074770\n",
            "2020-01-19 19:07:53 iter 75 loss = 0.082242\n",
            "2020-01-19 19:07:56 iter 100 loss = 0.088988\n",
            "2020-01-19 19:07:56 epoch 367/500 average_loss = 0.080191\n",
            "\n",
            "2020-01-19 19:07:56 start epoch 368/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:07:56 iter 1 loss = 0.078417\n",
            "2020-01-19 19:07:59 iter 25 loss = 0.073110\n",
            "2020-01-19 19:08:02 iter 50 loss = 0.088865\n",
            "2020-01-19 19:08:05 iter 75 loss = 0.075248\n",
            "2020-01-19 19:08:08 iter 100 loss = 0.075634\n",
            "2020-01-19 19:08:08 epoch 368/500 average_loss = 0.080004\n",
            "\n",
            "2020-01-19 19:08:08 start epoch 369/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:08:08 iter 1 loss = 0.066193\n",
            "2020-01-19 19:08:11 iter 25 loss = 0.086019\n",
            "2020-01-19 19:08:15 iter 50 loss = 0.094525\n",
            "2020-01-19 19:08:18 iter 75 loss = 0.076320\n",
            "2020-01-19 19:08:21 iter 100 loss = 0.078537\n",
            "2020-01-19 19:08:21 epoch 369/500 average_loss = 0.080050\n",
            "\n",
            "2020-01-19 19:08:21 start epoch 370/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:08:21 iter 1 loss = 0.066987\n",
            "2020-01-19 19:08:24 iter 25 loss = 0.067356\n",
            "2020-01-19 19:08:27 iter 50 loss = 0.098658\n",
            "2020-01-19 19:08:30 iter 75 loss = 0.097599\n",
            "2020-01-19 19:08:34 iter 100 loss = 0.088129\n",
            "2020-01-19 19:08:34 epoch 370/500 average_loss = 0.080241\n",
            "\n",
            "2020-01-19 19:08:34 start epoch 371/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:08:34 iter 1 loss = 0.067913\n",
            "2020-01-19 19:08:37 iter 25 loss = 0.082444\n",
            "2020-01-19 19:08:40 iter 50 loss = 0.080101\n",
            "2020-01-19 19:08:43 iter 75 loss = 0.082715\n",
            "2020-01-19 19:08:46 iter 100 loss = 0.084979\n",
            "2020-01-19 19:08:46 epoch 371/500 average_loss = 0.079912\n",
            "\n",
            "2020-01-19 19:08:46 start epoch 372/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:08:46 iter 1 loss = 0.079726\n",
            "2020-01-19 19:08:50 iter 25 loss = 0.078681\n",
            "2020-01-19 19:08:53 iter 50 loss = 0.064809\n",
            "2020-01-19 19:08:56 iter 75 loss = 0.078826\n",
            "2020-01-19 19:08:59 iter 100 loss = 0.065519\n",
            "2020-01-19 19:08:59 epoch 372/500 average_loss = 0.080376\n",
            "\n",
            "2020-01-19 19:08:59 start epoch 373/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:08:59 iter 1 loss = 0.076751\n",
            "2020-01-19 19:09:02 iter 25 loss = 0.087632\n",
            "2020-01-19 19:09:05 iter 50 loss = 0.083805\n",
            "2020-01-19 19:09:08 iter 75 loss = 0.088589\n",
            "2020-01-19 19:09:12 iter 100 loss = 0.097734\n",
            "2020-01-19 19:09:12 epoch 373/500 average_loss = 0.081783\n",
            "\n",
            "2020-01-19 19:09:12 start epoch 374/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:09:12 iter 1 loss = 0.077148\n",
            "2020-01-19 19:09:15 iter 25 loss = 0.088509\n",
            "2020-01-19 19:09:18 iter 50 loss = 0.077552\n",
            "2020-01-19 19:09:21 iter 75 loss = 0.073365\n",
            "2020-01-19 19:09:24 iter 100 loss = 0.076045\n",
            "2020-01-19 19:09:24 epoch 374/500 average_loss = 0.080342\n",
            "\n",
            "2020-01-19 19:09:24 start epoch 375/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:09:24 iter 1 loss = 0.072836\n",
            "2020-01-19 19:09:27 iter 25 loss = 0.083582\n",
            "2020-01-19 19:09:31 iter 50 loss = 0.085914\n",
            "2020-01-19 19:09:34 iter 75 loss = 0.076875\n",
            "2020-01-19 19:09:37 iter 100 loss = 0.082850\n",
            "2020-01-19 19:09:37 epoch 375/500 average_loss = 0.081066\n",
            "\n",
            "2020-01-19 19:09:37 start epoch 376/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:09:37 iter 1 loss = 0.082616\n",
            "2020-01-19 19:09:40 iter 25 loss = 0.085474\n",
            "2020-01-19 19:09:43 iter 50 loss = 0.083823\n",
            "2020-01-19 19:09:46 iter 75 loss = 0.082001\n",
            "2020-01-19 19:09:50 iter 100 loss = 0.079034\n",
            "2020-01-19 19:09:50 epoch 376/500 average_loss = 0.079524\n",
            "\n",
            "2020-01-19 19:09:50 start epoch 377/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:09:50 iter 1 loss = 0.091560\n",
            "2020-01-19 19:09:53 iter 25 loss = 0.077672\n",
            "2020-01-19 19:09:56 iter 50 loss = 0.069757\n",
            "2020-01-19 19:09:59 iter 75 loss = 0.081926\n",
            "2020-01-19 19:10:02 iter 100 loss = 0.088310\n",
            "2020-01-19 19:10:02 epoch 377/500 average_loss = 0.079222\n",
            "\n",
            "2020-01-19 19:10:02 start epoch 378/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:10:02 iter 1 loss = 0.103924\n",
            "2020-01-19 19:10:05 iter 25 loss = 0.078264\n",
            "2020-01-19 19:10:08 iter 50 loss = 0.077821\n",
            "2020-01-19 19:10:12 iter 75 loss = 0.083878\n",
            "2020-01-19 19:10:15 iter 100 loss = 0.082641\n",
            "2020-01-19 19:10:15 epoch 378/500 average_loss = 0.079957\n",
            "\n",
            "2020-01-19 19:10:15 start epoch 379/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:10:15 iter 1 loss = 0.067680\n",
            "2020-01-19 19:10:18 iter 25 loss = 0.074650\n",
            "2020-01-19 19:10:21 iter 50 loss = 0.073350\n",
            "2020-01-19 19:10:24 iter 75 loss = 0.080936\n",
            "2020-01-19 19:10:28 iter 100 loss = 0.075549\n",
            "2020-01-19 19:10:28 epoch 379/500 average_loss = 0.079963\n",
            "\n",
            "2020-01-19 19:10:28 start epoch 380/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:10:28 iter 1 loss = 0.081638\n",
            "2020-01-19 19:10:31 iter 25 loss = 0.078688\n",
            "2020-01-19 19:10:34 iter 50 loss = 0.082169\n",
            "2020-01-19 19:10:37 iter 75 loss = 0.073070\n",
            "2020-01-19 19:10:40 iter 100 loss = 0.079132\n",
            "2020-01-19 19:10:40 epoch 380/500 average_loss = 0.079056\n",
            "\n",
            "2020-01-19 19:10:40 start epoch 381/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:10:40 iter 1 loss = 0.094832\n",
            "2020-01-19 19:10:43 iter 25 loss = 0.068667\n",
            "2020-01-19 19:10:46 iter 50 loss = 0.076770\n",
            "2020-01-19 19:10:49 iter 75 loss = 0.089943\n",
            "2020-01-19 19:10:53 iter 100 loss = 0.098582\n",
            "2020-01-19 19:10:53 epoch 381/500 average_loss = 0.078838\n",
            "\n",
            "2020-01-19 19:10:53 start epoch 382/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:10:53 iter 1 loss = 0.082230\n",
            "2020-01-19 19:10:56 iter 25 loss = 0.068172\n",
            "2020-01-19 19:10:59 iter 50 loss = 0.107083\n",
            "2020-01-19 19:11:02 iter 75 loss = 0.068831\n",
            "2020-01-19 19:11:05 iter 100 loss = 0.106364\n",
            "2020-01-19 19:11:05 epoch 382/500 average_loss = 0.080892\n",
            "\n",
            "2020-01-19 19:11:05 start epoch 383/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:11:05 iter 1 loss = 0.073080\n",
            "2020-01-19 19:11:08 iter 25 loss = 0.078690\n",
            "2020-01-19 19:11:12 iter 50 loss = 0.080676\n",
            "2020-01-19 19:11:15 iter 75 loss = 0.091539\n",
            "2020-01-19 19:11:18 iter 100 loss = 0.094418\n",
            "2020-01-19 19:11:18 epoch 383/500 average_loss = 0.081321\n",
            "\n",
            "2020-01-19 19:11:18 start epoch 384/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:11:18 iter 1 loss = 0.074687\n",
            "2020-01-19 19:11:21 iter 25 loss = 0.073248\n",
            "2020-01-19 19:11:24 iter 50 loss = 0.082002\n",
            "2020-01-19 19:11:27 iter 75 loss = 0.079535\n",
            "2020-01-19 19:11:31 iter 100 loss = 0.071086\n",
            "2020-01-19 19:11:31 epoch 384/500 average_loss = 0.079597\n",
            "\n",
            "2020-01-19 19:11:31 start epoch 385/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:11:31 iter 1 loss = 0.066807\n",
            "2020-01-19 19:11:34 iter 25 loss = 0.078219\n",
            "2020-01-19 19:11:37 iter 50 loss = 0.065449\n",
            "2020-01-19 19:11:40 iter 75 loss = 0.068716\n",
            "2020-01-19 19:11:43 iter 100 loss = 0.070074\n",
            "2020-01-19 19:11:43 epoch 385/500 average_loss = 0.080531\n",
            "\n",
            "2020-01-19 19:11:43 start epoch 386/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:11:43 iter 1 loss = 0.070004\n",
            "2020-01-19 19:11:46 iter 25 loss = 0.101041\n",
            "2020-01-19 19:11:50 iter 50 loss = 0.074578\n",
            "2020-01-19 19:11:53 iter 75 loss = 0.062439\n",
            "2020-01-19 19:11:56 iter 100 loss = 0.079341\n",
            "2020-01-19 19:11:56 epoch 386/500 average_loss = 0.079945\n",
            "\n",
            "2020-01-19 19:11:56 start epoch 387/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:11:56 iter 1 loss = 0.084723\n",
            "2020-01-19 19:11:59 iter 25 loss = 0.075975\n",
            "2020-01-19 19:12:02 iter 50 loss = 0.072854\n",
            "2020-01-19 19:12:05 iter 75 loss = 0.096842\n",
            "2020-01-19 19:12:08 iter 100 loss = 0.067176\n",
            "2020-01-19 19:12:08 epoch 387/500 average_loss = 0.079877\n",
            "\n",
            "2020-01-19 19:12:08 start epoch 388/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:12:09 iter 1 loss = 0.076862\n",
            "2020-01-19 19:12:12 iter 25 loss = 0.069597\n",
            "2020-01-19 19:12:15 iter 50 loss = 0.070743\n",
            "2020-01-19 19:12:18 iter 75 loss = 0.081890\n",
            "2020-01-19 19:12:21 iter 100 loss = 0.106249\n",
            "2020-01-19 19:12:21 epoch 388/500 average_loss = 0.079599\n",
            "\n",
            "2020-01-19 19:12:21 start epoch 389/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:12:21 iter 1 loss = 0.069058\n",
            "2020-01-19 19:12:24 iter 25 loss = 0.062392\n",
            "2020-01-19 19:12:27 iter 50 loss = 0.090514\n",
            "2020-01-19 19:12:31 iter 75 loss = 0.080652\n",
            "2020-01-19 19:12:34 iter 100 loss = 0.078372\n",
            "2020-01-19 19:12:34 epoch 389/500 average_loss = 0.079774\n",
            "\n",
            "2020-01-19 19:12:34 start epoch 390/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:12:34 iter 1 loss = 0.072653\n",
            "2020-01-19 19:12:37 iter 25 loss = 0.069898\n",
            "2020-01-19 19:12:40 iter 50 loss = 0.059840\n",
            "2020-01-19 19:12:43 iter 75 loss = 0.074542\n",
            "2020-01-19 19:12:46 iter 100 loss = 0.093828\n",
            "2020-01-19 19:12:46 epoch 390/500 average_loss = 0.078661\n",
            "\n",
            "2020-01-19 19:12:46 start epoch 391/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:12:46 iter 1 loss = 0.078097\n",
            "2020-01-19 19:12:49 iter 25 loss = 0.073104\n",
            "2020-01-19 19:12:53 iter 50 loss = 0.084140\n",
            "2020-01-19 19:12:56 iter 75 loss = 0.075561\n",
            "2020-01-19 19:12:59 iter 100 loss = 0.078540\n",
            "2020-01-19 19:12:59 epoch 391/500 average_loss = 0.081167\n",
            "\n",
            "2020-01-19 19:12:59 start epoch 392/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:12:59 iter 1 loss = 0.074749\n",
            "2020-01-19 19:13:02 iter 25 loss = 0.104029\n",
            "2020-01-19 19:13:05 iter 50 loss = 0.091018\n",
            "2020-01-19 19:13:08 iter 75 loss = 0.072004\n",
            "2020-01-19 19:13:12 iter 100 loss = 0.096051\n",
            "2020-01-19 19:13:12 epoch 392/500 average_loss = 0.081775\n",
            "\n",
            "2020-01-19 19:13:12 start epoch 393/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:13:12 iter 1 loss = 0.082071\n",
            "2020-01-19 19:13:15 iter 25 loss = 0.072168\n",
            "2020-01-19 19:13:18 iter 50 loss = 0.068342\n",
            "2020-01-19 19:13:21 iter 75 loss = 0.068286\n",
            "2020-01-19 19:13:24 iter 100 loss = 0.073728\n",
            "2020-01-19 19:13:24 epoch 393/500 average_loss = 0.079772\n",
            "\n",
            "2020-01-19 19:13:24 start epoch 394/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:13:24 iter 1 loss = 0.068544\n",
            "2020-01-19 19:13:28 iter 25 loss = 0.080403\n",
            "2020-01-19 19:13:31 iter 50 loss = 0.082087\n",
            "2020-01-19 19:13:34 iter 75 loss = 0.088264\n",
            "2020-01-19 19:13:37 iter 100 loss = 0.087581\n",
            "2020-01-19 19:13:37 epoch 394/500 average_loss = 0.079555\n",
            "\n",
            "2020-01-19 19:13:37 start epoch 395/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:13:37 iter 1 loss = 0.080854\n",
            "2020-01-19 19:13:40 iter 25 loss = 0.088936\n",
            "2020-01-19 19:13:43 iter 50 loss = 0.073217\n",
            "2020-01-19 19:13:46 iter 75 loss = 0.069516\n",
            "2020-01-19 19:13:50 iter 100 loss = 0.085284\n",
            "2020-01-19 19:13:50 epoch 395/500 average_loss = 0.080141\n",
            "\n",
            "2020-01-19 19:13:50 start epoch 396/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:13:50 iter 1 loss = 0.073797\n",
            "2020-01-19 19:13:53 iter 25 loss = 0.078392\n",
            "2020-01-19 19:13:56 iter 50 loss = 0.078009\n",
            "2020-01-19 19:13:59 iter 75 loss = 0.078304\n",
            "2020-01-19 19:14:02 iter 100 loss = 0.076653\n",
            "2020-01-19 19:14:02 epoch 396/500 average_loss = 0.079343\n",
            "\n",
            "2020-01-19 19:14:02 start epoch 397/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:14:02 iter 1 loss = 0.072332\n",
            "2020-01-19 19:14:05 iter 25 loss = 0.102990\n",
            "2020-01-19 19:14:09 iter 50 loss = 0.078190\n",
            "2020-01-19 19:14:12 iter 75 loss = 0.086358\n",
            "2020-01-19 19:14:15 iter 100 loss = 0.091723\n",
            "2020-01-19 19:14:15 epoch 397/500 average_loss = 0.078535\n",
            "\n",
            "2020-01-19 19:14:15 start epoch 398/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:14:15 iter 1 loss = 0.087168\n",
            "2020-01-19 19:14:18 iter 25 loss = 0.068890\n",
            "2020-01-19 19:14:21 iter 50 loss = 0.073229\n",
            "2020-01-19 19:14:25 iter 75 loss = 0.079007\n",
            "2020-01-19 19:14:28 iter 100 loss = 0.088675\n",
            "2020-01-19 19:14:28 epoch 398/500 average_loss = 0.079268\n",
            "\n",
            "2020-01-19 19:14:28 start epoch 399/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:14:28 iter 1 loss = 0.084032\n",
            "2020-01-19 19:14:31 iter 25 loss = 0.074482\n",
            "2020-01-19 19:14:34 iter 50 loss = 0.080542\n",
            "2020-01-19 19:14:37 iter 75 loss = 0.075933\n",
            "2020-01-19 19:14:40 iter 100 loss = 0.069490\n",
            "2020-01-19 19:14:40 epoch 399/500 average_loss = 0.079394\n",
            "\n",
            "2020-01-19 19:14:40 start epoch 400/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:14:41 iter 1 loss = 0.084029\n",
            "2020-01-19 19:14:44 iter 25 loss = 0.083725\n",
            "2020-01-19 19:14:47 iter 50 loss = 0.066253\n",
            "2020-01-19 19:14:50 iter 75 loss = 0.076274\n",
            "2020-01-19 19:14:53 iter 100 loss = 0.076480\n",
            "2020-01-19 19:14:53 epoch 400/500 average_loss = 0.079862\n",
            "\n",
            "2020-01-19 19:14:53 start epoch 401/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:14:53 iter 1 loss = 0.078600\n",
            "2020-01-19 19:14:56 iter 25 loss = 0.070620\n",
            "2020-01-19 19:14:59 iter 50 loss = 0.075829\n",
            "2020-01-19 19:15:02 iter 75 loss = 0.072603\n",
            "2020-01-19 19:15:06 iter 100 loss = 0.078905\n",
            "2020-01-19 19:15:06 epoch 401/500 average_loss = 0.078019\n",
            "\n",
            "2020-01-19 19:15:06 start epoch 402/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:15:06 iter 1 loss = 0.072381\n",
            "2020-01-19 19:15:09 iter 25 loss = 0.082139\n",
            "2020-01-19 19:15:12 iter 50 loss = 0.056240\n",
            "2020-01-19 19:15:15 iter 75 loss = 0.074209\n",
            "2020-01-19 19:15:18 iter 100 loss = 0.082338\n",
            "2020-01-19 19:15:18 epoch 402/500 average_loss = 0.078767\n",
            "\n",
            "2020-01-19 19:15:18 start epoch 403/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:15:18 iter 1 loss = 0.087505\n",
            "2020-01-19 19:15:21 iter 25 loss = 0.075722\n",
            "2020-01-19 19:15:25 iter 50 loss = 0.088408\n",
            "2020-01-19 19:15:28 iter 75 loss = 0.073396\n",
            "2020-01-19 19:15:31 iter 100 loss = 0.074207\n",
            "2020-01-19 19:15:31 epoch 403/500 average_loss = 0.078721\n",
            "\n",
            "2020-01-19 19:15:31 start epoch 404/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:15:31 iter 1 loss = 0.064376\n",
            "2020-01-19 19:15:34 iter 25 loss = 0.069504\n",
            "2020-01-19 19:15:37 iter 50 loss = 0.093197\n",
            "2020-01-19 19:15:40 iter 75 loss = 0.082869\n",
            "2020-01-19 19:15:44 iter 100 loss = 0.070369\n",
            "2020-01-19 19:15:44 epoch 404/500 average_loss = 0.080125\n",
            "\n",
            "2020-01-19 19:15:44 start epoch 405/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:15:44 iter 1 loss = 0.089420\n",
            "2020-01-19 19:15:47 iter 25 loss = 0.074990\n",
            "2020-01-19 19:15:50 iter 50 loss = 0.080096\n",
            "2020-01-19 19:15:53 iter 75 loss = 0.062947\n",
            "2020-01-19 19:15:56 iter 100 loss = 0.094108\n",
            "2020-01-19 19:15:56 epoch 405/500 average_loss = 0.078883\n",
            "\n",
            "2020-01-19 19:15:56 start epoch 406/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:15:56 iter 1 loss = 0.067289\n",
            "2020-01-19 19:15:59 iter 25 loss = 0.082474\n",
            "2020-01-19 19:16:02 iter 50 loss = 0.076754\n",
            "2020-01-19 19:16:06 iter 75 loss = 0.072023\n",
            "2020-01-19 19:16:09 iter 100 loss = 0.084420\n",
            "2020-01-19 19:16:09 epoch 406/500 average_loss = 0.078628\n",
            "\n",
            "2020-01-19 19:16:09 start epoch 407/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:16:09 iter 1 loss = 0.095653\n",
            "2020-01-19 19:16:12 iter 25 loss = 0.081113\n",
            "2020-01-19 19:16:15 iter 50 loss = 0.078618\n",
            "2020-01-19 19:16:18 iter 75 loss = 0.070799\n",
            "2020-01-19 19:16:22 iter 100 loss = 0.079497\n",
            "2020-01-19 19:16:22 epoch 407/500 average_loss = 0.079920\n",
            "\n",
            "2020-01-19 19:16:22 start epoch 408/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:16:22 iter 1 loss = 0.064895\n",
            "2020-01-19 19:16:25 iter 25 loss = 0.082156\n",
            "2020-01-19 19:16:28 iter 50 loss = 0.070651\n",
            "2020-01-19 19:16:31 iter 75 loss = 0.104048\n",
            "2020-01-19 19:16:34 iter 100 loss = 0.081511\n",
            "2020-01-19 19:16:34 epoch 408/500 average_loss = 0.078051\n",
            "\n",
            "2020-01-19 19:16:34 start epoch 409/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:16:34 iter 1 loss = 0.070595\n",
            "2020-01-19 19:16:37 iter 25 loss = 0.074897\n",
            "2020-01-19 19:16:40 iter 50 loss = 0.073838\n",
            "2020-01-19 19:16:43 iter 75 loss = 0.088788\n",
            "2020-01-19 19:16:47 iter 100 loss = 0.075946\n",
            "2020-01-19 19:16:47 epoch 409/500 average_loss = 0.078713\n",
            "\n",
            "2020-01-19 19:16:47 start epoch 410/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:16:47 iter 1 loss = 0.068097\n",
            "2020-01-19 19:16:50 iter 25 loss = 0.074368\n",
            "2020-01-19 19:16:53 iter 50 loss = 0.080793\n",
            "2020-01-19 19:16:56 iter 75 loss = 0.073831\n",
            "2020-01-19 19:16:59 iter 100 loss = 0.060619\n",
            "2020-01-19 19:16:59 epoch 410/500 average_loss = 0.077089\n",
            "\n",
            "2020-01-19 19:16:59 start epoch 411/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:16:59 iter 1 loss = 0.069597\n",
            "2020-01-19 19:17:02 iter 25 loss = 0.063364\n",
            "2020-01-19 19:17:06 iter 50 loss = 0.089287\n",
            "2020-01-19 19:17:09 iter 75 loss = 0.101291\n",
            "2020-01-19 19:17:12 iter 100 loss = 0.094107\n",
            "2020-01-19 19:17:12 epoch 411/500 average_loss = 0.078018\n",
            "\n",
            "2020-01-19 19:17:12 start epoch 412/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:17:12 iter 1 loss = 0.086057\n",
            "2020-01-19 19:17:15 iter 25 loss = 0.087059\n",
            "2020-01-19 19:17:18 iter 50 loss = 0.095960\n",
            "2020-01-19 19:17:22 iter 75 loss = 0.077877\n",
            "2020-01-19 19:17:25 iter 100 loss = 0.085745\n",
            "2020-01-19 19:17:25 epoch 412/500 average_loss = 0.079949\n",
            "\n",
            "2020-01-19 19:17:25 start epoch 413/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:17:25 iter 1 loss = 0.075011\n",
            "2020-01-19 19:17:28 iter 25 loss = 0.073389\n",
            "2020-01-19 19:17:31 iter 50 loss = 0.065390\n",
            "2020-01-19 19:17:34 iter 75 loss = 0.074941\n",
            "2020-01-19 19:17:37 iter 100 loss = 0.077735\n",
            "2020-01-19 19:17:37 epoch 413/500 average_loss = 0.079099\n",
            "\n",
            "2020-01-19 19:17:37 start epoch 414/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:17:37 iter 1 loss = 0.069544\n",
            "2020-01-19 19:17:40 iter 25 loss = 0.059165\n",
            "2020-01-19 19:17:44 iter 50 loss = 0.084779\n",
            "2020-01-19 19:17:47 iter 75 loss = 0.061065\n",
            "2020-01-19 19:17:50 iter 100 loss = 0.099023\n",
            "2020-01-19 19:17:50 epoch 414/500 average_loss = 0.078632\n",
            "\n",
            "2020-01-19 19:17:50 start epoch 415/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:17:50 iter 1 loss = 0.066599\n",
            "2020-01-19 19:17:53 iter 25 loss = 0.082323\n",
            "2020-01-19 19:17:56 iter 50 loss = 0.081393\n",
            "2020-01-19 19:17:59 iter 75 loss = 0.083812\n",
            "2020-01-19 19:18:02 iter 100 loss = 0.082958\n",
            "2020-01-19 19:18:02 epoch 415/500 average_loss = 0.078726\n",
            "\n",
            "2020-01-19 19:18:02 start epoch 416/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:18:03 iter 1 loss = 0.085274\n",
            "2020-01-19 19:18:06 iter 25 loss = 0.072555\n",
            "2020-01-19 19:18:09 iter 50 loss = 0.088229\n",
            "2020-01-19 19:18:12 iter 75 loss = 0.075593\n",
            "2020-01-19 19:18:15 iter 100 loss = 0.069100\n",
            "2020-01-19 19:18:15 epoch 416/500 average_loss = 0.077913\n",
            "\n",
            "2020-01-19 19:18:15 start epoch 417/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:18:15 iter 1 loss = 0.092843\n",
            "2020-01-19 19:18:18 iter 25 loss = 0.077738\n",
            "2020-01-19 19:18:22 iter 50 loss = 0.071506\n",
            "2020-01-19 19:18:25 iter 75 loss = 0.092411\n",
            "2020-01-19 19:18:28 iter 100 loss = 0.086317\n",
            "2020-01-19 19:18:28 epoch 417/500 average_loss = 0.077042\n",
            "\n",
            "2020-01-19 19:18:28 start epoch 418/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:18:28 iter 1 loss = 0.087007\n",
            "2020-01-19 19:18:31 iter 25 loss = 0.083609\n",
            "2020-01-19 19:18:34 iter 50 loss = 0.077624\n",
            "2020-01-19 19:18:37 iter 75 loss = 0.080117\n",
            "2020-01-19 19:18:40 iter 100 loss = 0.081741\n",
            "2020-01-19 19:18:40 epoch 418/500 average_loss = 0.078316\n",
            "\n",
            "2020-01-19 19:18:40 start epoch 419/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:18:41 iter 1 loss = 0.052726\n",
            "2020-01-19 19:18:44 iter 25 loss = 0.088940\n",
            "2020-01-19 19:18:47 iter 50 loss = 0.091627\n",
            "2020-01-19 19:18:50 iter 75 loss = 0.072125\n",
            "2020-01-19 19:18:53 iter 100 loss = 0.082029\n",
            "2020-01-19 19:18:53 epoch 419/500 average_loss = 0.077835\n",
            "\n",
            "2020-01-19 19:18:53 start epoch 420/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:18:53 iter 1 loss = 0.074495\n",
            "2020-01-19 19:18:56 iter 25 loss = 0.075221\n",
            "2020-01-19 19:18:59 iter 50 loss = 0.073391\n",
            "2020-01-19 19:19:03 iter 75 loss = 0.073376\n",
            "2020-01-19 19:19:06 iter 100 loss = 0.076615\n",
            "2020-01-19 19:19:06 epoch 420/500 average_loss = 0.077966\n",
            "\n",
            "2020-01-19 19:19:06 start epoch 421/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:19:06 iter 1 loss = 0.073502\n",
            "2020-01-19 19:19:09 iter 25 loss = 0.092747\n",
            "2020-01-19 19:19:12 iter 50 loss = 0.073900\n",
            "2020-01-19 19:19:15 iter 75 loss = 0.072567\n",
            "2020-01-19 19:19:18 iter 100 loss = 0.081115\n",
            "2020-01-19 19:19:18 epoch 421/500 average_loss = 0.078184\n",
            "\n",
            "2020-01-19 19:19:18 start epoch 422/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:19:19 iter 1 loss = 0.065909\n",
            "2020-01-19 19:19:22 iter 25 loss = 0.065482\n",
            "2020-01-19 19:19:25 iter 50 loss = 0.078212\n",
            "2020-01-19 19:19:28 iter 75 loss = 0.074208\n",
            "2020-01-19 19:19:31 iter 100 loss = 0.068134\n",
            "2020-01-19 19:19:31 epoch 422/500 average_loss = 0.078750\n",
            "\n",
            "2020-01-19 19:19:31 start epoch 423/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:19:31 iter 1 loss = 0.075710\n",
            "2020-01-19 19:19:34 iter 25 loss = 0.081691\n",
            "2020-01-19 19:19:37 iter 50 loss = 0.088897\n",
            "2020-01-19 19:19:41 iter 75 loss = 0.077524\n",
            "2020-01-19 19:19:44 iter 100 loss = 0.097530\n",
            "2020-01-19 19:19:44 epoch 423/500 average_loss = 0.079029\n",
            "\n",
            "2020-01-19 19:19:44 start epoch 424/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:19:44 iter 1 loss = 0.085114\n",
            "2020-01-19 19:19:47 iter 25 loss = 0.078475\n",
            "2020-01-19 19:19:50 iter 50 loss = 0.074571\n",
            "2020-01-19 19:19:53 iter 75 loss = 0.074107\n",
            "2020-01-19 19:19:56 iter 100 loss = 0.060914\n",
            "2020-01-19 19:19:56 epoch 424/500 average_loss = 0.078610\n",
            "\n",
            "2020-01-19 19:19:56 start epoch 425/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:19:56 iter 1 loss = 0.060137\n",
            "2020-01-19 19:19:59 iter 25 loss = 0.072408\n",
            "2020-01-19 19:20:03 iter 50 loss = 0.079071\n",
            "2020-01-19 19:20:06 iter 75 loss = 0.075683\n",
            "2020-01-19 19:20:09 iter 100 loss = 0.088207\n",
            "2020-01-19 19:20:09 epoch 425/500 average_loss = 0.077563\n",
            "\n",
            "2020-01-19 19:20:09 start epoch 426/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:20:09 iter 1 loss = 0.084193\n",
            "2020-01-19 19:20:12 iter 25 loss = 0.085314\n",
            "2020-01-19 19:20:15 iter 50 loss = 0.080117\n",
            "2020-01-19 19:20:19 iter 75 loss = 0.109622\n",
            "2020-01-19 19:20:22 iter 100 loss = 0.086735\n",
            "2020-01-19 19:20:22 epoch 426/500 average_loss = 0.079038\n",
            "\n",
            "2020-01-19 19:20:22 start epoch 427/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:20:22 iter 1 loss = 0.088089\n",
            "2020-01-19 19:20:25 iter 25 loss = 0.076423\n",
            "2020-01-19 19:20:28 iter 50 loss = 0.111184\n",
            "2020-01-19 19:20:31 iter 75 loss = 0.080303\n",
            "2020-01-19 19:20:34 iter 100 loss = 0.069239\n",
            "2020-01-19 19:20:34 epoch 427/500 average_loss = 0.077856\n",
            "\n",
            "2020-01-19 19:20:34 start epoch 428/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:20:34 iter 1 loss = 0.076594\n",
            "2020-01-19 19:20:37 iter 25 loss = 0.094591\n",
            "2020-01-19 19:20:40 iter 50 loss = 0.082843\n",
            "2020-01-19 19:20:44 iter 75 loss = 0.099053\n",
            "2020-01-19 19:20:47 iter 100 loss = 0.072342\n",
            "2020-01-19 19:20:47 epoch 428/500 average_loss = 0.078624\n",
            "\n",
            "2020-01-19 19:20:47 start epoch 429/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:20:47 iter 1 loss = 0.074728\n",
            "2020-01-19 19:20:50 iter 25 loss = 0.073190\n",
            "2020-01-19 19:20:53 iter 50 loss = 0.075165\n",
            "2020-01-19 19:20:56 iter 75 loss = 0.074728\n",
            "2020-01-19 19:20:59 iter 100 loss = 0.080187\n",
            "2020-01-19 19:20:59 epoch 429/500 average_loss = 0.077710\n",
            "\n",
            "2020-01-19 19:20:59 start epoch 430/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:21:00 iter 1 loss = 0.076219\n",
            "2020-01-19 19:21:03 iter 25 loss = 0.069180\n",
            "2020-01-19 19:21:06 iter 50 loss = 0.066819\n",
            "2020-01-19 19:21:09 iter 75 loss = 0.070885\n",
            "2020-01-19 19:21:12 iter 100 loss = 0.101390\n",
            "2020-01-19 19:21:12 epoch 430/500 average_loss = 0.080381\n",
            "\n",
            "2020-01-19 19:21:12 start epoch 431/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:21:12 iter 1 loss = 0.077485\n",
            "2020-01-19 19:21:15 iter 25 loss = 0.074648\n",
            "2020-01-19 19:21:18 iter 50 loss = 0.092327\n",
            "2020-01-19 19:21:22 iter 75 loss = 0.072494\n",
            "2020-01-19 19:21:25 iter 100 loss = 0.097253\n",
            "2020-01-19 19:21:25 epoch 431/500 average_loss = 0.078497\n",
            "\n",
            "2020-01-19 19:21:25 start epoch 432/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:21:25 iter 1 loss = 0.079029\n",
            "2020-01-19 19:21:28 iter 25 loss = 0.074716\n",
            "2020-01-19 19:21:31 iter 50 loss = 0.086011\n",
            "2020-01-19 19:21:34 iter 75 loss = 0.071199\n",
            "2020-01-19 19:21:37 iter 100 loss = 0.081936\n",
            "2020-01-19 19:21:37 epoch 432/500 average_loss = 0.077209\n",
            "\n",
            "2020-01-19 19:21:37 start epoch 433/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:21:37 iter 1 loss = 0.082098\n",
            "2020-01-19 19:21:40 iter 25 loss = 0.080556\n",
            "2020-01-19 19:21:44 iter 50 loss = 0.075741\n",
            "2020-01-19 19:21:47 iter 75 loss = 0.068059\n",
            "2020-01-19 19:21:50 iter 100 loss = 0.072588\n",
            "2020-01-19 19:21:50 epoch 433/500 average_loss = 0.076374\n",
            "\n",
            "2020-01-19 19:21:50 start epoch 434/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:21:50 iter 1 loss = 0.074986\n",
            "2020-01-19 19:21:53 iter 25 loss = 0.075925\n",
            "2020-01-19 19:21:56 iter 50 loss = 0.069709\n",
            "2020-01-19 19:21:59 iter 75 loss = 0.069873\n",
            "2020-01-19 19:22:03 iter 100 loss = 0.070546\n",
            "2020-01-19 19:22:03 epoch 434/500 average_loss = 0.076330\n",
            "\n",
            "2020-01-19 19:22:03 start epoch 435/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:22:03 iter 1 loss = 0.087458\n",
            "2020-01-19 19:22:06 iter 25 loss = 0.078431\n",
            "2020-01-19 19:22:09 iter 50 loss = 0.085982\n",
            "2020-01-19 19:22:12 iter 75 loss = 0.072975\n",
            "2020-01-19 19:22:15 iter 100 loss = 0.088444\n",
            "2020-01-19 19:22:15 epoch 435/500 average_loss = 0.077817\n",
            "\n",
            "2020-01-19 19:22:15 start epoch 436/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:22:15 iter 1 loss = 0.073202\n",
            "2020-01-19 19:22:18 iter 25 loss = 0.073180\n",
            "2020-01-19 19:22:22 iter 50 loss = 0.068623\n",
            "2020-01-19 19:22:25 iter 75 loss = 0.056906\n",
            "2020-01-19 19:22:28 iter 100 loss = 0.079036\n",
            "2020-01-19 19:22:28 epoch 436/500 average_loss = 0.077099\n",
            "\n",
            "2020-01-19 19:22:28 start epoch 437/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:22:28 iter 1 loss = 0.079509\n",
            "2020-01-19 19:22:31 iter 25 loss = 0.076096\n",
            "2020-01-19 19:22:34 iter 50 loss = 0.077698\n",
            "2020-01-19 19:22:37 iter 75 loss = 0.075093\n",
            "2020-01-19 19:22:41 iter 100 loss = 0.069377\n",
            "2020-01-19 19:22:41 epoch 437/500 average_loss = 0.078524\n",
            "\n",
            "2020-01-19 19:22:41 start epoch 438/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:22:41 iter 1 loss = 0.072594\n",
            "2020-01-19 19:22:44 iter 25 loss = 0.086142\n",
            "2020-01-19 19:22:47 iter 50 loss = 0.071253\n",
            "2020-01-19 19:22:50 iter 75 loss = 0.072697\n",
            "2020-01-19 19:22:53 iter 100 loss = 0.073829\n",
            "2020-01-19 19:22:53 epoch 438/500 average_loss = 0.077182\n",
            "\n",
            "2020-01-19 19:22:53 start epoch 439/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:22:53 iter 1 loss = 0.077857\n",
            "2020-01-19 19:22:56 iter 25 loss = 0.072351\n",
            "2020-01-19 19:23:00 iter 50 loss = 0.075812\n",
            "2020-01-19 19:23:03 iter 75 loss = 0.083678\n",
            "2020-01-19 19:23:06 iter 100 loss = 0.075163\n",
            "2020-01-19 19:23:06 epoch 439/500 average_loss = 0.077567\n",
            "\n",
            "2020-01-19 19:23:06 start epoch 440/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:23:06 iter 1 loss = 0.083498\n",
            "2020-01-19 19:23:09 iter 25 loss = 0.085161\n",
            "2020-01-19 19:23:12 iter 50 loss = 0.083686\n",
            "2020-01-19 19:23:15 iter 75 loss = 0.076106\n",
            "2020-01-19 19:23:19 iter 100 loss = 0.098954\n",
            "2020-01-19 19:23:19 epoch 440/500 average_loss = 0.077900\n",
            "\n",
            "2020-01-19 19:23:19 start epoch 441/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:23:19 iter 1 loss = 0.075222\n",
            "2020-01-19 19:23:22 iter 25 loss = 0.071844\n",
            "2020-01-19 19:23:25 iter 50 loss = 0.061251\n",
            "2020-01-19 19:23:28 iter 75 loss = 0.085563\n",
            "2020-01-19 19:23:31 iter 100 loss = 0.073183\n",
            "2020-01-19 19:23:31 epoch 441/500 average_loss = 0.077738\n",
            "\n",
            "2020-01-19 19:23:31 start epoch 442/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:23:31 iter 1 loss = 0.082189\n",
            "2020-01-19 19:23:34 iter 25 loss = 0.077653\n",
            "2020-01-19 19:23:37 iter 50 loss = 0.082659\n",
            "2020-01-19 19:23:41 iter 75 loss = 0.070815\n",
            "2020-01-19 19:23:44 iter 100 loss = 0.070340\n",
            "2020-01-19 19:23:44 epoch 442/500 average_loss = 0.079245\n",
            "\n",
            "2020-01-19 19:23:44 start epoch 443/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:23:44 iter 1 loss = 0.080397\n",
            "2020-01-19 19:23:47 iter 25 loss = 0.089832\n",
            "2020-01-19 19:23:50 iter 50 loss = 0.081399\n",
            "2020-01-19 19:23:53 iter 75 loss = 0.076334\n",
            "2020-01-19 19:23:56 iter 100 loss = 0.072064\n",
            "2020-01-19 19:23:56 epoch 443/500 average_loss = 0.078091\n",
            "\n",
            "2020-01-19 19:23:56 start epoch 444/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:23:57 iter 1 loss = 0.078789\n",
            "2020-01-19 19:24:00 iter 25 loss = 0.083101\n",
            "2020-01-19 19:24:03 iter 50 loss = 0.072269\n",
            "2020-01-19 19:24:06 iter 75 loss = 0.075515\n",
            "2020-01-19 19:24:09 iter 100 loss = 0.072618\n",
            "2020-01-19 19:24:09 epoch 444/500 average_loss = 0.078043\n",
            "\n",
            "2020-01-19 19:24:09 start epoch 445/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:24:09 iter 1 loss = 0.073615\n",
            "2020-01-19 19:24:12 iter 25 loss = 0.076351\n",
            "2020-01-19 19:24:16 iter 50 loss = 0.071954\n",
            "2020-01-19 19:24:19 iter 75 loss = 0.071817\n",
            "2020-01-19 19:24:22 iter 100 loss = 0.068856\n",
            "2020-01-19 19:24:22 epoch 445/500 average_loss = 0.077106\n",
            "\n",
            "2020-01-19 19:24:22 start epoch 446/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:24:22 iter 1 loss = 0.069260\n",
            "2020-01-19 19:24:25 iter 25 loss = 0.065048\n",
            "2020-01-19 19:24:28 iter 50 loss = 0.075341\n",
            "2020-01-19 19:24:31 iter 75 loss = 0.081547\n",
            "2020-01-19 19:24:35 iter 100 loss = 0.063144\n",
            "2020-01-19 19:24:35 epoch 446/500 average_loss = 0.077006\n",
            "\n",
            "2020-01-19 19:24:35 start epoch 447/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:24:35 iter 1 loss = 0.074509\n",
            "2020-01-19 19:24:38 iter 25 loss = 0.085111\n",
            "2020-01-19 19:24:41 iter 50 loss = 0.084727\n",
            "2020-01-19 19:24:44 iter 75 loss = 0.070299\n",
            "2020-01-19 19:24:47 iter 100 loss = 0.074487\n",
            "2020-01-19 19:24:47 epoch 447/500 average_loss = 0.076701\n",
            "\n",
            "2020-01-19 19:24:47 start epoch 448/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:24:47 iter 1 loss = 0.073976\n",
            "2020-01-19 19:24:50 iter 25 loss = 0.080571\n",
            "2020-01-19 19:24:53 iter 50 loss = 0.067576\n",
            "2020-01-19 19:24:57 iter 75 loss = 0.071764\n",
            "2020-01-19 19:25:00 iter 100 loss = 0.076479\n",
            "2020-01-19 19:25:00 epoch 448/500 average_loss = 0.076135\n",
            "\n",
            "2020-01-19 19:25:00 start epoch 449/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:25:00 iter 1 loss = 0.077422\n",
            "2020-01-19 19:25:03 iter 25 loss = 0.075925\n",
            "2020-01-19 19:25:06 iter 50 loss = 0.077298\n",
            "2020-01-19 19:25:09 iter 75 loss = 0.080671\n",
            "2020-01-19 19:25:12 iter 100 loss = 0.076664\n",
            "2020-01-19 19:25:12 epoch 449/500 average_loss = 0.075909\n",
            "\n",
            "2020-01-19 19:25:12 start epoch 450/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:25:13 iter 1 loss = 0.078263\n",
            "2020-01-19 19:25:16 iter 25 loss = 0.078772\n",
            "2020-01-19 19:25:19 iter 50 loss = 0.082867\n",
            "2020-01-19 19:25:22 iter 75 loss = 0.076405\n",
            "2020-01-19 19:25:25 iter 100 loss = 0.062799\n",
            "2020-01-19 19:25:25 epoch 450/500 average_loss = 0.077885\n",
            "\n",
            "2020-01-19 19:25:25 start epoch 451/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:25:25 iter 1 loss = 0.092687\n",
            "2020-01-19 19:25:28 iter 25 loss = 0.079369\n",
            "2020-01-19 19:25:31 iter 50 loss = 0.084530\n",
            "2020-01-19 19:25:34 iter 75 loss = 0.071613\n",
            "2020-01-19 19:25:38 iter 100 loss = 0.069604\n",
            "2020-01-19 19:25:38 epoch 451/500 average_loss = 0.075944\n",
            "\n",
            "2020-01-19 19:25:38 start epoch 452/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:25:38 iter 1 loss = 0.084563\n",
            "2020-01-19 19:25:41 iter 25 loss = 0.077800\n",
            "2020-01-19 19:25:44 iter 50 loss = 0.075113\n",
            "2020-01-19 19:25:47 iter 75 loss = 0.083594\n",
            "2020-01-19 19:25:50 iter 100 loss = 0.086461\n",
            "2020-01-19 19:25:50 epoch 452/500 average_loss = 0.077072\n",
            "\n",
            "2020-01-19 19:25:50 start epoch 453/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:25:50 iter 1 loss = 0.069901\n",
            "2020-01-19 19:25:53 iter 25 loss = 0.068821\n",
            "2020-01-19 19:25:57 iter 50 loss = 0.084541\n",
            "2020-01-19 19:26:00 iter 75 loss = 0.151430\n",
            "2020-01-19 19:26:03 iter 100 loss = 0.067438\n",
            "2020-01-19 19:26:03 epoch 453/500 average_loss = 0.078213\n",
            "\n",
            "2020-01-19 19:26:03 start epoch 454/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:26:03 iter 1 loss = 0.081112\n",
            "2020-01-19 19:26:06 iter 25 loss = 0.069031\n",
            "2020-01-19 19:26:09 iter 50 loss = 0.085514\n",
            "2020-01-19 19:26:12 iter 75 loss = 0.069147\n",
            "2020-01-19 19:26:15 iter 100 loss = 0.064701\n",
            "2020-01-19 19:26:15 epoch 454/500 average_loss = 0.076965\n",
            "\n",
            "2020-01-19 19:26:15 start epoch 455/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:26:16 iter 1 loss = 0.069329\n",
            "2020-01-19 19:26:19 iter 25 loss = 0.077224\n",
            "2020-01-19 19:26:22 iter 50 loss = 0.084672\n",
            "2020-01-19 19:26:25 iter 75 loss = 0.069133\n",
            "2020-01-19 19:26:28 iter 100 loss = 0.075008\n",
            "2020-01-19 19:26:28 epoch 455/500 average_loss = 0.076896\n",
            "\n",
            "2020-01-19 19:26:28 start epoch 456/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:26:28 iter 1 loss = 0.090488\n",
            "2020-01-19 19:26:31 iter 25 loss = 0.082451\n",
            "2020-01-19 19:26:34 iter 50 loss = 0.086624\n",
            "2020-01-19 19:26:38 iter 75 loss = 0.070002\n",
            "2020-01-19 19:26:41 iter 100 loss = 0.081017\n",
            "2020-01-19 19:26:41 epoch 456/500 average_loss = 0.078052\n",
            "\n",
            "2020-01-19 19:26:41 start epoch 457/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:26:41 iter 1 loss = 0.075767\n",
            "2020-01-19 19:26:44 iter 25 loss = 0.082524\n",
            "2020-01-19 19:26:47 iter 50 loss = 0.077171\n",
            "2020-01-19 19:26:50 iter 75 loss = 0.074312\n",
            "2020-01-19 19:26:53 iter 100 loss = 0.070579\n",
            "2020-01-19 19:26:53 epoch 457/500 average_loss = 0.076841\n",
            "\n",
            "2020-01-19 19:26:53 start epoch 458/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:26:53 iter 1 loss = 0.069732\n",
            "2020-01-19 19:26:57 iter 25 loss = 0.082570\n",
            "2020-01-19 19:27:00 iter 50 loss = 0.067236\n",
            "2020-01-19 19:27:03 iter 75 loss = 0.080719\n",
            "2020-01-19 19:27:06 iter 100 loss = 0.061934\n",
            "2020-01-19 19:27:06 epoch 458/500 average_loss = 0.077210\n",
            "\n",
            "2020-01-19 19:27:06 start epoch 459/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:27:06 iter 1 loss = 0.071715\n",
            "2020-01-19 19:27:09 iter 25 loss = 0.070209\n",
            "2020-01-19 19:27:12 iter 50 loss = 0.079287\n",
            "2020-01-19 19:27:15 iter 75 loss = 0.079520\n",
            "2020-01-19 19:27:19 iter 100 loss = 0.081692\n",
            "2020-01-19 19:27:19 epoch 459/500 average_loss = 0.077364\n",
            "\n",
            "2020-01-19 19:27:19 start epoch 460/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:27:19 iter 1 loss = 0.077980\n",
            "2020-01-19 19:27:22 iter 25 loss = 0.097045\n",
            "2020-01-19 19:27:25 iter 50 loss = 0.084958\n",
            "2020-01-19 19:27:28 iter 75 loss = 0.070864\n",
            "2020-01-19 19:27:31 iter 100 loss = 0.077082\n",
            "2020-01-19 19:27:31 epoch 460/500 average_loss = 0.078092\n",
            "\n",
            "2020-01-19 19:27:31 start epoch 461/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:27:31 iter 1 loss = 0.075417\n",
            "2020-01-19 19:27:34 iter 25 loss = 0.087587\n",
            "2020-01-19 19:27:37 iter 50 loss = 0.068803\n",
            "2020-01-19 19:27:41 iter 75 loss = 0.073130\n",
            "2020-01-19 19:27:44 iter 100 loss = 0.070986\n",
            "2020-01-19 19:27:44 epoch 461/500 average_loss = 0.077153\n",
            "\n",
            "2020-01-19 19:27:44 start epoch 462/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:27:44 iter 1 loss = 0.070428\n",
            "2020-01-19 19:27:47 iter 25 loss = 0.069670\n",
            "2020-01-19 19:27:50 iter 50 loss = 0.066884\n",
            "2020-01-19 19:27:53 iter 75 loss = 0.071244\n",
            "2020-01-19 19:27:56 iter 100 loss = 0.080011\n",
            "2020-01-19 19:27:56 epoch 462/500 average_loss = 0.077487\n",
            "\n",
            "2020-01-19 19:27:56 start epoch 463/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:27:57 iter 1 loss = 0.073617\n",
            "2020-01-19 19:28:00 iter 25 loss = 0.065401\n",
            "2020-01-19 19:28:03 iter 50 loss = 0.067570\n",
            "2020-01-19 19:28:06 iter 75 loss = 0.088731\n",
            "2020-01-19 19:28:09 iter 100 loss = 0.074410\n",
            "2020-01-19 19:28:09 epoch 463/500 average_loss = 0.078215\n",
            "\n",
            "2020-01-19 19:28:09 start epoch 464/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:28:09 iter 1 loss = 0.090718\n",
            "2020-01-19 19:28:12 iter 25 loss = 0.075398\n",
            "2020-01-19 19:28:16 iter 50 loss = 0.075499\n",
            "2020-01-19 19:28:19 iter 75 loss = 0.067190\n",
            "2020-01-19 19:28:22 iter 100 loss = 0.072841\n",
            "2020-01-19 19:28:22 epoch 464/500 average_loss = 0.076873\n",
            "\n",
            "2020-01-19 19:28:22 start epoch 465/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:28:22 iter 1 loss = 0.075454\n",
            "2020-01-19 19:28:25 iter 25 loss = 0.070051\n",
            "2020-01-19 19:28:28 iter 50 loss = 0.069564\n",
            "2020-01-19 19:28:31 iter 75 loss = 0.087808\n",
            "2020-01-19 19:28:34 iter 100 loss = 0.087437\n",
            "2020-01-19 19:28:34 epoch 465/500 average_loss = 0.076099\n",
            "\n",
            "2020-01-19 19:28:34 start epoch 466/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:28:35 iter 1 loss = 0.064841\n",
            "2020-01-19 19:28:38 iter 25 loss = 0.075090\n",
            "2020-01-19 19:28:41 iter 50 loss = 0.074540\n",
            "2020-01-19 19:28:44 iter 75 loss = 0.076955\n",
            "2020-01-19 19:28:47 iter 100 loss = 0.083767\n",
            "2020-01-19 19:28:47 epoch 466/500 average_loss = 0.075927\n",
            "\n",
            "2020-01-19 19:28:47 start epoch 467/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:28:47 iter 1 loss = 0.058953\n",
            "2020-01-19 19:28:50 iter 25 loss = 0.082522\n",
            "2020-01-19 19:28:53 iter 50 loss = 0.076312\n",
            "2020-01-19 19:28:56 iter 75 loss = 0.072881\n",
            "2020-01-19 19:29:00 iter 100 loss = 0.090870\n",
            "2020-01-19 19:29:00 epoch 467/500 average_loss = 0.076806\n",
            "\n",
            "2020-01-19 19:29:00 start epoch 468/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:29:00 iter 1 loss = 0.083380\n",
            "2020-01-19 19:29:03 iter 25 loss = 0.087287\n",
            "2020-01-19 19:29:06 iter 50 loss = 0.075547\n",
            "2020-01-19 19:29:09 iter 75 loss = 0.076092\n",
            "2020-01-19 19:29:12 iter 100 loss = 0.064399\n",
            "2020-01-19 19:29:12 epoch 468/500 average_loss = 0.077192\n",
            "\n",
            "2020-01-19 19:29:12 start epoch 469/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:29:12 iter 1 loss = 0.085245\n",
            "2020-01-19 19:29:15 iter 25 loss = 0.075676\n",
            "2020-01-19 19:29:19 iter 50 loss = 0.066282\n",
            "2020-01-19 19:29:22 iter 75 loss = 0.085078\n",
            "2020-01-19 19:29:25 iter 100 loss = 0.071537\n",
            "2020-01-19 19:29:25 epoch 469/500 average_loss = 0.076120\n",
            "\n",
            "2020-01-19 19:29:25 start epoch 470/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:29:25 iter 1 loss = 0.065539\n",
            "2020-01-19 19:29:28 iter 25 loss = 0.070872\n",
            "2020-01-19 19:29:31 iter 50 loss = 0.074871\n",
            "2020-01-19 19:29:34 iter 75 loss = 0.074556\n",
            "2020-01-19 19:29:38 iter 100 loss = 0.083691\n",
            "2020-01-19 19:29:38 epoch 470/500 average_loss = 0.075558\n",
            "\n",
            "2020-01-19 19:29:38 start epoch 471/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:29:38 iter 1 loss = 0.068434\n",
            "2020-01-19 19:29:41 iter 25 loss = 0.069928\n",
            "2020-01-19 19:29:44 iter 50 loss = 0.072055\n",
            "2020-01-19 19:29:47 iter 75 loss = 0.066705\n",
            "2020-01-19 19:29:50 iter 100 loss = 0.067818\n",
            "2020-01-19 19:29:50 epoch 471/500 average_loss = 0.077321\n",
            "\n",
            "2020-01-19 19:29:50 start epoch 472/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:29:50 iter 1 loss = 0.076672\n",
            "2020-01-19 19:29:53 iter 25 loss = 0.069591\n",
            "2020-01-19 19:29:57 iter 50 loss = 0.084768\n",
            "2020-01-19 19:30:00 iter 75 loss = 0.081926\n",
            "2020-01-19 19:30:03 iter 100 loss = 0.104965\n",
            "2020-01-19 19:30:03 epoch 472/500 average_loss = 0.076727\n",
            "\n",
            "2020-01-19 19:30:03 start epoch 473/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:30:03 iter 1 loss = 0.079812\n",
            "2020-01-19 19:30:06 iter 25 loss = 0.072419\n",
            "2020-01-19 19:30:09 iter 50 loss = 0.074499\n",
            "2020-01-19 19:30:12 iter 75 loss = 0.098921\n",
            "2020-01-19 19:30:15 iter 100 loss = 0.084615\n",
            "2020-01-19 19:30:15 epoch 473/500 average_loss = 0.076494\n",
            "\n",
            "2020-01-19 19:30:15 start epoch 474/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:30:16 iter 1 loss = 0.076522\n",
            "2020-01-19 19:30:19 iter 25 loss = 0.076679\n",
            "2020-01-19 19:30:22 iter 50 loss = 0.083839\n",
            "2020-01-19 19:30:25 iter 75 loss = 0.082232\n",
            "2020-01-19 19:30:28 iter 100 loss = 0.074699\n",
            "2020-01-19 19:30:28 epoch 474/500 average_loss = 0.077448\n",
            "\n",
            "2020-01-19 19:30:28 start epoch 475/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:30:28 iter 1 loss = 0.075703\n",
            "2020-01-19 19:30:31 iter 25 loss = 0.075503\n",
            "2020-01-19 19:30:34 iter 50 loss = 0.079698\n",
            "2020-01-19 19:30:38 iter 75 loss = 0.071108\n",
            "2020-01-19 19:30:41 iter 100 loss = 0.078432\n",
            "2020-01-19 19:30:41 epoch 475/500 average_loss = 0.076776\n",
            "\n",
            "2020-01-19 19:30:41 start epoch 476/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:30:41 iter 1 loss = 0.070012\n",
            "2020-01-19 19:30:44 iter 25 loss = 0.082585\n",
            "2020-01-19 19:30:47 iter 50 loss = 0.073383\n",
            "2020-01-19 19:30:50 iter 75 loss = 0.070805\n",
            "2020-01-19 19:30:53 iter 100 loss = 0.075789\n",
            "2020-01-19 19:30:53 epoch 476/500 average_loss = 0.077638\n",
            "\n",
            "2020-01-19 19:30:53 start epoch 477/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:30:53 iter 1 loss = 0.072848\n",
            "2020-01-19 19:30:56 iter 25 loss = 0.075081\n",
            "2020-01-19 19:31:00 iter 50 loss = 0.074933\n",
            "2020-01-19 19:31:03 iter 75 loss = 0.071650\n",
            "2020-01-19 19:31:06 iter 100 loss = 0.075382\n",
            "2020-01-19 19:31:06 epoch 477/500 average_loss = 0.075225\n",
            "\n",
            "2020-01-19 19:31:06 start epoch 478/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:31:06 iter 1 loss = 0.079324\n",
            "2020-01-19 19:31:09 iter 25 loss = 0.080131\n",
            "2020-01-19 19:31:12 iter 50 loss = 0.086603\n",
            "2020-01-19 19:31:15 iter 75 loss = 0.085315\n",
            "2020-01-19 19:31:19 iter 100 loss = 0.085268\n",
            "2020-01-19 19:31:19 epoch 478/500 average_loss = 0.076795\n",
            "\n",
            "2020-01-19 19:31:19 start epoch 479/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:31:19 iter 1 loss = 0.068450\n",
            "2020-01-19 19:31:22 iter 25 loss = 0.070732\n",
            "2020-01-19 19:31:25 iter 50 loss = 0.071279\n",
            "2020-01-19 19:31:28 iter 75 loss = 0.086158\n",
            "2020-01-19 19:31:31 iter 100 loss = 0.069275\n",
            "2020-01-19 19:31:31 epoch 479/500 average_loss = 0.077062\n",
            "\n",
            "2020-01-19 19:31:31 start epoch 480/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:31:31 iter 1 loss = 0.061584\n",
            "2020-01-19 19:31:34 iter 25 loss = 0.089490\n",
            "2020-01-19 19:31:37 iter 50 loss = 0.079593\n",
            "2020-01-19 19:31:41 iter 75 loss = 0.079638\n",
            "2020-01-19 19:31:44 iter 100 loss = 0.073133\n",
            "2020-01-19 19:31:44 epoch 480/500 average_loss = 0.076195\n",
            "\n",
            "2020-01-19 19:31:44 start epoch 481/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:31:44 iter 1 loss = 0.076428\n",
            "2020-01-19 19:31:47 iter 25 loss = 0.097121\n",
            "2020-01-19 19:31:50 iter 50 loss = 0.071578\n",
            "2020-01-19 19:31:53 iter 75 loss = 0.088057\n",
            "2020-01-19 19:31:56 iter 100 loss = 0.073404\n",
            "2020-01-19 19:31:56 epoch 481/500 average_loss = 0.076308\n",
            "\n",
            "2020-01-19 19:31:56 start epoch 482/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:31:57 iter 1 loss = 0.086107\n",
            "2020-01-19 19:32:00 iter 25 loss = 0.075795\n",
            "2020-01-19 19:32:03 iter 50 loss = 0.080599\n",
            "2020-01-19 19:32:06 iter 75 loss = 0.082681\n",
            "2020-01-19 19:32:09 iter 100 loss = 0.075344\n",
            "2020-01-19 19:32:09 epoch 482/500 average_loss = 0.076332\n",
            "\n",
            "2020-01-19 19:32:09 start epoch 483/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:32:09 iter 1 loss = 0.071005\n",
            "2020-01-19 19:32:12 iter 25 loss = 0.065583\n",
            "2020-01-19 19:32:15 iter 50 loss = 0.065269\n",
            "2020-01-19 19:32:19 iter 75 loss = 0.069002\n",
            "2020-01-19 19:32:22 iter 100 loss = 0.076262\n",
            "2020-01-19 19:32:22 epoch 483/500 average_loss = 0.076202\n",
            "\n",
            "2020-01-19 19:32:22 start epoch 484/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:32:22 iter 1 loss = 0.073354\n",
            "2020-01-19 19:32:25 iter 25 loss = 0.078543\n",
            "2020-01-19 19:32:28 iter 50 loss = 0.067881\n",
            "2020-01-19 19:32:31 iter 75 loss = 0.115129\n",
            "2020-01-19 19:32:34 iter 100 loss = 0.079365\n",
            "2020-01-19 19:32:34 epoch 484/500 average_loss = 0.076289\n",
            "\n",
            "2020-01-19 19:32:34 start epoch 485/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:32:34 iter 1 loss = 0.081087\n",
            "2020-01-19 19:32:37 iter 25 loss = 0.095607\n",
            "2020-01-19 19:32:41 iter 50 loss = 0.079658\n",
            "2020-01-19 19:32:44 iter 75 loss = 0.083243\n",
            "2020-01-19 19:32:47 iter 100 loss = 0.073903\n",
            "2020-01-19 19:32:47 epoch 485/500 average_loss = 0.075855\n",
            "\n",
            "2020-01-19 19:32:47 start epoch 486/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:32:47 iter 1 loss = 0.068026\n",
            "2020-01-19 19:32:50 iter 25 loss = 0.075425\n",
            "2020-01-19 19:32:53 iter 50 loss = 0.079031\n",
            "2020-01-19 19:32:56 iter 75 loss = 0.082654\n",
            "2020-01-19 19:33:00 iter 100 loss = 0.084646\n",
            "2020-01-19 19:33:00 epoch 486/500 average_loss = 0.077287\n",
            "\n",
            "2020-01-19 19:33:00 start epoch 487/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:33:00 iter 1 loss = 0.077480\n",
            "2020-01-19 19:33:03 iter 25 loss = 0.071101\n",
            "2020-01-19 19:33:06 iter 50 loss = 0.083161\n",
            "2020-01-19 19:33:09 iter 75 loss = 0.081919\n",
            "2020-01-19 19:33:12 iter 100 loss = 0.090462\n",
            "2020-01-19 19:33:12 epoch 487/500 average_loss = 0.077506\n",
            "\n",
            "2020-01-19 19:33:12 start epoch 488/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:33:12 iter 1 loss = 0.073484\n",
            "2020-01-19 19:33:15 iter 25 loss = 0.105234\n",
            "2020-01-19 19:33:19 iter 50 loss = 0.070638\n",
            "2020-01-19 19:33:22 iter 75 loss = 0.084393\n",
            "2020-01-19 19:33:25 iter 100 loss = 0.069793\n",
            "2020-01-19 19:33:25 epoch 488/500 average_loss = 0.076231\n",
            "\n",
            "2020-01-19 19:33:25 start epoch 489/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:33:25 iter 1 loss = 0.083239\n",
            "2020-01-19 19:33:28 iter 25 loss = 0.084561\n",
            "2020-01-19 19:33:31 iter 50 loss = 0.076827\n",
            "2020-01-19 19:33:34 iter 75 loss = 0.076834\n",
            "2020-01-19 19:33:38 iter 100 loss = 0.082698\n",
            "2020-01-19 19:33:38 epoch 489/500 average_loss = 0.076453\n",
            "\n",
            "2020-01-19 19:33:38 start epoch 490/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:33:38 iter 1 loss = 0.077543\n",
            "2020-01-19 19:33:41 iter 25 loss = 0.091266\n",
            "2020-01-19 19:33:44 iter 50 loss = 0.061991\n",
            "2020-01-19 19:33:47 iter 75 loss = 0.083183\n",
            "2020-01-19 19:33:50 iter 100 loss = 0.068962\n",
            "2020-01-19 19:33:50 epoch 490/500 average_loss = 0.075835\n",
            "\n",
            "2020-01-19 19:33:50 start epoch 491/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:33:50 iter 1 loss = 0.074912\n",
            "2020-01-19 19:33:53 iter 25 loss = 0.075626\n",
            "2020-01-19 19:33:56 iter 50 loss = 0.075314\n",
            "2020-01-19 19:34:00 iter 75 loss = 0.084510\n",
            "2020-01-19 19:34:03 iter 100 loss = 0.097613\n",
            "2020-01-19 19:34:03 epoch 491/500 average_loss = 0.076440\n",
            "\n",
            "2020-01-19 19:34:03 start epoch 492/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:34:03 iter 1 loss = 0.080381\n",
            "2020-01-19 19:34:06 iter 25 loss = 0.063088\n",
            "2020-01-19 19:34:09 iter 50 loss = 0.073942\n",
            "2020-01-19 19:34:12 iter 75 loss = 0.072902\n",
            "2020-01-19 19:34:15 iter 100 loss = 0.081515\n",
            "2020-01-19 19:34:15 epoch 492/500 average_loss = 0.077705\n",
            "\n",
            "2020-01-19 19:34:15 start epoch 493/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:34:16 iter 1 loss = 0.071010\n",
            "2020-01-19 19:34:19 iter 25 loss = 0.075628\n",
            "2020-01-19 19:34:22 iter 50 loss = 0.077029\n",
            "2020-01-19 19:34:25 iter 75 loss = 0.078006\n",
            "2020-01-19 19:34:28 iter 100 loss = 0.079976\n",
            "2020-01-19 19:34:28 epoch 493/500 average_loss = 0.075247\n",
            "\n",
            "2020-01-19 19:34:28 start epoch 494/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:34:28 iter 1 loss = 0.083120\n",
            "2020-01-19 19:34:31 iter 25 loss = 0.066541\n",
            "2020-01-19 19:34:35 iter 50 loss = 0.089675\n",
            "2020-01-19 19:34:38 iter 75 loss = 0.081750\n",
            "2020-01-19 19:34:41 iter 100 loss = 0.076714\n",
            "2020-01-19 19:34:41 epoch 494/500 average_loss = 0.077341\n",
            "\n",
            "2020-01-19 19:34:41 start epoch 495/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:34:41 iter 1 loss = 0.086887\n",
            "2020-01-19 19:34:44 iter 25 loss = 0.069555\n",
            "2020-01-19 19:34:47 iter 50 loss = 0.077736\n",
            "2020-01-19 19:34:50 iter 75 loss = 0.080683\n",
            "2020-01-19 19:34:53 iter 100 loss = 0.085988\n",
            "2020-01-19 19:34:53 epoch 495/500 average_loss = 0.076183\n",
            "\n",
            "2020-01-19 19:34:53 start epoch 496/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:34:54 iter 1 loss = 0.056120\n",
            "2020-01-19 19:34:57 iter 25 loss = 0.060869\n",
            "2020-01-19 19:35:00 iter 50 loss = 0.075740\n",
            "2020-01-19 19:35:03 iter 75 loss = 0.105154\n",
            "2020-01-19 19:35:06 iter 100 loss = 0.073148\n",
            "2020-01-19 19:35:06 epoch 496/500 average_loss = 0.075153\n",
            "\n",
            "2020-01-19 19:35:06 start epoch 497/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:35:06 iter 1 loss = 0.072826\n",
            "2020-01-19 19:35:09 iter 25 loss = 0.075698\n",
            "2020-01-19 19:35:13 iter 50 loss = 0.073282\n",
            "2020-01-19 19:35:16 iter 75 loss = 0.073850\n",
            "2020-01-19 19:35:19 iter 100 loss = 0.057089\n",
            "2020-01-19 19:35:19 epoch 497/500 average_loss = 0.075541\n",
            "\n",
            "2020-01-19 19:35:19 start epoch 498/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:35:19 iter 1 loss = 0.070117\n",
            "2020-01-19 19:35:22 iter 25 loss = 0.075290\n",
            "2020-01-19 19:35:25 iter 50 loss = 0.067559\n",
            "2020-01-19 19:35:28 iter 75 loss = 0.086100\n",
            "2020-01-19 19:35:31 iter 100 loss = 0.097680\n",
            "2020-01-19 19:35:31 epoch 498/500 average_loss = 0.075204\n",
            "\n",
            "2020-01-19 19:35:31 start epoch 499/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:35:32 iter 1 loss = 0.071625\n",
            "2020-01-19 19:35:35 iter 25 loss = 0.089868\n",
            "2020-01-19 19:35:38 iter 50 loss = 0.069090\n",
            "2020-01-19 19:35:41 iter 75 loss = 0.085029\n",
            "2020-01-19 19:35:44 iter 100 loss = 0.070553\n",
            "2020-01-19 19:35:44 epoch 499/500 average_loss = 0.075617\n",
            "\n",
            "2020-01-19 19:35:44 start epoch 500/500: learning_rate = 0.004 sequence_len = 28\n",
            "2020-01-19 19:35:44 iter 1 loss = 0.076001\n",
            "2020-01-19 19:35:47 iter 25 loss = 0.079967\n",
            "2020-01-19 19:35:50 iter 50 loss = 0.076219\n",
            "2020-01-19 19:35:54 iter 75 loss = 0.087885\n",
            "2020-01-19 19:35:57 iter 100 loss = 0.077157\n",
            "2020-01-19 19:35:57 epoch 500/500 average_loss = 0.076964\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTUH_K-Hb94D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(my_model.state_dict(),\"weights_final.pth\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kE8wffL97xOv",
        "colab_type": "code",
        "outputId": "c9b54673-280a-461d-b153-7e6d960ec14e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        }
      },
      "source": [
        "dataiter = iter(loader_train)\n",
        "#my_model.load_state_dict(torch.load(\"/weights\"))\n",
        "#my_model.eval()\n",
        "image_train, label_train = dataiter.next()\n",
        "image_train=image_train[2,...].resize_([1]+list(image_train.size())[1:])\n",
        "#new_image=Image.open(\"cropped_data/cropped_dir/10.jpg\").convert(\"RGB\")\n",
        "#new_image=mytransform(new_image)\n",
        "print(image_train.size())\n",
        "#new_image=new_image.unsqueeze(0)\n",
        "imshow(utils.make_grid(image_train))\n",
        "print(label_train[2])\n",
        "\n",
        "x_var_train = Variable(image_train.type(dtype))\n",
        "out=my_model.feature_extractor(x_var_train)\n",
        "feature_map=out.cpu().data.numpy()\n",
        "print(feature_map.shape)\n",
        "sample_index=np.random.choice(256,4)\n",
        "plt.figure(figsize = (2,2))\n",
        "gs1 = gridspec.GridSpec(2, 2)\n",
        "gs1.update(wspace=0.025, hspace=0.05)\n",
        "\n",
        "for i in range(4):\n",
        "    plt.subplot(gs1[i])\n",
        "    feature_submap=feature_map[0,sample_index[i],:,:]\n",
        "    plt.imshow(feature_submap)\n",
        "    plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "my_model.RNN.init_hidden(1)\n",
        "result=my_model(x_var_train)\n",
        "softmax=nn.Softmax(dim=2)\n",
        "result_sf=softmax(result)\n",
        "result_np=result_sf.cpu().data.numpy()\n",
        "result_word=''\n",
        "for i in range(sequence_len):\n",
        "    ch=np.argmax(result_np[i,0,:])\n",
        "    #print(ch)\n",
        "    if indexTochr[ch] in result_word:\n",
        "      continue\n",
        "    result_word+=indexTochr[ch]\n",
        "print(result_word.replace(\"-\",\" \").strip())"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 3, 224, 224])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQEAAAD8CAYAAAB3lxGOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlMP/B5TYTXMAcs8YAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "पचमढी\n",
            "(1, 256, 28, 28)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHsAAAB7CAYAAABUx/9/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
            "text/plain": [
              "<Figure size 144x144 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "पचमढी\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4owWfYqfmgM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}